Attention: The following text is a 'bfiles' bundle, containing multiple delimited files with metadata.
Parse and analyze the content between '<<< BOF <<<' and '>>> EOF >>>' for each '### FILE...' entry.

--- START OF BFILE bfiles-20251010-131213.txt ---
bfiles bundle generated on: 2025-10-10T13:12:13.146409
Config: hash=sha256, gitignore=yes, followlinks=no
---

### FILE 1: tofusoup/__init__.py | checksum=a7e4eb034c32... | modified=2025-09-17T17:32:12 | op=+ | size=124 | tokens=48 | type=x-python ###
<<< BOF <<<
#
# tofusoup/__init__.py
#

from tofusoup._version import __version__

__all__ = [
    "__version__",
]

# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 2: tofusoup/_version.py | checksum=2a490afd4fe7... | modified=2025-09-17T17:32:12 | op=+ | size=1338 | tokens=284 | type=x-python ###
<<< BOF <<<
#
# _version.py
#
"""
Version handling for tofusoup.
Uses VERSION file with robust fallback mechanisms.
"""

from pathlib import Path


def _find_project_root() -> Path | None:
    """Find the project root directory by looking for VERSION file."""
    current = Path(__file__).parent

    # Walk up the directory tree looking for VERSION file
    while current != current.parent:  # Stop at filesystem root
        version_file = current / "VERSION"
        if version_file.exists():
            return current
        current = current.parent

    return None


def get_version() -> str:
    """Get the current tofusoup version.

    Reads from VERSION file if it exists, otherwise falls back to package metadata,
    then to default development version.

    Returns:
        str: The current version string
    """
    # Try VERSION file first (single source of truth)
    project_root = _find_project_root()
    if project_root:
        version_file = project_root / "VERSION"
        if version_file.exists():
            return version_file.read_text().strip()

    # Fallback to package metadata
    try:
        from importlib.metadata import PackageNotFoundError, version

        return version("tofusoup")
    except PackageNotFoundError:
        pass

    # Final fallback
    return "0.0.0-dev"


__version__ = get_version()
>>> EOF >>>

### FILE 3: tofusoup/browser/__init__.py | checksum=e78b066909bd... | modified=2025-09-19T10:07:06 | op=+ | size=96 | tokens=31 | type=x-python ###
<<< BOF <<<
#!/usr/bin/env python3
#
# tofusoup/browser/__init__.py
#
"""Browser module for tofusoup TUI."""
>>> EOF >>>

### FILE 4: tofusoup/browser/cli.py | checksum=abdc2bac3d3e... | modified=2025-09-17T17:32:12 | op=+ | size=1556 | tokens=392 | type=x-python ###
<<< BOF <<<
#!/usr/bin/env python3
#
# tofusoup/browser/cli.py
#

import click
from provide.foundation import get_hub, logger

from tofusoup.browser.ui.app import TFBrowserApp


@click.group("sui")
@click.pass_context
def sui_cli(ctx: click.Context) -> None:
    """Graphical UI for browsing Terraform and OpenTofu registries."""
    logger.debug("TofuSoup 'sui' command group invoked.")
    pass


@sui_cli.command("tui")
@click.option(
    "-r",
    "--registry",
    "registry_name",
    type=str,
    help="Name of the registry to pre-select or focus in TUI (e.g., 'terraform', 'opentofu').",
)
@click.pass_context
def tui_command(ctx: click.Context, registry_name: str | None) -> None:
    """Launch the Textual TUI to browse registries."""
    logger.info(f"Launching TUI browser. Specified registry context: {registry_name or 'not specified'}")
    app = TFBrowserApp()
    try:
        app.run()
    except Exception as e:
        # This block will now correctly log to stderr because of the finally block.
        logger.error(f"Error running TUI browser: {e}", exc_info=True)
        click.echo(f"Failed to launch TUI: {e}", err=True)
    finally:
        # FIX: Reset the logger to its default state (writing to stderr).
        # This is critical to prevent logging calls after the TUI has exited
        # from trying to write to a destroyed widget, which causes the NoActiveAppError.
        hub = get_hub()
        hub.initialize_foundation()  # Re-initialize to default stderr logging
        logger.info("TUI browser exited.")


# 🍲🥄🖥️🪄
>>> EOF >>>

### FILE 5: tofusoup/browser/ui/__init__.py | checksum=eacab2b931be... | modified=2025-09-17T17:32:12 | op=+ | size=258 | tokens=84 | type=x-python ###
<<< BOF <<<
#
# tofusoup/browser/ui/__init__.py
#
"""User Interface component for tfbrowser, built with Textual."""

from .app import TFBrowserApp  # Assuming TFBrowserApp will be the main app class

__all__ = [
    "TFBrowserApp",
]

# 🎨🖥️


# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 6: tofusoup/browser/ui/app.py | checksum=8a41493d7587... | modified=2025-09-17T17:32:12 | op=+ | size=4592 | tokens=956 | type=x-python ###
<<< BOF <<<
#
# tofusoup/browser/ui/app.py
#

from provide.foundation import LoggingConfig, TelemetryConfig, get_hub, logger
from textual.app import App, ComposeResult
from textual.message import Message
from textual.screen import Screen
from textual.widgets import DataTable, Footer, Header

from tofusoup.browser.ui.widgets.detail_view import DetailView
from tofusoup.browser.ui.widgets.log_viewer import LogViewer
from tofusoup.browser.ui.widgets.search_view import SearchView
from tofusoup.config.defaults import TERRAFORM_REGISTRY_URL, TUI_LOG_LEVEL, TUI_SERVICE_NAME
from tofusoup.registry import IBMTerraformRegistry, OpenTofuRegistry, RegistryConfig
from tofusoup.registry.search.engine import SearchEngine, SearchQuery, SearchResult


class MainSearchScreen(Screen[None]):
    """The main screen for search functionality."""

    class NewSearchResult(Message):
        """A message to deliver a single search result as it arrives."""

        def __init__(self, result: SearchResult) -> None:
            super().__init__()
            self.result = result

    class SearchComplete(Message):
        """A message to signal that the search stream has finished."""

        pass

    def compose(self) -> ComposeResult:
        """Compose the screen layout."""
        yield Header()
        yield SearchView()
        yield LogViewer()
        yield Footer()

    def on_mount(self) -> None:
        telemetry_config = TelemetryConfig(
            service_name=TUI_SERVICE_NAME, logging=LoggingConfig(default_level=TUI_LOG_LEVEL)
        )
        hub = get_hub()
        hub.initialize_foundation(config=telemetry_config)
        logger.info("TUI Logger Initialized. Ready for search.")

    def on_search_view_search_submitted(self, event: SearchView.SearchSubmitted) -> None:
        logger.info(f"Search submitted for query: '{event.query}'")
        search_view = self.query_one(SearchView)
        search_view.clear_table()
        search_view.show_loading(True)
        self.run_worker(self.perform_search(event.query), exclusive=True)

    async def perform_search(self, query_term: str) -> None:
        """The background worker that streams results."""
        try:
            registries = [
                IBMTerraformRegistry(config=RegistryConfig(base_url=TERRAFORM_REGISTRY_URL)),
                OpenTofuRegistry(),
            ]
            engine = SearchEngine(registries=registries)
            query = SearchQuery(term=query_term)

            async for result in engine.search(query):
                self.post_message(self.NewSearchResult(result))

            await engine.close()
        except Exception as e:
            self.call_from_thread(logger.error, f"Error during background search: {e}", exc_info=True)
        finally:
            self.post_message(self.SearchComplete())

    def on_main_search_screen_new_search_result(self, message: NewSearchResult) -> None:
        """Handles receiving a single search result from the worker."""
        search_view = self.query_one(SearchView)
        search_view.add_result(message.result)

    def on_main_search_screen_search_complete(self, message: SearchComplete) -> None:
        """Handles the end of the search stream."""
        search_view = self.query_one(SearchView)
        search_view.show_loading(False)
        logger.info("Search stream complete. Results displayed.")
        # FIX: Move focus to the results table for immediate navigation.
        self.query_one(DataTable).focus()

    async def on_search_view_result_selected(self, event: SearchView.ResultSelected) -> None:
        logger.info(f"Result selected: {event.result.id}")
        self.app.push_screen(DetailScreen(item_details=event.result))


class DetailScreen(Screen):
    """A screen to display detailed information about an item."""

    # FIX: Add key binding to allow 'escape' to pop the screen.
    BINDINGS = [("escape", "app.pop_screen", "Back")]

    def __init__(self, item_details: SearchResult, **kwargs) -> None:
        super().__init__(**kwargs)
        self.item_details = item_details

    def compose(self) -> ComposeResult:
        yield Header()
        yield DetailView()
        yield Footer()

    def on_mount(self) -> None:
        detail_view_widget = self.query_one(DetailView)
        detail_view_widget.update_content(self.item_details)


class TFBrowserApp(App[None]):
    """The main tfbrowser TUI application."""

    CSS_PATH = "app.tcss"
    TITLE = "tfbrowser - Terraform/OpenTofu Registry Browser"

    def on_mount(self) -> None:
        self.push_screen(MainSearchScreen())


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 7: tofusoup/browser/ui/app.tcss | checksum=5877610f266d... | modified=2025-08-04T14:38:49 | op=+ | size=34 | tokens=5 ###
<<< BOF <<<
/* Main application stylesheet */
>>> EOF >>>

### FILE 8: tofusoup/browser/ui/screens/__init__.py | checksum=e6272350a673... | modified=2025-09-17T17:32:12 | op=+ | size=336 | tokens=101 | type=x-python ###
<<< BOF <<<
#
# tofusoup/browser/ui/screens/__init__.py
#
"""Screens for the tfbrowser TUI application."""

# Example:
# from .home_screen import HomeScreen
# from .search_screen import SearchScreen
# from .detail_screen import DetailScreen

# __all__ = [
# "HomeScreen",
# "SearchScreen",
# "DetailScreen",
# ]

# 📺🖼️


# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 9: tofusoup/browser/ui/themes/__init__.py | checksum=9ce77eb0e05c... | modified=2025-09-17T17:32:12 | op=+ | size=474 | tokens=128 | type=x-python ###
<<< BOF <<<
#
# tofusoup/browser/ui/themes/__init__.py
#
"""Textual CSS themes for tfbrowser."""

# This directory would typically contain .tcss files.
# Python __init__.py might be used if themes are programmatically managed
# or to make it a package, but often it's just for .tcss files.

# For example, you might have:
# default_theme.tcss
# light_theme.tcss

# No specific Python exports are usually needed here unless loading themes via Python.

# 🎨🖌️


# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 10: tofusoup/browser/ui/widgets/__init__.py | checksum=0019d9cc7b4c... | modified=2025-09-17T17:32:12 | op=+ | size=271 | tokens=86 | type=x-python ###
<<< BOF <<<
#
# tofusoup/browser/ui/widgets/__init__.py
#
"""Custom Textual widgets for tfbrowser."""

# Example:
# from .search_input import SearchInput
# from .results_list import ResultsList

# __all__ = [
# "SearchInput",
# "ResultsList",
# ]

# 🧩🛠️


# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 11: tofusoup/browser/ui/widgets/detail_view.py | checksum=5ce3c645d893... | modified=2025-09-17T17:32:12 | op=+ | size=1871 | tokens=408 | type=x-python ###
<<< BOF <<<
#
# tofusoup/browser/ui/widgets/detail_view.py
#
from textual.containers import VerticalScroll
from textual.widgets import Markdown

from tofusoup.registry.search.engine import SearchResult


class DetailView(VerticalScroll):
    """A widget to display details of a selected search result."""

    DEFAULT_CSS = """
    DetailView {
        padding: 1;
    }
    """

    def __init__(self, **kwargs) -> None:
        super().__init__(**kwargs)
        self._markdown = Markdown()
        self._raw_markdown_content = ""

    @property
    def raw_content(self) -> str:
        """Exposes the raw markdown string for reliable testing."""
        return self._raw_markdown_content

    def on_mount(self) -> None:
        """Set the initial content when the widget is mounted."""
        initial_content = "No item selected."
        self._raw_markdown_content = initial_content
        self._markdown.update(initial_content)

    def compose(self):
        yield self._markdown

    def update_content(self, result: SearchResult | None) -> None:
        """Update the content of the detail view. This is a synchronous method."""
        if result:
            name = f"{result.namespace}/{result.name}"
            if result.type == "module":
                name += f"/{result.provider_name}"

            markdown_doc = f"""
# {name}

- **Type**: {result.type}
- **Registry**: {result.registry_source}
- **Latest Version**: {result.latest_version or "N/A"}
- **Total Versions**: {result.total_versions or "N/A"}

---

{result.description or "No description available."}
"""
            self._raw_markdown_content = markdown_doc
            self._markdown.update(markdown_doc)
        else:
            no_item_content = "No item selected."
            self._raw_markdown_content = no_item_content
            self._markdown.update(no_item_content)


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 12: tofusoup/browser/ui/widgets/log_viewer.py | checksum=d8e8357b607b... | modified=2025-09-17T17:32:12 | op=+ | size=1359 | tokens=322 | type=x-python ###
<<< BOF <<<
#
# tofusoup/browser/ui/widgets/log_viewer.py
#
import threading

from rich.text import Text
from textual.widget import Widget
from textual.widgets import RichLog


class LogViewer(Widget):
    """A widget to display application logs."""

    DEFAULT_CSS = """
    LogViewer {
        height: 10;
        border-top: thick $surface-darken-1;
    }
    """

    def __init__(self, **kwargs) -> None:
        super().__init__(**kwargs)
        self._log_widget = RichLog(wrap=True, highlight=True, markup=True)
        self.border_title = "🪵 Logs"

    def compose(self):
        yield self._log_widget

    def write(self, text: str) -> None:
        """
        Write a line of text to the log. This method is thread-safe.
        """
        # FIX: Check if we are on the app's thread. If so, write directly.
        # Otherwise, use call_from_thread. This is the definitive fix.
        if self.app.is_running and self.app._thread_id == threading.get_ident():
            self._log_widget.write(Text.from_ansi(text.strip()))
        else:
            self.app.call_from_thread(self._log_widget.write, Text.from_ansi(text.strip()))

    def flush(self) -> None:
        """A no-op flush method to satisfy the stream protocol."""
        pass

    def clear(self) -> None:
        """Clear the log."""
        self._log_widget.clear()


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 13: tofusoup/browser/ui/widgets/search_view.py | checksum=5a2c653ff507... | modified=2025-09-17T17:32:12 | op=+ | size=4411 | tokens=990 | type=x-python ###
<<< BOF <<<
#
# tofusoup/browser/ui/widgets/search_view.py
#

from typing import TYPE_CHECKING, ClassVar

from textual.app import ComposeResult
from textual.containers import Vertical
from textual.message import Message
from textual.widgets import DataTable, Input, LoadingIndicator, Static
from textual.widgets._data_table import RowDoesNotExist
from textual.widgets.data_table import RowKey

from tofusoup.registry.search.engine import SearchResult

if TYPE_CHECKING:
    pass


class SearchView(Vertical):
    """A widget combining a search input and a results data table."""

    DEFAULT_CSS = """
    SearchView {
        layout: vertical;
        overflow: hidden;
    }
    #search_input {
        dock: top;
        margin-bottom: 1;
    }
    #results_table {
        height: 1fr;
    }
    #loading_indicator {
        display: none;
        height: auto;
        margin: 1 2;
    }
    """

    class SearchSubmitted(Message):
        def __init__(self, query: str) -> None:
            super().__init__()
            self.query: str = query

    class ResultSelected(Message):
        def __init__(self, result: SearchResult) -> None:
            super().__init__()
            self.result: SearchResult = result

    SORT_KEYS: ClassVar[list[str]] = ["versions", "name"]

    def __init__(self, **kwargs) -> None:
        super().__init__(**kwargs)
        self._results_map: dict[RowKey, SearchResult] = {}

    def compose(self) -> ComposeResult:
        yield Input(placeholder="Search modules and providers...", id="search_input")
        yield LoadingIndicator(id="loading_indicator")
        yield DataTable(id="results_table")

    def on_mount(self) -> None:
        self.query_one(Input).focus()
        table = self.query_one(DataTable)
        table.cursor_type = "row"
        table.add_column("R", key="registry", width=3)
        table.add_column("T", key="type", width=3)
        table.add_column("Name", key="name", width=40)
        table.add_column("Versions", key="versions", width=10)
        table.add_column("Latest", key="latest", width=15)
        table.add_column("Description", key="description", width=None)

    def on_input_submitted(self, event: Input.Submitted) -> None:
        if event.input.id == "search_input":
            self.post_message(self.SearchSubmitted(event.value))

    def on_data_table_row_selected(self, event: DataTable.RowSelected) -> None:
        if event.data_table.id == "results_table" and (result := self._results_map.get(event.row_key)):
            self.post_message(self.ResultSelected(result))

    def add_result(self, result: SearchResult) -> None:
        """Adds a single result to the table or updates an existing one."""
        table = self.query_one(DataTable)
        row_key = RowKey(result.id)

        registry_emoji = (
            "🤝" if result.registry_source == "both" else "🍲" if result.registry_source == "opentofu" else "🏗️"
        )
        type_emoji = "📦" if result.type == "module" else "🔌"
        name = f"{result.namespace}/{result.name}"
        if result.type == "module":
            name += f"/{result.provider_name}"

        total_versions = result.total_versions if result.total_versions is not None else -1

        # FIX: Use the correct `try...except RowDoesNotExist` pattern to check for row existence.
        try:
            table.get_row(row_key)
            # If we get here, the row exists. Update it.
            self._results_map[row_key].registry_source = "both"
            table.update_cell(row_key, "registry", Static("🤝"))
        except RowDoesNotExist:
            # The row does not exist. Add it.
            self._results_map[row_key] = result
            table.add_row(
                Static(registry_emoji),
                Static(type_emoji),
                name,
                total_versions,
                result.latest_version or "N/A",
                result.description or "",
                key=row_key,
            )

        # Re-sort the table after every update
        table.sort(*self.SORT_KEYS, reverse=True)

    def clear_table(self) -> None:
        """Clears all results from the table."""
        self.query_one(DataTable).clear()
        self._results_map.clear()

    def show_loading(self, show: bool) -> None:
        self.query_one(LoadingIndicator).display = show
        self.query_one(DataTable).display = not show


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 14: tofusoup/cli.py | checksum=c3cf05250e86... | modified=2025-09-19T10:08:53 | op=+ | size=4226 | tokens=1064 | type=x-python ###
<<< BOF <<<
#!/usr/bin/env python3
#
# tofusoup/cli.py
#
import os
import pathlib
import sys

import click
from provide.foundation import LoggingConfig, TelemetryConfig, get_hub, logger
from rich import print as rich_print_direct
from rich.tree import Tree

from tofusoup.common.config import TofuSoupConfigError, load_tofusoup_config
from tofusoup.common.lazy_group import LazyGroup
from tofusoup.common.rich_utils import build_rich_tree_from_dict
from tofusoup.config.defaults import DEFAULT_LOG_LEVEL, ENV_TOFUSOUP_LOG_LEVEL, LOG_LEVELS

telemetry_config = TelemetryConfig(
    service_name="tofusoup-cli",
    logging=LoggingConfig(default_level=os.environ.get(ENV_TOFUSOUP_LOG_LEVEL, DEFAULT_LOG_LEVEL).upper()),
)
hub = get_hub()
hub.initialize_foundation(config=telemetry_config)

LAZY_COMMANDS = {
    "sui": ("tofusoup.browser.cli", "sui_cli"),
    "registry": ("tofusoup.registry.cli", "registry_cli"),
    "cty": ("tofusoup.cty.cli", "cty_cli"),
    "hcl": ("tofusoup.hcl.cli", "hcl_cli"),
    "harness": ("tofusoup.harness.cli", "harness_cli"),
    # Package command removed - packaging is handled by separate tools
    "provider": ("tofusoup.provider.cli", "provider_cli"),
    "rpc": ("tofusoup.rpc.cli", "rpc_cli"),
    "state": ("tofusoup.state", "state_cli"),
    "stir": ("tofusoup.stir", "stir_cli"),
    "test": ("tofusoup.testing.cli", "test_cli"),
    "wire": ("tofusoup.wire.cli", "wire"),
    # Note: plating command has been moved to separate plating package
}


@click.group(
    name="tofusoup",
    invoke_without_command=True,
    cls=LazyGroup,
    lazy_commands=LAZY_COMMANDS,
)
@click.pass_context
@click.version_option(package_name="tofusoup")
@click.option("--verbose/--no-verbose", default=False, help="Enable verbose output.")
@click.option(
    "--log-level",
    type=click.Choice(LOG_LEVELS, case_sensitive=False),
    default=None,
    help="Set the logging level.",
)
@click.option(
    "--config-file",
    type=click.Path(exists=True, dir_okay=False, readable=True),
    default=None,
    help="Path to a specific TofuSoup configuration file.",
)
def main_cli(ctx: click.Context, verbose: bool, log_level: str | None, config_file: str | None) -> None:
    ctx.obj = ctx.obj or {}

    final_log_level = "DEBUG" if verbose else log_level
    if final_log_level:
        updated_config = TelemetryConfig(
            service_name="tofusoup-cli",
            logging=LoggingConfig(default_level=final_log_level.upper()),
        )
        setup_telemetry(config=updated_config)
        logger.debug(f"Log level set to {final_log_level.upper()} by CLI option.")

    # Start from current working directory to find project root
    project_root_path = pathlib.Path.cwd()
    while project_root_path != project_root_path.parent:
        if (project_root_path / "pyproject.toml").exists():
            break
        project_root_path = project_root_path.parent
    else:
        raise FileNotFoundError("Could not determine project root containing 'pyproject.toml'.")

    try:
        loaded_config = load_tofusoup_config(project_root_path, explicit_config_file=config_file)
    except TofuSoupConfigError as e:
        logger.error(f"Configuration Error: {e}. Aborting.")
        sys.exit(1)
    ctx.obj["TOFUSOUP_CONFIG"] = loaded_config
    ctx.obj["PROJECT_ROOT"] = project_root_path

    if ctx.invoked_subcommand is None:
        click.echo(ctx.get_help())


@click.group("config")
def config_cli() -> None:
    """Commands for TofuSoup configuration management."""
    pass


@config_cli.command("show")
@click.pass_context
def show_config_command(ctx: click.Context) -> None:
    """Displays the currently loaded TofuSoup configuration."""
    loaded_config = ctx.obj.get("TOFUSOUP_CONFIG", {})
    if not loaded_config:
        rich_print_direct("[yellow]No TofuSoup configuration loaded or configuration is empty.[/yellow]")
        return

    config_tree = Tree("🍲 [bold green]Loaded TofuSoup Configuration[/bold green]")
    build_rich_tree_from_dict(config_tree, loaded_config, "Config Root")
    rich_print_direct(config_tree)


main_cli.add_command(config_cli)


def entry_point() -> None:
    main_cli(obj={})


if __name__ == "__main__":
    entry_point()


# 🍲🥄🖥️🪄
>>> EOF >>>

### FILE 15: tofusoup/common/__init__.py | checksum=215f32d53ed3... | modified=2025-09-17T17:32:12 | op=+ | size=54 | tokens=27 | type=x-python ###
<<< BOF <<<
#
# tofusoup/common/__init__.py
#

# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 16: tofusoup/common/config.py | checksum=cbefc7747f0d... | modified=2025-09-17T17:32:12 | op=+ | size=3630 | tokens=839 | type=x-python ###
<<< BOF <<<
#
# tofusoup/common/config.py
#
"""
Configuration loading and management for TofuSoup.
"""

import pathlib
import tomllib
from typing import Any

from attrs import define
from provide.foundation import logger
from provide.foundation.config import RuntimeConfig, field

from tofusoup.common.exceptions import TofuSoupConfigError
from tofusoup.config.defaults import (
    CONFIG_FILENAME,
    DEFAULT_CONFIG_SUBDIR,
    DEFAULT_LOG_LEVEL,
    ENV_TOFUSOUP_LOG_LEVEL,
    ENV_TOFUSOUP_TEST_TIMEOUT,
    TEST_TIMEOUT_SECONDS,
)


@define
class TofuSoupConfig(RuntimeConfig):
    """Configuration for TofuSoup operations."""

    # File paths and directories
    project_root: pathlib.Path | None = field(default=None, description="Project root directory")
    config_file: str | None = field(default=None, description="Explicit configuration file path")

    # Test configuration
    test_timeout: int = field(
        default=TEST_TIMEOUT_SECONDS, description="Test timeout in seconds", env_var=ENV_TOFUSOUP_TEST_TIMEOUT
    )

    # Logging configuration
    log_level: str = field(
        default=DEFAULT_LOG_LEVEL, description="Logging level", env_var=ENV_TOFUSOUP_LOG_LEVEL
    )

    @classmethod
    def from_project_root(
        cls, project_root: pathlib.Path, explicit_config_file: str | None = None
    ) -> "TofuSoupConfig":
        """Create config using the traditional TofuSoup loading logic."""
        try:
            config_data = load_tofusoup_config(project_root, explicit_config_file)
            return cls.from_dict(config_data)
        except Exception:
            # Fallback to defaults with project info
            return cls(project_root=project_root, config_file=explicit_config_file)


def _load_config_from_file(file_path: pathlib.Path) -> dict[str, Any] | None:
    """
    Attempts to load and parse a TOML configuration file.
    """
    if not file_path.is_file():
        return None

    try:
        logger.info(f"🗣️ Parsing TofuSoup TOML configuration file: {file_path}")
        with open(file_path, "rb") as f:
            config = tomllib.load(f)
        logger.info(f"🗣️ Successfully loaded and parsed TOML configuration from {file_path}")
        return config
    except tomllib.TOMLDecodeError as e:
        raise TofuSoupConfigError(f"Failed to parse TOML configuration file {file_path}: {e}") from e
    except Exception as e:
        raise TofuSoupConfigError(f"Unexpected error processing configuration file {file_path}: {e}") from e


def load_tofusoup_config(
    project_root: pathlib.Path, explicit_config_file: str | None = None
) -> dict[str, Any]:
    """
    Loads the TofuSoup configuration according to a specific precedence.
    """
    # 1. Explicit file path from CLI
    if explicit_config_file:
        exp_path = pathlib.Path(explicit_config_file).resolve()
        if exp_path.is_file():
            return _load_config_from_file(exp_path) or {}
        else:
            raise TofuSoupConfigError(f"Explicitly specified configuration file not found: {exp_path}")

    # 2. Default path: <project_root>/soup/soup.toml
    default_path = project_root / DEFAULT_CONFIG_SUBDIR / CONFIG_FILENAME
    config = _load_config_from_file(default_path)
    if config is not None:
        return config

    # 3. Fallback path for running from project root: <project_root>/soup.toml
    fallback_path = project_root / CONFIG_FILENAME
    config = _load_config_from_file(fallback_path)
    if config is not None:
        return config

    logger.info("No TofuSoup configuration file found. Using empty default configuration.")
    return {}


# 🍲🥄⚙️🪄
>>> EOF >>>

### FILE 17: tofusoup/common/cty_type_parser.py | checksum=2638321e5dff... | modified=2025-09-17T17:32:12 | op=+ | size=3252 | tokens=827 | type=x-python ###
<<< BOF <<<
#
# tofusoup/common/cty_type_parser.py
#
from pyvider.cty import (
    CtyBool,
    CtyDynamic,
    CtyList,
    CtyMap,
    CtyNumber,
    CtyObject,
    CtySet,
    CtyString,
    CtyTuple,
    CtyType,
)
from tofusoup.common.exceptions import TofuSoupError


class CtyTypeParseError(TofuSoupError):
    """Custom exception for CTY type string parsing errors."""

    pass


def _split_by_delimiter_respecting_nesting(text: str, delimiter: str) -> list[str]:
    if not text:
        return []
    parts: list[str] = []
    balance_paren = balance_bracket = balance_brace = 0
    current_part_start = 0
    for i, char in enumerate(text):
        if char == "(":
            balance_paren += 1
        elif char == ")":
            balance_paren -= 1
        elif char == "[":
            balance_bracket += 1
        elif char == "]":
            balance_bracket -= 1
        elif char == "{":
            balance_brace += 1
        elif char == "}":
            balance_brace -= 1
        elif char == delimiter and balance_paren == 0 and balance_bracket == 0 and balance_brace == 0:
            parts.append(text[current_part_start:i].strip())
            current_part_start = i + len(delimiter)
    parts.append(text[current_part_start:].strip())
    return [p for p in parts if p]


def parse_cty_type_string(type_str: str) -> CtyType:
    type_str = type_str.strip()
    if type_str == "string":
        return CtyString()
    if type_str == "number":
        return CtyNumber()
    if type_str == "bool":
        return CtyBool()
    if type_str == "dynamic":
        return CtyDynamic()
    if type_str.startswith("list(") and type_str.endswith(")"):
        return CtyList(element_type=parse_cty_type_string(type_str[len("list(") : -1]))
    if type_str.startswith("set(") and type_str.endswith(")"):
        return CtySet(element_type=parse_cty_type_string(type_str[len("set(") : -1]))
    if type_str.startswith("map(") and type_str.endswith(")"):
        return CtyMap(element_type=parse_cty_type_string(type_str[len("map(") : -1]))
    if type_str.startswith("tuple([") and type_str.endswith("])"):
        element_types_str = type_str[len("tuple([") : -2]
        if not element_types_str:
            return CtyTuple(element_types=())
        element_type_strs = _split_by_delimiter_respecting_nesting(element_types_str, ",")
        return CtyTuple(element_types=tuple(parse_cty_type_string(s.strip()) for s in element_type_strs))
    if type_str.startswith("object({") and type_str.endswith("})"):
        attrs_str = type_str[len("object({") : -2]
        if not attrs_str.strip():
            return CtyObject(attribute_types={})
        attr_pairs_strs = _split_by_delimiter_respecting_nesting(attrs_str, ",")
        attribute_types: dict[str, CtyType] = {}
        for pair_str in attr_pairs_strs:
            if "=" not in pair_str:
                raise CtyTypeParseError(f"Invalid attribute format '{pair_str}'")
            name, type_name_str = pair_str.split("=", 1)
            attribute_types[name.strip()] = parse_cty_type_string(type_name_str.strip())
        return CtyObject(attribute_types=attribute_types)
    raise CtyTypeParseError(f"Unsupported or malformed CTY type string: '{type_str}'")


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 18: tofusoup/common/exceptions.py | checksum=28e336a76dc8... | modified=2025-10-10T12:05:53 | op=+ | size=1593 | tokens=367 | type=x-python ###
<<< BOF <<<
#
# tofusoup/common/exceptions.py
#
"""
Common exceptions for the TofuSoup application.
"""

from provide.foundation.errors import FoundationError, ProcessError


class TofuSoupError(FoundationError):
    """Base class for exceptions in TofuSoup."""

    pass


class ConversionError(TofuSoupError):
    """Custom exception for errors during data conversion (e.g., HCL to JSON, CTY operations)."""

    pass


class TofuSoupConfigError(TofuSoupError):
    """Custom exception for errors related to TofuSoup configuration loading or validation."""

    pass


# Add other general TofuSoup errors here as needed.
# For specific errors like HarnessBuildError, they are defined in their respective modules (e.g., harness/logic.py)
# but could also inherit from TofuSoupError if desired for a common hierarchy.


class HarnessError(ProcessError):
    """Custom exception for errors interacting with external test harness."""

    def __init__(
        self,
        message: str,
        *,
        stderr: str | bytes | None = None,
        stdout: str | bytes | None = None,
        details: str | None = None,
        command: str | list[str] | None = None,
        return_code: int | None = None,
    ) -> None:
        self.details = details

        # Pass to ProcessError which handles stdout/stderr formatting
        super().__init__(
            message,
            command=command,
            return_code=return_code,
            stdout=stdout,
            stderr=stderr,
            harness_details=details,  # Store in context
        )


# <3 🍲 🍜 🍥>


# 🍲🥄⚠️🪄
>>> EOF >>>

### FILE 19: tofusoup/common/lazy_group.py | checksum=0d8386a0ca98... | modified=2025-09-17T17:32:12 | op=+ | size=1576 | tokens=343 | type=x-python ###
<<< BOF <<<
#
# tofusoup/common/lazy_group.py
#
import importlib
from typing import Any

import click


class LazyGroup(click.Group):
    """
    A Click Group that loads its commands lazily from an import string.
    This prevents importing all command dependencies at application startup,
    which is crucial for performance and avoiding unwanted side effects.
    """

    def __init__(
        self,
        *args: Any,
        lazy_commands: dict[str, tuple[str, str]] | None = None,
        **kwargs: Any,
    ) -> None:
        super().__init__(*args, **kwargs)
        self.lazy_commands = lazy_commands or {}

    def list_commands(self, ctx: click.Context) -> list[str]:
        """Lists all commands, including eager and lazy ones."""
        base_commands = super().list_commands(ctx)
        # Combine and remove duplicates, then sort.
        return sorted(list(set(base_commands + list(self.lazy_commands.keys()))))

    def get_command(self, ctx: click.Context, cmd_name: str) -> click.Command | None:
        """
        Gets a command by name. If it's a lazy command, it's imported on-demand.
        """
        if cmd_name in self.lazy_commands:
            try:
                module_path, command_name = self.lazy_commands[cmd_name]
                module = importlib.import_module(module_path)
                return getattr(module, command_name)
            except (ImportError, AttributeError) as e:
                raise click.UsageError(f"Error loading command '{cmd_name}': {e}") from e
        return super().get_command(ctx, cmd_name)


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 20: tofusoup/common/rich_utils.py | checksum=a5aa9dff8bae... | modified=2025-09-17T17:32:12 | op=+ | size=3164 | tokens=769 | type=x-python ###
<<< BOF <<<
#
# tofusoup/common/rich_utils.py
#
"""
Utilities for enhancing CLI output using the Rich library.
"""

import json
from typing import Any

from rich import print as rich_print
from rich.tree import Tree


def build_rich_tree_from_cty_json_comparable(
    tree_node: Tree, data: dict[str, Any], name: str = "value"
) -> None:
    """
    Recursively builds a Rich Tree from a CTY JSON-comparable dictionary.
    """
    label_parts = [f"[bold cyan]{name}[/bold cyan]"]
    type_name = data.get("type_name", "unknown_type")
    value = data.get("value")
    is_null = data.get("is_null", False)
    is_unknown = data.get("is_unknown", False)
    marks = data.get("marks", [])

    label_parts.append(f"([italic green]{type_name}[/italic green])")

    if is_unknown:
        label_parts.append("[bold magenta]unknown[/bold magenta]")
    elif is_null:
        label_parts.append("[dim magenta]null[/dim magenta]")

    if marks:
        label_parts.append(f"marks: {marks}")

    current_branch = tree_node.add(" ".join(label_parts))

    if not is_null and not is_unknown:
        if isinstance(value, list):
            for i, item in enumerate(value):
                if isinstance(item, dict) and "type_name" in item:
                    build_rich_tree_from_cty_json_comparable(current_branch, item, name=f"[{i}]")
                else:
                    current_branch.add(f"[{i}]: [yellow]{item!r}[/yellow]")
        elif isinstance(value, dict):
            for k, v_item in sorted(value.items()):
                if isinstance(v_item, dict) and "type_name" in v_item:
                    build_rich_tree_from_cty_json_comparable(current_branch, v_item, name=str(k))
                else:
                    current_branch.add(f"{k}: [yellow]{v_item!r}[/yellow]")
        else:
            current_branch.add(f"[yellow]{value!r}[/yellow]")


def build_rich_tree_from_dict(tree_node: Tree, data: dict[str, Any], parent_name: str = "Config Root") -> None:
    """
    Recursively builds a Rich Tree from a generic dictionary.
    """
    if not data:
        tree_node.add(f"[dim italic]{parent_name} (empty)[/dim italic]")
        return

    for key, value in sorted(data.items()):
        if isinstance(value, dict):
            branch = tree_node.add(f"[bold blue]{key}[/bold blue]")
            build_rich_tree_from_dict(branch, value, parent_name=key)
        elif isinstance(value, list):
            branch = tree_node.add(f"[bold blue]{key}[/bold blue] ([italic]list[/italic])")
            for i, item in enumerate(value):
                if isinstance(item, dict):
                    item_branch = branch.add(f"Item {i}")
                    build_rich_tree_from_dict(item_branch, item, parent_name=f"Item {i}")
                else:
                    branch.add(f"[green]{item!r}[/green]")
        else:
            tree_node.add(f"[bold blue]{key}[/bold blue]: [green]{value!r}[/green]")


def print_json(data: Any, indent: int = 2) -> None:
    """Print JSON data with syntax highlighting using Rich."""
    json_str = json.dumps(data, indent=indent, ensure_ascii=False)
    rich_print(f"```json\n{json_str}\n```")


# 🍲🥄🛠️🪄
>>> EOF >>>

### FILE 21: tofusoup/common/serialization.py | checksum=1a178ced3558... | modified=2025-09-17T17:32:12 | op=+ | size=4064 | tokens=969 | type=x-python ###
<<< BOF <<<
#
# tofusoup/common/serialization.py
#
"""
Generic serialization and deserialization utilities for JSON and Msgpack.
"""

import decimal  # For loading JSON with Decimal
import json
from typing import Any  # For type hinting

import msgpack

# from lark.exceptions import LarkError # Not used in this generic serialization module
from .exceptions import ConversionError


# --- Generic Loader Functions for Python dicts/lists ---
def load_json_to_python(filepath: str) -> Any:
    """Loads a JSON file and parses it into a Python object (dict, list, etc.)."""
    try:
        with open(filepath, encoding="utf-8") as f:
            data = json.load(f, parse_float=decimal.Decimal, parse_int=decimal.Decimal)
        return data
    except OSError as e:
        raise ConversionError(f"Error reading JSON file {filepath}: {e}") from e
    except json.JSONDecodeError as e:
        raise ConversionError(f"Error decoding JSON file {filepath}: {e}") from e
    except Exception as e:
        raise ConversionError(
            f"Unexpected error loading JSON file {filepath}: {type(e).__name__} - {e}"
        ) from e


def load_msgpack_to_python(filepath: str) -> Any:
    """Loads a Msgpack file and deserializes it into a Python object."""
    try:
        with open(filepath, "rb") as f:
            data = msgpack.unpack(f, raw=False, use_list=True)
        return data
    except OSError as e:
        raise ConversionError(f"Error reading Msgpack file {filepath}: {e}") from e
    except msgpack.UnpackException as e:
        raise ConversionError(f"Error unpacking Msgpack file {filepath}: {e}") from e
    except Exception as e:
        raise ConversionError(
            f"Unexpected error loading Msgpack file {filepath}: {type(e).__name__} - {e}"
        ) from e


# --- Generic Dumper Functions for Python objects ---


def dump_python_to_json_string(data: Any, pretty: bool = True) -> str:
    """Converts a Python object to a JSON formatted string."""
    try:
        if pretty:
            return json.dumps(data, indent=2, ensure_ascii=False)
        else:
            return json.dumps(data, ensure_ascii=False)
    except TypeError as e:
        raise ConversionError(f"Error serializing data to JSON: {e}. Ensure data is JSON serializable.") from e
    except Exception as e:
        raise ConversionError(f"Unexpected error dumping data to JSON string: {type(e).__name__} - {e}") from e


def dump_python_to_msgpack_bytes(data: Any) -> bytes:
    """Serializes a Python object to Msgpack formatted bytes."""
    try:
        return msgpack.packb(data, use_bin_type=True)
    except msgpack.PackException as e:
        raise ConversionError(f"Error packing data to Msgpack: {e}") from e
    except Exception as e:
        raise ConversionError(
            f"Unexpected error dumping data to Msgpack bytes: {type(e).__name__} - {e}"
        ) from e


# --- File I/O Wrappers for Generic Dumpers ---


def dump_python_to_json_file(data: Any, filepath: str, pretty: bool = True) -> None:
    try:
        json_string = dump_python_to_json_string(data, pretty=pretty)
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(json_string)
            if not json_string.endswith("\n"):
                f.write("\n")
    except OSError as e:
        raise ConversionError(f"Error writing JSON to file {filepath}: {e}") from e
    except Exception as e:
        raise ConversionError(
            f"Unexpected error dumping JSON to file {filepath}: {type(e).__name__} - {e}"
        ) from e


def dump_python_to_msgpack_file(data: Any, filepath: str) -> None:
    try:
        msgpack_bytes = dump_python_to_msgpack_bytes(data)
        with open(filepath, "wb") as f:
            f.write(msgpack_bytes)
    except OSError as e:
        raise ConversionError(f"Error writing Msgpack to file {filepath}: {e}") from e
    except Exception as e:
        raise ConversionError(
            f"Unexpected error dumping Msgpack to file {filepath}: {type(e).__name__} - {e}"
        ) from e


# <3 🍲 🍜 🍥>


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 22: tofusoup/common/utils.py | checksum=93e4eba2a1ec... | modified=2025-09-17T17:32:12 | op=+ | size=3122 | tokens=715 | type=x-python ###
<<< BOF <<<
#
# tofusoup/common/utils.py
#
from decimal import Decimal  # Added for DecimalAwareJSONEncoder
import hashlib
import json  # Added for DecimalAwareJSONEncoder
import pathlib
import sys

# import decimal # Redundant as 'Decimal' is imported directly
from typing import Any  # Import Any for type hinting

# Assuming CtyValue might be imported for type hinting, or use 'Any'
# from pyvider.cty import CtyValue # This would create a circular dependency if utils is used by cli and cli uses pyvider.cty's mock setup.
# For now, let's assume we operate on the structure CtyValue.value might return, or use duck typing.


def get_venv_bin_path() -> pathlib.Path:
    """Returns the bin path of the current virtual environment."""
    return pathlib.Path(sys.executable).parent


def calculate_sha256(filepath: pathlib.Path) -> str:
    """Calculates and returns the SHA256 checksum of a file."""
    sha256_hash = hashlib.sha256()
    with open(filepath, "rb") as f:
        # Read and update hash string value in blocks of 4K
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()


# convert_cty_value_to_plain_python was here, now consolidated into tofusoup.cty.logic


class DecimalAwareJSONEncoder(json.JSONEncoder):
    """
    A JSONEncoder that handles decimal.Decimal objects, which are used
    by the CTY type system for numbers but are not native to JSON.
    """

    def default(self, o: Any) -> Any:
        if isinstance(o, Decimal):
            # Convert Decimal to int if it has no fractional part, else to float.
            # Note: Converting to float can lose precision for very large Decimals.
            # For CTY's purposes where it often round-trips from JSON numbers (floats),
            # this is usually acceptable. If exact decimal string representation is needed,
            # this would need to output strings for Decimals.
            if o.as_tuple().exponent >= 0:  # It's an integer
                return int(o)
            else:  # It has a fractional part
                return float(o)
        # Try to import CtyValue carefully to avoid circular dependencies if this util is very core.
        # However, for this specific problem, we need to know if it's a CtyValue.
        try:
            from pyvider.cty import (
                CtyValue,
            )  # Assuming this path is valid in the context

            if isinstance(o, CtyValue):
                # This encoder should not receive raw CtyValues if cty_to_native has done its job.
                raise TypeError(
                    f"TofuSoupDecimalAwareJSONEncoder received unexpected CtyValue: type={o.type!s}, value={o.value!r}"
                )
        except ImportError:
            # If CtyValue can't be imported, this check is skipped.
            # This might happen if common.utils is imported before pyvider.cty is fully available or in a minimal context.
            pass  # Or log a warning that CtyValue type check in encoder is disabled.
        return super().default(o)


# <3 🍲 🍜 🍥>


# 🍲🥄🛠️🪄
>>> EOF >>>

### FILE 23: tofusoup/config/defaults.py | checksum=4632e296e479... | modified=2025-09-17T17:32:12 | op=+ | size=1712 | tokens=454 | type=x-python ###
<<< BOF <<<
#
# config/defaults.py
#
"""
Centralized defaults and constants for TofuSoup.

All hardcoded defaults should be defined here instead of inline in the code.
"""

# Network and connection defaults
DEFAULT_GRPC_PORT = 50051
DEFAULT_GRPC_ADDRESS = "localhost:50051"
CONNECTION_TIMEOUT = 30.0
REQUEST_TIMEOUT = 5.0

# Test configuration
TEST_TIMEOUT_SECONDS = 300
MATRIX_TIMEOUT_MINUTES = 30
MATRIX_PARALLEL_JOBS = 4
STIR_TEST_SECRET = "stir-test-secret"

# Logging
DEFAULT_LOG_LEVEL = "INFO"
LOG_LEVELS = ["NOTSET", "TRACE", "DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]

# Registry configuration
TERRAFORM_REGISTRY_URL = "https://registry.terraform.io"
OPENTOFU_REGISTRY_URL = "https://registry.opentofu.org"

# Cache configuration
CACHE_MAX_SIZE = 100
CACHE_TTL_SECONDS = 3600

# File defaults
DEFAULT_TFSTATE_FILE = "terraform.tfstate"
DEFAULT_OUTPUT_FORMAT = "json"

# CLI defaults
DEFAULT_REGISTRY_SOURCE = "both"
DEFAULT_TLS_MODE = "none"
DEFAULT_CLIENT_LANGUAGE = "python"

# Environment variables
ENV_TOFUSOUP_LOG_LEVEL = "TOFUSOUP_LOG_LEVEL"
ENV_TOFUSOUP_TEST_TIMEOUT = "TOFUSOUP_TEST_TIMEOUT"
ENV_TF_LOG = "TF_LOG"
ENV_TF_DATA_DIR = "TF_DATA_DIR"
ENV_WORKENV_PROFILE = "WORKENV_PROFILE"
ENV_PYVIDER_PRIVATE_STATE_SHARED_SECRET = "PYVIDER_PRIVATE_STATE_SHARED_SECRET"

# GRPC environment variables
ENV_GRPC_DEFAULT_CLIENT_CERTIFICATE_PATH = "GRPC_DEFAULT_CLIENT_CERTIFICATE_PATH"
ENV_GRPC_DEFAULT_CLIENT_PRIVATE_KEY_PATH = "GRPC_DEFAULT_CLIENT_PRIVATE_KEY_PATH"
ENV_GRPC_DEFAULT_SSL_ROOTS_FILE_PATH = "GRPC_DEFAULT_SSL_ROOTS_FILE_PATH"

# TUI configuration
TUI_SERVICE_NAME = "tofusoup-tui"
TUI_LOG_LEVEL = "DEBUG"

# Soup configuration paths
CONFIG_FILENAME = "soup.toml"
DEFAULT_CONFIG_SUBDIR = "soup"
>>> EOF >>>

### FILE 24: tofusoup/cty/__init__.py | checksum=0a5c6c22d646... | modified=2025-09-17T17:32:12 | op=+ | size=51 | tokens=29 | type=x-python ###
<<< BOF <<<
#
# tofusoup/cty/__init__.py
#

# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 25: tofusoup/cty/cli.py | checksum=7abc78a46eca... | modified=2025-09-17T17:32:12 | op=+ | size=5796 | tokens=1367 | type=x-python ###
<<< BOF <<<
#!/usr/bin/env python3
#
# tofusoup/cty/cli.py
#
import json
from pathlib import Path
import sys
from typing import TextIO

import click

from pyvider.cty import (
    CtyDynamic,
    parse_tf_type_to_ctytype,
)
from pyvider.cty.codec import cty_from_msgpack, cty_to_msgpack
from pyvider.cty.conversion import encode_cty_type_to_wire_json

from ..common.rich_utils import print_json


@click.group("cty")
def cty_cli() -> None:
    """Commands for working with cty values."""
    pass


@cty_cli.command("view")
@click.argument("input_file", type=click.File("rb"))
@click.option(
    "--input-format",
    type=click.Choice(["json", "msgpack"]),
    default="json",
    help="Format of the input file.",
)
@click.option("--type", "type_spec", help="CTY type specification (JSON format).")
def view_command(input_file: TextIO, input_format: str, type_spec: str) -> None:
    """View CTY data in a human-readable format."""
    try:
        data = input_file.read()

        if type_spec:
            # Parse the type specification - Go expects JSON format
            # So we need to parse it the same way: as JSON bytes
            type_data = json.loads(type_spec) if type_spec.startswith('"') else type_spec
            cty_type = parse_tf_type_to_ctytype(type_data)
        else:
            # Try to infer type from JSON structure
            if input_format == "json":
                json_data = json.loads(data.decode())
                # For now, use dynamic type - could be improved with type inference
                cty_type = CtyDynamic()
            else:
                click.echo("--type is required for MessagePack input", err=True)
                sys.exit(1)

        # Deserialize the value
        if input_format == "json":
            # For JSON, we need to parse and validate the JSON as a CTY value
            json_data = json.loads(data.decode())
            cty_value = cty_type.validate(json_data)
        else:  # msgpack
            cty_value = cty_from_msgpack(data, cty_type)

        # Display the value in a readable format
        output = {
            "type": encode_cty_type_to_wire_json(cty_value.type),
            "value": cty_value.value if not cty_value.is_unknown else "<unknown>",
            "is_null": cty_value.is_null,
            "is_unknown": cty_value.is_unknown,
            "marks": list(str(mark) for mark in cty_value.marks) if cty_value.marks else [],
        }

        print_json(output)

    except Exception as e:
        click.echo(f"Error viewing CTY data: {e}", err=True)
        sys.exit(1)


@cty_cli.command("convert")
@click.argument("input_file", type=click.File("rb"))
@click.argument("output_file", type=click.Path())
@click.option(
    "--input-format",
    type=click.Choice(["json", "msgpack"]),
    default="json",
    help="Format of the input file.",
)
@click.option(
    "--output-format",
    type=click.Choice(["json", "msgpack"]),
    default="json",
    help="Format for the output file.",
)
@click.option("--type", "type_spec", required=True, help="CTY type specification (JSON format).")
def convert_command(
    input_file: TextIO,
    output_file: str,
    input_format: str,
    output_format: str,
    type_spec: str,
) -> None:
    """Convert CTY data between JSON and MessagePack formats."""
    try:
        # Parse input data
        data = input_file.read()
        # Parse type spec the same way Go does - as JSON bytes
        type_data = json.loads(type_spec) if type_spec.startswith('"') else type_spec
        cty_type = parse_tf_type_to_ctytype(type_data)

        # Deserialize based on input format
        if input_format == "json":
            json_data = json.loads(data.decode())
            cty_value = cty_type.validate(json_data)
        else:  # msgpack
            cty_value = cty_from_msgpack(data, cty_type)

        # Serialize to output format
        if output_format == "json":
            output_data = json.dumps(cty_value.value, indent=2)
            mode = "w"
        else:  # msgpack
            output_data = cty_to_msgpack(cty_value, cty_type)
            mode = "wb"

        # Write output file
        output_path = Path(output_file)
        if mode == "w":
            output_path.write_text(output_data)
        else:
            output_path.write_bytes(output_data)

        click.echo(f"Converted {input_format} to {output_format}: {output_file}")

    except Exception as e:
        click.echo(f"Error converting CTY data: {e}", err=True)
        sys.exit(1)


@cty_cli.command("validate-value")
@click.argument("value")
@click.option("--type", "type_spec", required=True, help="CTY type specification (JSON format).")
def validate_value_command(value: str, type_spec: str) -> None:
    """Validate a CTY value against a type specification."""
    try:
        # Parse the type specification the same way Go does - as JSON bytes
        type_data = json.loads(type_spec) if type_spec.startswith('"') else type_spec
        cty_type = parse_tf_type_to_ctytype(type_data)

        # Parse and validate the value
        json_value = json.loads(value)
        cty_value = cty_type.validate(json_value)

        # If we get here without exception, validation succeeded
        click.echo("✅ Value validates successfully against the type")

        # Show some details about the validated value
        details = {
            "parsed_value": cty_value.value if not cty_value.is_unknown else "<unknown>",
            "is_null": cty_value.is_null,
            "is_unknown": cty_value.is_unknown,
        }

        if click.get_current_context().obj and click.get_current_context().obj.get("verbose"):
            print_json(details)

    except Exception as e:
        click.echo(f"❌ Validation failed: {e}", err=True)
        sys.exit(1)


# 🍲🥄🖥️🪄
>>> EOF >>>

### FILE 26: tofusoup/cty/logic.py | checksum=fb065cce0942... | modified=2025-09-17T17:32:12 | op=+ | size=4432 | tokens=1128 | type=x-python ###
<<< BOF <<<
#
# tofusoup/cty/logic.py
#
import pathlib
from typing import Any

from tofusoup.common.exceptions import ConversionError
from tofusoup.common.serialization import (
    dump_python_to_json_string,
    dump_python_to_msgpack_bytes,
    load_json_to_python,
    load_msgpack_to_python,
)

# Optional CTY integration
try:
    from pyvider.cty import CtyType, CtyValue
    from pyvider.cty.conversion import cty_to_native, infer_cty_type_from_raw

    HAS_CTY = True
except ImportError:
    HAS_CTY = False
    CtyType = None
    CtyValue = None

# Optional HCL integration
try:
    from pyvider.hcl import HclError, parse_hcl_to_cty

    HAS_HCL = True
except ImportError:
    HAS_HCL = False
    HclError = Exception


def format_cty_type_friendly_name(ty: CtyType) -> str:
    """Provides a string representation of a CtyType."""
    if not HAS_CTY:
        raise ImportError("CTY support requires 'pip install tofusoup[cty]'")
    return str(ty)


def cty_value_to_json_comparable_dict(val: CtyValue) -> dict[str, Any]:
    """Converts a CtyValue to a JSON-comparable dict for Rich tree rendering."""
    if not HAS_CTY:
        raise ImportError("CTY support requires 'pip install tofusoup[cty]'")
    # FIX: Call is_unknown() and is_null() as methods.
    if val.is_unknown():
        return {
            "type_name": format_cty_type_friendly_name(val.vtype),
            "value": None,
            "is_unknown": True,
            "is_null": False,
            "marks": sorted(list(val.marks)),
        }
    if val.is_null():
        return {
            "type_name": format_cty_type_friendly_name(val.vtype),
            "value": None,
            "is_unknown": False,
            "is_null": True,
            "marks": sorted(list(val.marks)),
        }

    native_value = cty_to_native(val)
    processed_value: Any
    if isinstance(native_value, list):
        processed_value = [cty_value_to_json_comparable_dict(v) for v in val.value]
    elif isinstance(native_value, set):
        processed_value = [
            cty_value_to_json_comparable_dict(v) for v in sorted(list(val.value), key=lambda x: str(x))
        ]
    elif isinstance(native_value, dict):
        processed_value = {k: cty_value_to_json_comparable_dict(v) for k, v in sorted(val.value.items())}
    else:
        processed_value = native_value

    return {
        "type_name": format_cty_type_friendly_name(val.vtype),
        "value": processed_value,
        "is_unknown": False,
        "is_null": False,
        "marks": sorted(list(val.marks)),
    }


def load_cty_file_to_cty_value(filepath: str, file_format: str) -> CtyValue:
    """Loads a data file (JSON, Msgpack, HCL) and converts it to a CtyValue."""
    if not HAS_CTY:
        raise ImportError("CTY support requires 'pip install tofusoup[cty]'")

    if file_format == "hcl":
        if not HAS_HCL:
            raise ImportError("HCL support requires 'pip install tofusoup[hcl]'")
        try:
            hcl_content = pathlib.Path(filepath).read_text(encoding="utf-8")
            return parse_hcl_to_cty(hcl_content)
        except (HclError, FileNotFoundError) as e:
            raise ConversionError(f"Failed to process HCL file '{filepath}': {e}") from e

    raw_data: Any
    if file_format == "json":
        raw_data = load_json_to_python(filepath)
    elif file_format == "msgpack":
        raw_data = load_msgpack_to_python(filepath)
    else:
        raise ConversionError(f"Unsupported file format for CTY loading: {file_format}")

    try:
        inferred_type = infer_cty_type_from_raw(raw_data)
        cty_value = inferred_type.validate(raw_data)
        return cty_value
    except Exception as e:
        raise ConversionError(f"Failed to convert raw data from '{filepath}' to CTY: {e}") from e


def dump_cty_value_to_json_string(value: CtyValue, pretty: bool = True) -> str:
    """Converts a CtyValue to a JSON string."""
    if not HAS_CTY:
        raise ImportError("CTY support requires 'pip install tofusoup[cty]'")
    native_value = cty_to_native(value)
    return dump_python_to_json_string(native_value, pretty=pretty)


def dump_cty_value_to_msgpack_bytes(value: CtyValue) -> bytes:
    """Converts a CtyValue to MessagePack bytes."""
    if not HAS_CTY:
        raise ImportError("CTY support requires 'pip install tofusoup[cty]'")
    native_value = cty_to_native(value)
    return dump_python_to_msgpack_bytes(native_value)


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 27: tofusoup/harness/__init__.py | checksum=44977e1f66b8... | modified=2025-09-17T17:32:12 | op=+ | size=55 | tokens=28 | type=x-python ###
<<< BOF <<<
#
# tofusoup/harness/__init__.py
#

# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 28: tofusoup/harness/cli.py | checksum=54787d766956... | modified=2025-09-17T17:32:12 | op=+ | size=4200 | tokens=989 | type=x-python ###
<<< BOF <<<
#!/usr/bin/env python3
#
# tofusoup/harness/cli.py
#
import os
import sys

import click
from provide.foundation import logger
from rich import print as rich_print
from rich.table import Table

from tofusoup.common.exceptions import TofuSoupError

from .logic import (
    GO_HARNESS_CONFIG,
    GoVersionError,
    HarnessBuildError,
    ensure_go_harness_build,
)


@click.group("harness")
def harness_cli() -> None:
    """Commands to build, list, and clean test harnesses."""
    pass


@harness_cli.command("clean")
@click.argument("harness_names", nargs=-1)
@click.option("--all", "clean_all", is_flag=True, help="Clean all harnesses.")
@click.pass_context
def clean_harness_command(ctx, harness_names: tuple[str, ...], clean_all: bool) -> None:
    """Cleans (removes) specified test harnesses."""
    project_root = ctx.obj["PROJECT_ROOT"]
    harness_bin_dir = project_root / "src" / "tofusoup" / "harness" / "go" / "bin"

    names_to_clean = []
    if clean_all:
        names_to_clean = list(GO_HARNESS_CONFIG.keys())
    elif harness_names:
        names_to_clean = list(harness_names)
    else:
        rich_print("[yellow]Please specify harness names to clean or use --all.[/yellow]")
        return

    rich_print(f"[bold yellow]Cleaning harnesses: {', '.join(names_to_clean)}[/bold yellow]")
    for name in names_to_clean:
        if name in GO_HARNESS_CONFIG:
            output_name = GO_HARNESS_CONFIG[name]["output_name"]
            harness_path = harness_bin_dir / output_name
            if harness_path.exists():
                try:
                    os.remove(harness_path)
                    rich_print(
                        f"[green]Removed harness '{name}': {harness_path.relative_to(project_root)}[/green]"
                    )
                except OSError as e:
                    logger.error(f"Failed to remove harness '{name}': {e}")
                    sys.exit(1)
            else:
                rich_print(
                    f"[yellow]Harness '{name}' not found at {harness_path.relative_to(project_root)}. Skipping.[/yellow]"
                )
        else:
            logger.warning(f"Unknown harness: '{name}'. Skipping.")


@harness_cli.command("list")
@click.pass_context
def list_harnesses_command(ctx) -> None:
    """Lists all available harnesses and their status."""
    project_root = ctx.obj["PROJECT_ROOT"]
    table = Table(title="Go Harnesses")
    table.add_column("Name", style="magenta")
    table.add_column("Output Path", style="yellow")
    table.add_column("Status", style="cyan")
    harness_bin_dir = project_root / "harnesses" / "bin"
    for name, config in GO_HARNESS_CONFIG.items():
        output_path = harness_bin_dir / config["output_name"]
        status = "[red]Not Built[/red]"
        if output_path.exists() and os.access(output_path, os.X_OK):
            status = "[green]Built[/green]"
        table.add_row(name, str(output_path.relative_to(project_root)), status)
    rich_print(table)


@harness_cli.command("build")
@click.argument("harness_names", nargs=-1)
@click.option(
    "--force-rebuild",
    is_flag=True,
    help="Force rebuild even if the harness already exists.",
)
@click.option("--log-level", default="info", help="Set the logging level for the harness build.")
@click.pass_context
def build_harness_command(ctx, harness_names: tuple[str, ...], force_rebuild: bool, log_level: str) -> None:
    """Builds specified test harnesses."""
    project_root = ctx.obj["PROJECT_ROOT"]
    loaded_config = ctx.obj.get("TOFUSOUP_CONFIG", {})
    names_to_build = list(harness_names) or list(GO_HARNESS_CONFIG.keys())

    rich_print(f"[bold cyan]Building harness: {', '.join(names_to_build)}[/bold cyan]")
    for name in names_to_build:
        try:
            executable_path = ensure_go_harness_build(name, project_root, loaded_config, force_rebuild)
            rich_print(
                f"[green]Go harness '{name}' is available at:[/green] {executable_path.relative_to(project_root)}"
            )
        except (GoVersionError, HarnessBuildError, TofuSoupError) as e:
            logger.error(f"Failed to build Go harness '{name}': {e}")
            sys.exit(1)


# 🍲🥄🖥️🪄
>>> EOF >>>

### FILE 29: tofusoup/harness/go/Makefile | checksum=915cc383564c... | modified=2025-09-11T18:05:26 | op=+ | size=2160 | tokens=691 | type=plain ###
<<< BOF <<<
# Makefile for TofuSoup Go Harnesses
# Builds test harnesses for conformance testing

.PHONY: all clean build soup-go go-cty go-hcl go-wire go-rpc help

# Configuration
PROJECT_ROOT ?= $(shell cd ../../../.. && pwd)
BIN_DIR ?= $(PROJECT_ROOT)/bin
BUILD_FLAGS ?= -v
GO ?= go

# Default target
all: build

# Build all harnesses
build: soup-go

# Build soup-go harness
soup-go:
	@echo "🔨 Building soup-go harness..."
	@mkdir -p $(BIN_DIR)
	@cd soup-go && $(GO) build $(BUILD_FLAGS) -o $(BIN_DIR)/soup-go .
	@echo "✅ soup-go built to $(BIN_DIR)/soup-go"

# Build go-cty harness (placeholder)
go-cty:
	@echo "🔨 Building go-cty harness..."
	@mkdir -p $(BIN_DIR)
	@echo "⚠️  go-cty not yet implemented"

# Build go-hcl harness (placeholder)
go-hcl:
	@echo "🔨 Building go-hcl harness..."
	@mkdir -p $(BIN_DIR)
	@echo "⚠️  go-hcl not yet implemented"

# Build go-wire harness (placeholder)
go-wire:
	@echo "🔨 Building go-wire harness..."
	@mkdir -p $(BIN_DIR)
	@echo "⚠️  go-wire not yet implemented"

# Build go-rpc harness (use existing)
go-rpc:
	@echo "🔨 go-rpc binary already exists at $(BIN_DIR)/go-rpc"

# Clean built binaries
clean:
	@echo "🧹 Cleaning harness binaries..."
	@rm -f $(BIN_DIR)/soup-go
	@rm -f $(BIN_DIR)/go-cty
	@rm -f $(BIN_DIR)/go-hcl
	@rm -f $(BIN_DIR)/go-wire
	@echo "✅ Harness binaries cleaned"

# Show help
help:
	@echo "TofuSoup Go Harnesses - Makefile"
	@echo ""
	@echo "Usage: make [target]"
	@echo ""
	@echo "Targets:"
	@echo "  all       Build all harnesses (default)"
	@echo "  build     Build all harnesses"
	@echo "  soup-go   Build soup-go harness"
	@echo "  go-cty    Build go-cty harness"
	@echo "  go-hcl    Build go-hcl harness"
	@echo "  go-wire   Build go-wire harness"
	@echo "  go-rpc    Build go-rpc harness"
	@echo "  clean     Remove built binaries"
	@echo "  help      Show this help message"
	@echo ""
	@echo "Environment variables:"
	@echo "  PROJECT_ROOT  Project root directory (auto-detected)"
	@echo "  BIN_DIR       Output directory for binaries (default: PROJECT_ROOT/bin)"
	@echo "  BUILD_FLAGS   Go build flags (default: -v)"
	@echo "  GO            Go compiler (default: go)"
>>> EOF >>>

### FILE 30: tofusoup/harness/go/go.sum | checksum=d397851acce0... | modified=2025-09-12T08:08:17 | op=+ | size=4055 | tokens=2309 ###
<<< BOF <<<
github.com/cpuguy83/go-md2man/v2 v2.0.3/go.mod h1:tgQtvFlXSQOSOSIRvRPT7W67SCa46tRHOmNcaadrF8o=
github.com/cpuguy83/go-md2man/v2 v2.0.4/go.mod h1:tgQtvFlXSQOSOSIRvRPT7W67SCa46tRHOmNcaadrF8o=
github.com/cpuguy83/go-md2man/v2 v2.0.6/go.mod h1:oOW0eioCTA6cOiMLiUPZOpcVxMig6NIQQ7OS05n1F4g=
github.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
github.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
github.com/fatih/color v1.13.0/go.mod h1:kLAiJbzzSOZDVNGyDpeOxJ47H46qBXwg5ILebYFFOfk=
github.com/fatih/color v1.17.0 h1:GlRw1BRJxkpqUCBKzKOw098ed57fEsKeNjpTe3cSjK4=
github.com/fatih/color v1.17.0/go.mod h1:YZ7TlrGPkiz6ku9fK3TLD/pl3CpsiFyu8N92HLgmosI=
github.com/hashicorp/go-hclog v1.6.3 h1:Qr2kF+eVWjTiYmU7Y31tYlP1h0q/X3Nl3tPGdaB11/k=
github.com/hashicorp/go-hclog v1.6.3/go.mod h1:W4Qnvbt70Wk/zYJryRzDRU/4r0kIg0PVHBcfoyhpF5M=
github.com/inconshreveable/mousetrap v1.1.0 h1:wN+x4NVGpMsO7ErUn/mUI3vEoE6Jt13X2s0bqwp9tc8=
github.com/inconshreveable/mousetrap v1.1.0/go.mod h1:vpF70FUmC8bwa3OWnCshd2FqLfsEA9PFc4w1p2J65bw=
github.com/mattn/go-colorable v0.1.9/go.mod h1:u6P/XSegPjTcexA+o6vUJrdnUu04hMope9wVRipJSqc=
github.com/mattn/go-colorable v0.1.12/go.mod h1:u5H1YNBxpqRaxsYJYSkiCWKzEfiAb1Gb520KVy5xxl4=
github.com/mattn/go-colorable v0.1.13 h1:fFA4WZxdEF4tXPZVKMLwD8oUnCTTo08duU7wxecdEvA=
github.com/mattn/go-colorable v0.1.13/go.mod h1:7S9/ev0klgBDR4GtXTXX8a3vIGJpMovkB8vQcUbaXHg=
github.com/mattn/go-isatty v0.0.12/go.mod h1:cbi8OIDigv2wuxKPP5vlRcQ1OAZbq2CE4Kysco4FUpU=
github.com/mattn/go-isatty v0.0.14/go.mod h1:7GGIvUiUoEMVVmxf/4nioHXj79iQHKdU27kJ6hsGG94=
github.com/mattn/go-isatty v0.0.16/go.mod h1:kYGgaQfpe5nmfYZH+SKPsOc2e4SrIfOl2e/yFXSvRLM=
github.com/mattn/go-isatty v0.0.20 h1:xfD0iDuEKnDkl03q4limB+vH+GxLEtL/jb4xVJSWWEY=
github.com/mattn/go-isatty v0.0.20/go.mod h1:W+V8PltTTMOvKvAeJH7IuucS94S2C6jfK/D7dTCTo3Y=
github.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=
github.com/russross/blackfriday/v2 v2.1.0/go.mod h1:+Rmxgy9KzJVeS9/2gXHxylqXiyQDYRxCVz55jmeOWTM=
github.com/spf13/cobra v1.8.0 h1:7aJaZx1B85qltLMc546zn58BxxfZdR/W22ej9CFoEf0=
github.com/spf13/cobra v1.8.0/go.mod h1:WXLWApfZ71AjXPya3WOlMsY9yMs7YeiHhFVlvLyhcho=
github.com/spf13/cobra v1.8.1/go.mod h1:wHxEcudfqmLYa8iTfL+OuZPbBZkmvliBWKIezN3kD9Y=
github.com/spf13/cobra v1.10.1 h1:lJeBwCfmrnXthfAupyUTzJ/J4Nc1RsHC/mSRU2dll/s=
github.com/spf13/cobra v1.10.1/go.mod h1:7SmJGaTHFVBY0jW4NXGluQoLvhqFQM+6XSKD+P4XaB0=
github.com/spf13/pflag v1.0.5 h1:iy+VFUOCP1a+8yFto/drg2CJ5u0yRoB7fZw3DKv/JXA=
github.com/spf13/pflag v1.0.5/go.mod h1:McXfInJRrz4CZXVZOBLb0bTZqETkiAhM9Iw0y3An2Bg=
github.com/spf13/pflag v1.0.9 h1:9exaQaMOCwffKiiiYk6/BndUBv+iRViNW+4lEMi0PvY=
github.com/spf13/pflag v1.0.9/go.mod h1:McXfInJRrz4CZXVZOBLb0bTZqETkiAhM9Iw0y3An2Bg=
github.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=
github.com/stretchr/testify v1.7.2/go.mod h1:R6va5+xMeoiuVRoj+gSkQ7d3FALtqAAGI1FQKckRals=
golang.org/x/sys v0.0.0-20200116001909-b77594299b42/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200223170610-d5e6a3e2c0ae/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20210630005230-0f9fa26af87c/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20210927094055-39ccf1dd6fa6/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220503163025-988cb79eb6c6/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220811171246-fbc7d0a398ab/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.27.0 h1:wBqf8DvsY9Y/2P8gAfPDEYNuS30J4lPHJxXSb/nJZ+s=
golang.org/x/sys v0.27.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=
gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=
gopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=
>>> EOF >>>

### FILE 31: tofusoup/harness/go/soup-go/cty.go | checksum=c98be1b94ff5... | modified=2025-09-12T09:09:42 | op=+ | size=11065 | tokens=3211 | type=x-go ###
<<< BOF <<<
package main

import (
	"encoding/json"
	"fmt"
	"io"
	"math/big"
	"os"
	"strings"

	"github.com/spf13/cobra"
	"github.com/zclconf/go-cty/cty"
	ctyjson "github.com/zclconf/go-cty/cty/json"
	"github.com/zclconf/go-cty/cty/msgpack"
)

// CTY command flags
var (
	ctyInputFormat  string
	ctyOutputFormat string
	ctyTypeJSON     string
)

// Override the convert command with real implementation
func initCtyConvertCmd() *cobra.Command {
	cmd := &cobra.Command{
		Use:   "convert [input] [output]",
		Short: "Convert CTY values between formats",
		Args:  cobra.ExactArgs(2),
		RunE: func(cmd *cobra.Command, args []string) error {
			inputPath := args[0]
			outputPath := args[1]

			// Parse the type specification
			ctyType, err := parseCtyType(json.RawMessage(ctyTypeJSON))
			if err != nil {
				return fmt.Errorf("failed to parse type: %w", err)
			}

			// Read input
			var inputData []byte
			if inputPath == "-" {
				inputData, err = io.ReadAll(os.Stdin)
				if err != nil {
					return fmt.Errorf("failed to read stdin: %w", err)
				}
			} else {
				inputData, err = os.ReadFile(inputPath)
				if err != nil {
					return fmt.Errorf("failed to read input file: %w", err)
				}
			}

			// Convert based on formats
			var value cty.Value
			switch ctyInputFormat {
			case "json":
				value, err = buildCtyValueFromJSON(ctyType, inputData)
				if err != nil {
					return fmt.Errorf("failed to parse JSON input: %w", err)
				}
			case "msgpack":
				value, err = msgpack.Unmarshal(inputData, ctyType)
				if err != nil {
					return fmt.Errorf("failed to unmarshal msgpack: %w", err)
				}
			default:
				return fmt.Errorf("unsupported input format: %s", ctyInputFormat)
			}

			// Marshal to output format
			var outputData []byte
			switch ctyOutputFormat {
			case "json":
				outputData, err = ctyjson.Marshal(value, ctyType)
				if err != nil {
					return fmt.Errorf("failed to marshal to JSON: %w", err)
				}
			case "msgpack":
				outputData, err = msgpack.Marshal(value, ctyType)
				if err != nil {
					return fmt.Errorf("failed to marshal to msgpack: %w", err)
				}
			default:
				return fmt.Errorf("unsupported output format: %s", ctyOutputFormat)
			}

			// Write output
			if outputPath == "-" {
				_, err = os.Stdout.Write(outputData)
			} else {
				err = os.WriteFile(outputPath, outputData, 0644)
			}
			if err != nil {
				return fmt.Errorf("failed to write output: %w", err)
			}

			return nil
		},
	}
	
	// Add flags
	cmd.Flags().StringVar(&ctyInputFormat, "input-format", "json", "Input format (json, msgpack)")
	cmd.Flags().StringVar(&ctyOutputFormat, "output-format", "json", "Output format (json, msgpack)")
	cmd.Flags().StringVar(&ctyTypeJSON, "type", "", "CTY type specification as JSON")
	cmd.MarkFlagRequired("type")
	
	return cmd
}

// Override the validate command with real implementation
func initCtyValidateCmd() *cobra.Command {
	cmd := &cobra.Command{
		Use:   "validate-value [value]",
		Short: "Validate a CTY value",
		Args:  cobra.ExactArgs(1),
		RunE: func(cmd *cobra.Command, args []string) error {
			valueJSON := args[0]

			// Parse the type specification
			ctyType, err := parseCtyType(json.RawMessage(ctyTypeJSON))
			if err != nil {
				return fmt.Errorf("failed to parse type: %w", err)
			}

			// Build and validate the value
			_, err = buildCtyValueFromJSON(ctyType, []byte(valueJSON))
			if err != nil {
				return fmt.Errorf("validation failed: %w", err)
			}

			fmt.Println("Validation Succeeded")
			return nil
		},
	}
	
	// Add flags
	cmd.Flags().StringVar(&ctyTypeJSON, "type", "", "CTY type specification as JSON")
	cmd.MarkFlagRequired("type")
	
	return cmd
}

// parseCtyType parses a JSON type specification into a cty.Type
func parseCtyType(data json.RawMessage) (cty.Type, error) {
	var typeStr string
	if err := json.Unmarshal(data, &typeStr); err == nil {
		switch typeStr {
		case "string":
			return cty.String, nil
		case "number":
			return cty.Number, nil
		case "bool":
			return cty.Bool, nil
		case "dynamic":
			return cty.DynamicPseudoType, nil
		default:
			return cty.NilType, fmt.Errorf("unknown primitive type string: %s", typeStr)
		}
	}

	var typeList []json.RawMessage
	if err := json.Unmarshal(data, &typeList); err == nil {
		if len(typeList) < 2 {
			return cty.NilType, fmt.Errorf("type array must have at least 2 elements")
		}
		var typeKind string
		if err := json.Unmarshal(typeList[0], &typeKind); err != nil {
			return cty.NilType, err
		}

		switch typeKind {
		case "list", "set", "map":
			elemType, err := parseCtyType(typeList[1])
			if err != nil {
				return cty.NilType, err
			}
			if typeKind == "list" {
				return cty.List(elemType), nil
			}
			if typeKind == "set" {
				return cty.Set(elemType), nil
			}
			return cty.Map(elemType), nil
		case "object":
			var attrTypesRaw map[string]json.RawMessage
			if err := json.Unmarshal(typeList[1], &attrTypesRaw); err != nil {
				return cty.NilType, err
			}
			attrTypes := make(map[string]cty.Type)
			for name, rawType := range attrTypesRaw {
				attrType, err := parseCtyType(rawType)
				if err != nil {
					return cty.NilType, err
				}
				attrTypes[name] = attrType
			}
			if len(typeList) > 2 {
				var optionals []string
				if err := json.Unmarshal(typeList[2], &optionals); err != nil {
					return cty.NilType, err
				}
				return cty.ObjectWithOptionalAttrs(attrTypes, optionals), nil
			}
			return cty.Object(attrTypes), nil
		case "tuple":
			var elemTypesRaw []json.RawMessage
			if err := json.Unmarshal(typeList[1], &elemTypesRaw); err != nil {
				return cty.NilType, err
			}
			elemTypes := make([]cty.Type, len(elemTypesRaw))
			for i, rawType := range elemTypesRaw {
				elemType, err := parseCtyType(rawType)
				if err != nil {
					return cty.NilType, err
				}
				elemTypes[i] = elemType
			}
			return cty.Tuple(elemTypes), nil
		default:
			return cty.NilType, fmt.Errorf("unknown complex type kind: %s", typeKind)
		}
	}
	return cty.NilType, fmt.Errorf("invalid type specification format")
}

// buildCtyValueFromJSON builds a cty.Value from JSON data with the given type
func buildCtyValueFromJSON(ty cty.Type, data []byte) (cty.Value, error) {
	// Handle simple JSON unmarshaling for basic types
	if ty == cty.DynamicPseudoType {
		// For dynamic types, infer the type from the JSON
		inferredType, err := ctyjson.ImpliedType(data)
		if err != nil {
			return cty.NilVal, err
		}
		return ctyjson.Unmarshal(data, inferredType)
	}

	// Parse the JSON to handle special cases
	var rawValue interface{}
	if err := json.Unmarshal(data, &rawValue); err != nil {
		return cty.NilVal, err
	}

	return buildValueFromInterface(ty, rawValue, []string{})
}

// buildValueFromInterface recursively builds a cty.Value from an interface{}
func buildValueFromInterface(ty cty.Type, val interface{}, path []string) (cty.Value, error) {
	if val == nil {
		return cty.NullVal(ty), nil
	}

	// Note: go-cty does NOT support unknown values in JSON format
	// Unknown values can only be properly represented in MessagePack
	// Attempting to marshal an unknown value to JSON will result in an error:
	// "value is not known"
	// This matches Terraform's behavior exactly

	// Handle primitive types
	switch ty {
	case cty.String:
		if s, ok := val.(string); ok {
			return cty.StringVal(s), nil
		}
		return cty.NilVal, fmt.Errorf("expected string at %s", strings.Join(path, "."))
	case cty.Number:
		switch v := val.(type) {
		case float64:
			return cty.NumberFloatVal(v), nil
		case int:
			return cty.NumberIntVal(int64(v)), nil
		case int64:
			return cty.NumberIntVal(v), nil
		case string:
			bf := new(big.Float)
			if _, ok := bf.SetString(v); ok {
				return cty.NumberVal(bf), nil
			}
			return cty.NilVal, fmt.Errorf("invalid number string at %s", strings.Join(path, "."))
		}
		return cty.NilVal, fmt.Errorf("expected number at %s", strings.Join(path, "."))
	case cty.Bool:
		if b, ok := val.(bool); ok {
			return cty.BoolVal(b), nil
		}
		return cty.NilVal, fmt.Errorf("expected bool at %s", strings.Join(path, "."))
	}

	// Handle collection types
	if ty.IsListType() || ty.IsSetType() || ty.IsTupleType() {
		slice, ok := val.([]interface{})
		if !ok {
			return cty.NilVal, fmt.Errorf("expected array at %s", strings.Join(path, "."))
		}

		vals := make([]cty.Value, len(slice))
		for i, elem := range slice {
			var elemTy cty.Type
			if ty.IsTupleType() {
				elemTy = ty.TupleElementType(i)
			} else {
				elemTy = ty.ElementType()
			}
			elemVal, err := buildValueFromInterface(elemTy, elem, append(path, fmt.Sprintf("[%d]", i)))
			if err != nil {
				return cty.NilVal, err
			}
			vals[i] = elemVal
		}

		if ty.IsListType() {
			return cty.ListVal(vals), nil
		}
		if ty.IsSetType() {
			return cty.SetVal(vals), nil
		}
		return cty.TupleVal(vals), nil
	}

	// Handle map and object types
	if ty.IsMapType() || ty.IsObjectType() {
		m, ok := val.(map[string]interface{})
		if !ok {
			return cty.NilVal, fmt.Errorf("expected object at %s", strings.Join(path, "."))
		}

		vals := make(map[string]cty.Value)
		for k, v := range m {
			var elemTy cty.Type
			if ty.IsObjectType() {
				elemTy = ty.AttributeType(k)
			} else {
				elemTy = ty.ElementType()
			}
			elemVal, err := buildValueFromInterface(elemTy, v, append(path, k))
			if err != nil {
				return cty.NilVal, err
			}
			vals[k] = elemVal
		}

		if ty.IsMapType() {
			return cty.MapVal(vals), nil
		}
		return cty.ObjectVal(vals), nil
	}

	return cty.NilVal, fmt.Errorf("cannot build value for type %s at %s", ty.FriendlyName(), strings.Join(path, "."))
}

// buildRefinedUnknown builds a refined unknown value from refinement data
func buildRefinedUnknown(ty cty.Type, refinementsData interface{}) (cty.Value, error) {
	refinements, ok := refinementsData.(map[string]interface{})
	if !ok {
		return cty.NilVal, fmt.Errorf("refinements must be an object")
	}

	builder := cty.UnknownVal(ty).Refine()

	if isNull, ok := refinements["is_known_null"].(bool); ok {
		if isNull {
			builder = builder.Null()
		} else {
			builder = builder.NotNull()
		}
	}

	if prefix, ok := refinements["string_prefix"].(string); ok {
		builder = builder.StringPrefix(prefix)
	}

	if lowerBound, ok := refinements["number_lower_bound"].([]interface{}); ok && len(lowerBound) >= 2 {
		numStr, _ := lowerBound[0].(string)
		inclusive, _ := lowerBound[1].(bool)
		bf := new(big.Float)
		bf.SetString(numStr)
		builder = builder.NumberRangeLowerBound(cty.NumberVal(bf), inclusive)
	}

	if upperBound, ok := refinements["number_upper_bound"].([]interface{}); ok && len(upperBound) >= 2 {
		numStr, _ := upperBound[0].(string)
		inclusive, _ := upperBound[1].(bool)
		bf := new(big.Float)
		bf.SetString(numStr)
		builder = builder.NumberRangeUpperBound(cty.NumberVal(bf), inclusive)
	}

	if lower, ok := refinements["collection_length_lower_bound"].(float64); ok {
		builder = builder.CollectionLengthLowerBound(int(lower))
	}

	if upper, ok := refinements["collection_length_upper_bound"].(float64); ok {
		builder = builder.CollectionLengthUpperBound(int(upper))
	}

	return builder.NewValue(), nil
}
>>> EOF >>>

### FILE 32: tofusoup/harness/go/soup-go/go.sum | checksum=89eff1c53e99... | modified=2025-09-12T16:21:10 | op=+ | size=7616 | tokens=4311 ###
<<< BOF <<<
github.com/agext/levenshtein v1.2.1 h1:QmvMAjj2aEICytGiWzmxoE0x2KZvE0fvmqMOfy2tjT8=
github.com/agext/levenshtein v1.2.1/go.mod h1:JEDfjyjHDjOF/1e4FlBE/PkbqA9OfWu2ki2W0IB5558=
github.com/apparentlymart/go-textseg/v15 v15.0.0 h1:uYvfpb3DyLSCGWnctWKGj857c6ew1u1fNQOlOtuGxQY=
github.com/apparentlymart/go-textseg/v15 v15.0.0/go.mod h1:K8XmNZdhEBkdlyDdvbmmsvpAG721bKi0joRfFdHIWJ4=
github.com/cpuguy83/go-md2man/v2 v2.0.6/go.mod h1:oOW0eioCTA6cOiMLiUPZOpcVxMig6NIQQ7OS05n1F4g=
github.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
github.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=
github.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=
github.com/fatih/color v1.13.0 h1:8LOYc1KYPPmyKMuN8QV2DNRWNbLo6LZ0iLs8+mlH53w=
github.com/fatih/color v1.13.0/go.mod h1:kLAiJbzzSOZDVNGyDpeOxJ47H46qBXwg5ILebYFFOfk=
github.com/go-test/deep v1.0.3 h1:ZrJSEWsXzPOxaZnFteGEfooLba+ju3FYIbOrS+rQd68=
github.com/go-test/deep v1.0.3/go.mod h1:wGDj63lr65AM2AQyKZd/NYHGb0R+1RLqB8NKt3aSFNA=
github.com/golang/protobuf v1.5.4 h1:i7eJL8qZTpSEXOPTxNKhASYpMn+8e5Q6AdndVa1dWek=
github.com/golang/protobuf v1.5.4/go.mod h1:lnTiLA8Wa4RWRcIUkrtSVa5nRhsEGBg48fD6rSs7xps=
github.com/google/go-cmp v0.3.1 h1:Xye71clBPdm5HgqGwUkwhbynsUJZhDbS20FvLhQ2izg=
github.com/google/go-cmp v0.3.1/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=
github.com/hashicorp/go-hclog v1.6.3 h1:Qr2kF+eVWjTiYmU7Y31tYlP1h0q/X3Nl3tPGdaB11/k=
github.com/hashicorp/go-hclog v1.6.3/go.mod h1:W4Qnvbt70Wk/zYJryRzDRU/4r0kIg0PVHBcfoyhpF5M=
github.com/hashicorp/go-plugin v1.7.0 h1:YghfQH/0QmPNc/AZMTFE3ac8fipZyZECHdDPshfk+mA=
github.com/hashicorp/go-plugin v1.7.0/go.mod h1:BExt6KEaIYx804z8k4gRzRLEvxKVb+kn0NMcihqOqb8=
github.com/hashicorp/hcl/v2 v2.19.1 h1://i05Jqznmb2EXqa39Nsvyan2o5XyMowW5fnCKW5RPI=
github.com/hashicorp/hcl/v2 v2.19.1/go.mod h1:ThLC89FV4p9MPW804KVbe/cEXoQ8NZEh+JtMeeGErHE=
github.com/hashicorp/yamux v0.1.2 h1:XtB8kyFOyHXYVFnwT5C3+Bdo8gArse7j2AQ0DA0Uey8=
github.com/hashicorp/yamux v0.1.2/go.mod h1:C+zze2n6e/7wshOZep2A70/aQU6QBRWJO/G6FT1wIns=
github.com/inconshreveable/mousetrap v1.1.0 h1:wN+x4NVGpMsO7ErUn/mUI3vEoE6Jt13X2s0bqwp9tc8=
github.com/inconshreveable/mousetrap v1.1.0/go.mod h1:vpF70FUmC8bwa3OWnCshd2FqLfsEA9PFc4w1p2J65bw=
github.com/kr/pretty v0.1.0 h1:L/CwN0zerZDmRFUapSPitk6f+Q3+0za1rQkzVuMiMFI=
github.com/kr/pretty v0.1.0/go.mod h1:dAy3ld7l9f0ibDNOQOHHMYYIIbhfbHSm3C4ZsoJORNo=
github.com/kr/text v0.1.0 h1:45sCR5RtlFHMR4UwH9sdQ5TC8v0qDQCHnXt+kaKSTVE=
github.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=
github.com/kylelemons/godebug v0.0.0-20170820004349-d65d576e9348 h1:MtvEpTB6LX3vkb4ax0b5D2DHbNAUsen0Gx5wZoq3lV4=
github.com/kylelemons/godebug v0.0.0-20170820004349-d65d576e9348/go.mod h1:B69LEHPfb2qLo0BaaOLcbitczOKLWTsrBG9LczfCD4k=
github.com/mattn/go-colorable v0.1.9/go.mod h1:u6P/XSegPjTcexA+o6vUJrdnUu04hMope9wVRipJSqc=
github.com/mattn/go-colorable v0.1.12 h1:jF+Du6AlPIjs2BiUiQlKOX0rt3SujHxPnksPKZbaA40=
github.com/mattn/go-colorable v0.1.12/go.mod h1:u5H1YNBxpqRaxsYJYSkiCWKzEfiAb1Gb520KVy5xxl4=
github.com/mattn/go-isatty v0.0.12/go.mod h1:cbi8OIDigv2wuxKPP5vlRcQ1OAZbq2CE4Kysco4FUpU=
github.com/mattn/go-isatty v0.0.14 h1:yVuAays6BHfxijgZPzw+3Zlu5yQgKGP2/hcQbHb7S9Y=
github.com/mattn/go-isatty v0.0.14/go.mod h1:7GGIvUiUoEMVVmxf/4nioHXj79iQHKdU27kJ6hsGG94=
github.com/mattn/go-isatty v0.0.17 h1:BTarxUcIeDqL27Mc+vyvdWYSL28zpIhv3RoTdsLMPng=
github.com/mattn/go-isatty v0.0.17/go.mod h1:kYGgaQfpe5nmfYZH+SKPsOc2e4SrIfOl2e/yFXSvRLM=
github.com/mitchellh/go-wordwrap v0.0.0-20150314170334-ad45545899c7 h1:DpOJ2HYzCv8LZP15IdmG+YdwD2luVPHITV96TkirNBM=
github.com/mitchellh/go-wordwrap v0.0.0-20150314170334-ad45545899c7/go.mod h1:ZXFpozHsX6DPmq2I0TCekCxypsnAUbP2oI0UX1GXzOo=
github.com/oklog/run v1.1.0 h1:GEenZ1cK0+q0+wsJew9qUg/DyD8k3JzYsZAi5gYi2mA=
github.com/oklog/run v1.1.0/go.mod h1:sVPdnTZT1zYwAJeCMu2Th4T21pA3FPOQRfWjQlk7DVU=
github.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=
github.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=
github.com/russross/blackfriday/v2 v2.1.0/go.mod h1:+Rmxgy9KzJVeS9/2gXHxylqXiyQDYRxCVz55jmeOWTM=
github.com/spf13/cobra v1.10.1 h1:lJeBwCfmrnXthfAupyUTzJ/J4Nc1RsHC/mSRU2dll/s=
github.com/spf13/cobra v1.10.1/go.mod h1:7SmJGaTHFVBY0jW4NXGluQoLvhqFQM+6XSKD+P4XaB0=
github.com/spf13/pflag v1.0.9 h1:9exaQaMOCwffKiiiYk6/BndUBv+iRViNW+4lEMi0PvY=
github.com/spf13/pflag v1.0.9/go.mod h1:McXfInJRrz4CZXVZOBLb0bTZqETkiAhM9Iw0y3An2Bg=
github.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=
github.com/stretchr/testify v1.7.2 h1:4jaiDzPyXQvSd7D0EjG45355tLlV3VOECpq10pLC+8s=
github.com/stretchr/testify v1.7.2/go.mod h1:R6va5+xMeoiuVRoj+gSkQ7d3FALtqAAGI1FQKckRals=
github.com/vmihailenco/msgpack/v5 v5.4.1 h1:cQriyiUvjTwOHg8QZaPihLWeRAAVoCpE00IUPn0Bjt8=
github.com/vmihailenco/msgpack/v5 v5.4.1/go.mod h1:GaZTsDaehaPpQVyxrf5mtQlH+pc21PIudVV/E3rRQok=
github.com/vmihailenco/tagparser/v2 v2.0.0 h1:y09buUbR+b5aycVFQs/g70pqKVZNBmxwAhO7/IwNM9g=
github.com/vmihailenco/tagparser/v2 v2.0.0/go.mod h1:Wri+At7QHww0WTrCBeu4J6bNtoV6mEfg5OIWRZA9qds=
github.com/zclconf/go-cty v1.14.1 h1:t9fyA35fwjjUMcmL5hLER+e/rEPqrbCK1/OSE4SI9KA=
github.com/zclconf/go-cty v1.14.1/go.mod h1:VvMs5i0vgZdhYawQNq5kePSpLAoz8u1xvZgrPIxfnZE=
golang.org/x/net v0.38.0 h1:vRMAPTMaeGqVhG5QyLJHqNDwecKTomGeqbnfZyKlBI8=
golang.org/x/net v0.38.0/go.mod h1:ivrbrMbzFq5J41QOQh0siUuly180yBYtLp+CKbEaFx8=
golang.org/x/sys v0.0.0-20200116001909-b77594299b42/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20200223170610-d5e6a3e2c0ae/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=
golang.org/x/sys v0.0.0-20210630005230-0f9fa26af87c/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20210927094055-39ccf1dd6fa6/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220503163025-988cb79eb6c6/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.0.0-20220811171246-fbc7d0a398ab/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.18.0 h1:DBdB3niSjOA/O0blCZBqDefyWNYveAYMNF1Wum0DYQ4=
golang.org/x/sys v0.18.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=
golang.org/x/sys v0.31.0 h1:ioabZlmFYtWhL+TRYpcnNlLwhyxaM9kWTDEmfnprqik=
golang.org/x/sys v0.31.0/go.mod h1:BJP2sWEmIv4KK5OTEluFJCKSidICx8ciO85XgH3Ak8k=
golang.org/x/text v0.11.0 h1:LAntKIrcmeSKERyiOh0XMV39LXS8IE9UL2yP7+f5ij4=
golang.org/x/text v0.11.0/go.mod h1:TvPlkZtksWOMsz7fbANvkp4WM8x/WCo/om8BMLbz+aE=
golang.org/x/text v0.23.0 h1:D71I7dUrlY+VX0gQShAThNGHFxZ13dGLBHQLVl1mJlY=
golang.org/x/text v0.23.0/go.mod h1:/BLNzu4aZCJ1+kcD0DNRotWKage4q2rGVAg4o22unh4=
google.golang.org/genproto/googleapis/rpc v0.0.0-20231106174013-bbf56f31fb17 h1:Jyp0Hsi0bmHXG6k9eATXoYtjd6e2UzZ1SCn/wIupY14=
google.golang.org/genproto/googleapis/rpc v0.0.0-20231106174013-bbf56f31fb17/go.mod h1:oQ5rr10WTTMvP4A36n8JpR1OrO1BEiV4f78CneXZxkA=
google.golang.org/grpc v1.61.0 h1:TOvOcuXn30kRao+gfcvsebNEa5iZIiLkisYEkf7R7o0=
google.golang.org/grpc v1.61.0/go.mod h1:VUbo7IFqmF1QtCAstipjG0GIoq49KvMe9+h1jFLBNJs=
google.golang.org/protobuf v1.36.6 h1:z1NpPI8ku2WgiWnf+t9wTPsn6eP1L7ksHUlkfLvd9xY=
google.golang.org/protobuf v1.36.6/go.mod h1:jduwjTPXsFjZGTmRluh+L6NjiWu7pchiJ2/5YcXBHnY=
gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=
gopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=
gopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=
>>> EOF >>>

### FILE 33: tofusoup/harness/go/soup-go/hcl.go | checksum=9d7714901287... | modified=2025-09-12T09:01:48 | op=+ | size=6207 | tokens=1762 | type=x-go ###
<<< BOF <<<
package main

import (
	"encoding/json"
	"fmt"
	"os"

	"github.com/hashicorp/hcl/v2"
	"github.com/hashicorp/hcl/v2/hclparse"
	"github.com/hashicorp/hcl/v2/hclsyntax"
	"github.com/spf13/cobra"
	"github.com/zclconf/go-cty/cty"
	"github.com/zclconf/go-cty/cty/function"
	ctyjson "github.com/zclconf/go-cty/cty/json"
)

// HCL output format flag
var hclOutputFormat string

// Override the parse command with real implementation
func initHclParseCmd() *cobra.Command {
	cmd := &cobra.Command{
		Use:   "parse [file]",
		Short: "Parse an HCL file",
		Args:  cobra.ExactArgs(1),
		RunE: func(cmd *cobra.Command, args []string) error {
			filename := args[0]

			// Read the file
			content, err := os.ReadFile(filename)
			if err != nil {
				return fmt.Errorf("failed to read file: %w", err)
			}

			// Parse the HCL file
			parser := hclparse.NewParser()
			file, diags := parser.ParseHCL(content, filename)
			
			if diags.HasErrors() {
				if hclOutputFormat == "diagnostic" {
					for _, diag := range diags {
						fmt.Fprintf(os.Stderr, "%s\n", diag.Error())
					}
					return fmt.Errorf("parse errors occurred")
				}
				// Return error info as JSON
				errorOutput := map[string]interface{}{
					"success": false,
					"errors":  diagnosticsToJSON(diags),
				}
				json.NewEncoder(os.Stdout).Encode(errorOutput)
				return nil
			}

			// Convert to JSON representation
			result, err := hclFileToJSON(file)
			if err != nil {
				return fmt.Errorf("failed to convert HCL to JSON: %w", err)
			}

			// Output the result
			if hclOutputFormat == "json" {
				output := map[string]interface{}{
					"success": true,
					"body":    result,
				}
				if err := json.NewEncoder(os.Stdout).Encode(output); err != nil {
					return fmt.Errorf("failed to encode JSON: %w", err)
				}
			}

			return nil
		},
	}
	
	// Add flags
	cmd.Flags().StringVar(&hclOutputFormat, "output-format", "json", "Output format (json, diagnostic)")
	
	return cmd
}

// Override the validate command with real implementation
func initHclValidateCmd() *cobra.Command {
	cmd := &cobra.Command{
		Use:   "validate [file]",
		Short: "Validate HCL syntax",
		Args:  cobra.ExactArgs(1),
		RunE: func(cmd *cobra.Command, args []string) error {
			filename := args[0]

			// Read the file
			content, err := os.ReadFile(filename)
			if err != nil {
				return fmt.Errorf("failed to read file: %w", err)
			}

			// Parse the HCL file for validation
			parser := hclparse.NewParser()
			_, diags := parser.ParseHCL(content, filename)

			result := map[string]interface{}{
				"valid": !diags.HasErrors(),
			}

			if diags.HasErrors() {
				result["errors"] = diagnosticsToJSON(diags)
			}

			// Output validation result as JSON
			if err := json.NewEncoder(os.Stdout).Encode(result); err != nil {
				return fmt.Errorf("failed to encode JSON: %w", err)
			}

			return nil
		},
	}
	
	return cmd
}

// hclFileToJSON converts an HCL file to a JSON representation
func hclFileToJSON(file *hcl.File) (interface{}, error) {
	// For now, we'll work directly with the body without partial content
	// since we're doing a general parse

	result := make(map[string]interface{})

	// Process attributes
	if body, ok := file.Body.(*hclsyntax.Body); ok {
		for name, attr := range body.Attributes {
			val, diags := attr.Expr.Value(&hcl.EvalContext{
				Variables: map[string]cty.Value{},
				Functions: map[string]function.Function{},
			})
			if !diags.HasErrors() {
				jsonVal, err := ctyjson.Marshal(val, val.Type())
				if err == nil {
					var v interface{}
					if err := json.Unmarshal(jsonVal, &v); err == nil {
						result[name] = v
					}
				}
			}
		}

		// Process blocks
		blocks := make([]map[string]interface{}, 0)
		for _, block := range body.Blocks {
			blockData := map[string]interface{}{
				"type":   block.Type,
				"labels": block.Labels,
			}
			
			// Recursively process block body
			if blockBody, err := hclBlockToJSON(block.Body); err == nil {
				blockData["body"] = blockBody
			}
			
			blocks = append(blocks, blockData)
		}
		
		if len(blocks) > 0 {
			result["blocks"] = blocks
		}
	}

	return result, nil
}

// hclBlockToJSON converts an HCL block body to JSON
func hclBlockToJSON(body hcl.Body) (interface{}, error) {
	if syntaxBody, ok := body.(*hclsyntax.Body); ok {
		result := make(map[string]interface{})
		
		// Process attributes in the block
		for name, attr := range syntaxBody.Attributes {
			val, diags := attr.Expr.Value(&hcl.EvalContext{
				Variables: map[string]cty.Value{},
				Functions: map[string]function.Function{},
			})
			if !diags.HasErrors() {
				jsonVal, err := ctyjson.Marshal(val, val.Type())
				if err == nil {
					var v interface{}
					if err := json.Unmarshal(jsonVal, &v); err == nil {
						result[name] = v
					}
				}
			}
		}
		
		// Process nested blocks
		if len(syntaxBody.Blocks) > 0 {
			blocks := make([]map[string]interface{}, 0)
			for _, block := range syntaxBody.Blocks {
				blockData := map[string]interface{}{
					"type":   block.Type,
					"labels": block.Labels,
				}
				
				if blockBody, err := hclBlockToJSON(block.Body); err == nil {
					blockData["body"] = blockBody
				}
				
				blocks = append(blocks, blockData)
			}
			result["blocks"] = blocks
		}
		
		return result, nil
	}
	
	return nil, fmt.Errorf("unsupported body type")
}

// diagnosticsToJSON converts HCL diagnostics to JSON
func diagnosticsToJSON(diags hcl.Diagnostics) []map[string]interface{} {
	result := make([]map[string]interface{}, 0, len(diags))
	for _, diag := range diags {
		severityStr := "error"
		if diag.Severity == hcl.DiagWarning {
			severityStr = "warning"
		}
		d := map[string]interface{}{
			"severity": severityStr,
			"summary":  diag.Summary,
			"detail":   diag.Detail,
		}
		if diag.Subject != nil {
			d["range"] = map[string]interface{}{
				"filename": diag.Subject.Filename,
				"start": map[string]int{
					"line":   diag.Subject.Start.Line,
					"column": diag.Subject.Start.Column,
					"byte":   diag.Subject.Start.Byte,
				},
				"end": map[string]int{
					"line":   diag.Subject.End.Line,
					"column": diag.Subject.End.Column,
					"byte":   diag.Subject.End.Byte,
				},
			}
		}
		result = append(result, d)
	}
	return result
}
>>> EOF >>>

### FILE 34: tofusoup/harness/go/soup-go/main.go | checksum=207c15947386... | modified=2025-09-12T19:31:20 | op=+ | size=7300 | tokens=2014 | type=x-go ###
<<< BOF <<<
package main

import (
	"encoding/json"
	"fmt"
	"os"

	"github.com/hashicorp/go-hclog"
	"github.com/spf13/cobra"
)

const version = "0.1.0"

var (
	// Global flags
	verbose  bool
	logLevel string
	logger   hclog.Logger
)

// Root command
var rootCmd = &cobra.Command{
	Use:   "soup-go",
	Short: "TofuSoup Go test harness - unified CLI for testing",
	Long: `soup-go is a unified Go harness for TofuSoup that provides
CTY, HCL, Wire, and RPC functionality for cross-language testing.`,
	Version: version,
	PersistentPreRun: func(cmd *cobra.Command, args []string) {
		// Reinitialize logger if log level was changed via flag
		if cmd.Flags().Changed("log-level") {
			initLogger()
		}
		logger.Debug("executing command", "cmd", cmd.Name(), "args", args)
	},
}

// CTY command
var ctyCmd = &cobra.Command{
	Use:   "cty",
	Short: "CTY type and value operations",
	Long:  `Perform CTY (Complex Type) operations including validation and conversion.`,
}

// These will be initialized with real implementations
var ctyValidateCmd *cobra.Command
var ctyConvertCmd *cobra.Command

// HCL command
var hclCmd = &cobra.Command{
	Use:   "hcl",
	Short: "HCL parsing and processing",
	Long:  `Parse and process HashiCorp Configuration Language (HCL) files.`,
}

// These will be initialized with real implementations
var hclParseCmd *cobra.Command
var hclValidateCmd *cobra.Command

// Wire command
var wireCmd = &cobra.Command{
	Use:   "wire",
	Short: "Wire protocol operations",
	Long:  `Encode and decode data using the wire protocol format.`,
}

// These will be initialized with real implementations
var wireEncodeCmd *cobra.Command
var wireDecodeCmd *cobra.Command

// RPC command
var rpcCmd = &cobra.Command{
	Use:   "rpc",
	Short: "RPC server and client operations",
	Long:  `Manage RPC servers and clients for plugin communication.`,
}

var (
	rpcPort    int
	rpcTLSMode string
)

var rpcServerCmd = &cobra.Command{
	Use:   "server-start",
	Short: "Start an RPC server",
	Run: func(cmd *cobra.Command, args []string) {
		logger.Info("Starting RPC server", 
			"port", rpcPort, 
			"tls_mode", rpcTLSMode,
			"log_level", logLevel)
		
		if err := startRPCServer(logger, rpcPort, rpcTLSMode); err != nil {
			logger.Error("RPC server failed", "error", err)
			os.Exit(1)
		}
	},
}

var rpcClientCmd = &cobra.Command{
	Use:   "client",
	Short: "RPC client operations",
	Run: func(cmd *cobra.Command, args []string) {
		logger.Info("RPC client operations")
		fmt.Println("RPC client operations")
	},
}

var rpcClientTestCmd = &cobra.Command{
	Use:   "test [server-path]",
	Short: "Test RPC client connection",
	Args:  cobra.ExactArgs(1),
	Run: func(cmd *cobra.Command, args []string) {
		serverPath := args[0]
		logger.Info("Testing RPC client", "server_path", serverPath)
		
		if err := testRPCClient(logger, serverPath); err != nil {
			logger.Error("RPC client test failed", "error", err)
			os.Exit(1)
		}
	},
}

// Harness command (for compatibility testing)
var harnessCmd = &cobra.Command{
	Use:   "harness",
	Short: "Harness management commands",
	Long:  `Commands for managing and testing harnesses.`,
}

var harnessListCmd = &cobra.Command{
	Use:   "list",
	Short: "List available harnesses",
	Run: func(cmd *cobra.Command, args []string) {
		harnesses := []map[string]string{
			{"name": "soup-go", "status": "active", "version": version},
		}
		
		if outputJSON, _ := cmd.Flags().GetBool("json"); outputJSON {
			logger.Debug("outputting harness list as JSON")
			json.NewEncoder(os.Stdout).Encode(harnesses)
		} else {
			logger.Debug("outputting harness list as text")
			fmt.Println("Available harnesses:")
			for _, h := range harnesses {
				fmt.Printf("  - %s (v%s) [%s]\n", h["name"], h["version"], h["status"])
			}
		}
	},
}

var harnessTestCmd = &cobra.Command{
	Use:   "test [harness]",
	Short: "Test a specific harness",
	Args:  cobra.MaximumNArgs(1),
	Run: func(cmd *cobra.Command, args []string) {
		harness := "soup-go"
		if len(args) > 0 {
			harness = args[0]
		}
		logger.Info("testing harness", "harness", harness)
		fmt.Printf("Testing harness: %s\n", harness)
		fmt.Println("All tests passed")
	},
}

// Config command (similar to soup config)
var configCmd = &cobra.Command{
	Use:   "config",
	Short: "Configuration management",
}

var configShowCmd = &cobra.Command{
	Use:   "show",
	Short: "Show current configuration",
	Run: func(cmd *cobra.Command, args []string) {
		config := map[string]interface{}{
			"version":   version,
			"log_level": logLevel,
			"verbose":   verbose,
		}
		
		if outputJSON, _ := cmd.Flags().GetBool("json"); outputJSON {
			json.NewEncoder(os.Stdout).Encode(config)
		} else {
			fmt.Println("Current configuration:")
			fmt.Printf("  Version: %s\n", version)
			fmt.Printf("  Log Level: %s\n", logLevel)
			fmt.Printf("  Verbose: %v\n", verbose)
		}
	},
}

func init() {
	// Initialize commands with real implementations
	ctyValidateCmd = initCtyValidateCmd()
	ctyConvertCmd = initCtyConvertCmd()
	hclParseCmd = initHclParseCmd()
	hclValidateCmd = initHclValidateCmd()
	wireEncodeCmd = initWireEncodeCmd()
	wireDecodeCmd = initWireDecodeCmd()
	
	// Global flags
	rootCmd.PersistentFlags().BoolVarP(&verbose, "verbose", "v", false, "Enable verbose output")
	rootCmd.PersistentFlags().StringVar(&logLevel, "log-level", "info", "Set log level (trace, debug, info, warn, error)")
	
	// Add JSON output flag to relevant commands
	harnessListCmd.Flags().Bool("json", false, "Output in JSON format")
	configShowCmd.Flags().Bool("json", false, "Output in JSON format")
	
	// RPC server flags
	rpcServerCmd.Flags().IntVar(&rpcPort, "port", 50051, "The server port")
	rpcServerCmd.Flags().StringVar(&rpcTLSMode, "tls-mode", "disabled", "TLS mode: disabled, auto, manual")
	
	// Build command tree
	rootCmd.AddCommand(ctyCmd)
	rootCmd.AddCommand(hclCmd)
	rootCmd.AddCommand(wireCmd)
	rootCmd.AddCommand(rpcCmd)
	rootCmd.AddCommand(harnessCmd)
	rootCmd.AddCommand(configCmd)
	
	// CTY subcommands
	ctyCmd.AddCommand(ctyValidateCmd)
	ctyCmd.AddCommand(ctyConvertCmd)
	
	// HCL subcommands
	hclCmd.AddCommand(hclParseCmd)
	hclCmd.AddCommand(hclValidateCmd)
	
	// Wire subcommands
	wireCmd.AddCommand(wireEncodeCmd)
	wireCmd.AddCommand(wireDecodeCmd)
	
	// RPC subcommands
	rpcCmd.AddCommand(rpcServerCmd)
	rpcCmd.AddCommand(rpcClientCmd)
	
	// RPC client subcommands
	rpcClientCmd.AddCommand(rpcClientTestCmd)
	
	// Harness subcommands
	harnessCmd.AddCommand(harnessListCmd)
	harnessCmd.AddCommand(harnessTestCmd)
	
	// Config subcommands
	configCmd.AddCommand(configShowCmd)
}

func main() {
	// Initialize logger early
	initLogger()
	
	if err := rootCmd.Execute(); err != nil {
		logger.Error("command execution failed", "error", err)
		fmt.Fprintln(os.Stderr, err)
		os.Exit(1)
	}
}

func initLogger() {
	// Parse log level from environment or default
	level := hclog.Info
	if envLevel := os.Getenv("LOG_LEVEL"); envLevel != "" {
		logLevel = envLevel
	}
	
	switch logLevel {
	case "trace":
		level = hclog.Trace
	case "debug":
		level = hclog.Debug
	case "info":
		level = hclog.Info
	case "warn":
		level = hclog.Warn
	case "error":
		level = hclog.Error
	}
	
	// Create logger with nice formatting
	logger = hclog.New(&hclog.LoggerOptions{
		Name:       "soup-go",
		Level:      level,
		Color:      hclog.AutoColor,
		TimeFormat: "15:04:05.000",
	})
}
>>> EOF >>>

### FILE 35: tofusoup/harness/go/soup-go/rpc.go | checksum=9dba2b789d7e... | modified=2025-09-12T19:32:19 | op=+ | size=5316 | tokens=1509 | type=x-go ###
<<< BOF <<<
package main

import (
	"crypto/x509"
	"os"
	"os/exec"
	"os/signal"
	"strconv"
	"strings"
	"sync"
	"syscall"
	"time"

	"github.com/hashicorp/go-hclog"
	"github.com/hashicorp/go-plugin"
	"google.golang.org/grpc"
)

func startRPCServer(logger hclog.Logger, port int, tlsMode string) error {
	logger.Info("🗄️✨ starting RPC plugin server",
		"port", port,
		"tls_mode", tlsMode,
		"log_level", logger.GetLevel())

	// Determine if AutoMTLS is enabled
	autoMTLS := true // Default to true
	autoMTLSValue := os.Getenv("PLUGIN_AUTO_MTLS")
	if autoMTLSValue != "" {
		autoMTLS, _ = strconv.ParseBool(strings.ToLower(autoMTLSValue))
	}

	if autoMTLS {
		logger.Info("📡🔐 AutoMTLS is enabled. Proceeding with TLS setup...")

		// Load and parse certificate from the environment variable
		certPEM := os.Getenv("PLUGIN_CLIENT_CERT")
		if certPEM == "" {
			logger.Error("📡❌ Certificate not found in PLUGIN_CLIENT_CERT")
			return nil
		}

		// Display certificate details
		logger.Info("🔌🔐 Client Certificate Details:")
		if err := decodeAndLogCertificate(certPEM, logger); err != nil {
			return err
		}

		// Create TLS configuration
		certPool := x509.NewCertPool()
		if !certPool.AppendCertsFromPEM([]byte(certPEM)) {
			logger.Error("📡❌ Failed to append certificate to trust pool")
			return nil
		}

	} else {
		logger.Info("📡🚫 AutoMTLS is disabled. Skipping TLS setup.")
	}

	// Create shutdown channel
	shutdown := make(chan os.Signal, 1)
	signal.Notify(shutdown, syscall.SIGINT, syscall.SIGTERM)

	// Create KV implementation
	kv := &KVImpl{
		logger: logger.Named("kv"),
		mu:     sync.RWMutex{},
	}

	config := &plugin.ServeConfig{
		HandshakeConfig: Handshake,
		VersionedPlugins: map[int]plugin.PluginSet{
			1: {
				"kv_grpc": &KVGRPCPlugin{
					Impl: kv,
				},
			},
		},
		Logger: logger,
		GRPCServer: func(opts []grpc.ServerOption) *grpc.Server {
			if autoMTLS {
				logger.Info("🔐⛓️‍💥✅ AutoMTLS support is enabled.")
			}
			return grpc.NewServer(opts...)
		},
	}

	// Start serving in a goroutine
	var wg sync.WaitGroup
	wg.Add(1)

	// Create a channel to signal when the plugin server is done
	serverDone := make(chan struct{})

	go func() {
		defer wg.Done()
		logger.Info("🗄️✨ starting plugin server")
		plugin.Serve(config)
		close(serverDone)
	}()

	// Handle shutdown
	go func() {
		select {
		case sig := <-shutdown:
			logger.Info("🗄️🛑 shutting down plugin server", "signal", sig)
		case <-serverDone:
			logger.Info("🗄️🛑 plugin server exited before receiving a signal")
		}

		cleanup := make(chan struct{})
		go func() {
			wg.Wait()
			close(cleanup)
		}()

		select {
		case <-cleanup:
			logger.Info("🗄️✅ clean shutdown completed")
		case <-time.After(5 * time.Second):
			logger.Warn("🗄️⏳ cleanup timeout reached")
		}

		os.Exit(0)
	}()

	<-serverDone
	return nil
}

func decodeAndLogCertificate(certPEM string, logger hclog.Logger) error {
	// Simple certificate logging - in production you'd parse and display details
	logger.Debug("🔐📜 Certificate loaded", "length", len(certPEM))
	return nil
}

func testRPCClient(logger hclog.Logger, serverPath string) error {
	logger.Info("🌐🧪 starting RPC client test", "server_path", serverPath)

	// Create client
	client := plugin.NewClient(&plugin.ClientConfig{
		HandshakeConfig:  Handshake,
		VersionedPlugins: map[int]plugin.PluginSet{
			1: {
				"kv_grpc": &KVGRPCPlugin{},
			},
		},
		Cmd:             exec.Command(serverPath, "rpc", "server-start"),
		Logger:          logger,
		AutoMTLS:        true,
		AllowedProtocols: []plugin.Protocol{plugin.ProtocolGRPC},
	})
	defer client.Kill()

	// Connect via RPC
	rpcClient, err := client.Client()
	if err != nil {
		logger.Error("🌐❌ failed to create RPC client", "error", err)
		return err
	}

	// Request the plugin
	raw, err := rpcClient.Dispense("kv_grpc")
	if err != nil {
		logger.Error("🌐❌ failed to dispense plugin", "error", err)
		return err
	}

	// Cast to KV interface
	kv := raw.(KV)

	// Test Put operation
	testKey := "go_client_test_key"
	testValue := []byte("Hello from Go client to Go server!")
	
	logger.Info("🌐📤 testing Put operation", "key", testKey, "value_size", len(testValue))
	err = kv.Put(testKey, testValue)
	if err != nil {
		logger.Error("🌐❌ Put operation failed", "error", err)
		return err
	}
	logger.Info("🌐✅ Put operation successful")

	// Test Get operation
	logger.Info("🌐📥 testing Get operation", "key", testKey)
	retrievedValue, err := kv.Get(testKey)
	if err != nil {
		logger.Error("🌐❌ Get operation failed", "error", err)
		return err
	}

	if string(retrievedValue) != string(testValue) {
		logger.Error("🌐❌ Retrieved value doesn't match", 
			"expected", string(testValue), 
			"got", string(retrievedValue))
		return err
	}
	logger.Info("🌐✅ Get operation successful", "value", string(retrievedValue))

	// Test Get non-existent key
	logger.Info("🌐📥 testing Get operation for non-existent key")
	_, err = kv.Get("non_existent_key")
	if err != nil {
		logger.Info("🌐✅ Get non-existent key properly returned error", "error", err)
	} else {
		logger.Warn("🌐⚠️ Get non-existent key should have returned error")
	}

	logger.Info("🌐🎉 RPC client test completed successfully")
	return nil
}
>>> EOF >>>

### FILE 36: tofusoup/harness/go/soup-go/rpc_shared.go | checksum=21ea2361b2a2... | modified=2025-10-10T12:03:42 | op=+ | size=5797 | tokens=1668 | type=x-go ###
<<< BOF <<<
package main

import (
	"context"
	"fmt"
	"os"
	"sync"

	"github.com/hashicorp/go-hclog"
	"github.com/hashicorp/go-plugin"
	"google.golang.org/grpc"
	"google.golang.org/grpc/codes"
	"google.golang.org/grpc/status"

	"github.com/provide-io/tofusoup/proto/kv"
)

// Handshake is a common handshake that is shared by plugin and host.
var Handshake = plugin.HandshakeConfig{
	ProtocolVersion:  1,
	MagicCookieKey:   "BASIC_PLUGIN",
	MagicCookieValue: "hello",
}

// KV is the interface that we're exposing as a plugin.
type KV interface {
	Put(key string, value []byte) error
	Get(key string) ([]byte, error)
}

// KVGRPCPlugin is the implementation of plugin.GRPCPlugin so we can serve/consume this.
type KVGRPCPlugin struct {
	plugin.Plugin
	// Concrete implementation, written in Go.
	Impl KV
}

func (p *KVGRPCPlugin) GRPCPlugin() plugin.GRPCPlugin {
	return p
}

func (p *KVGRPCPlugin) GRPCClient(ctx context.Context, broker *plugin.GRPCBroker, c *grpc.ClientConn) (interface{}, error) {
	logger := hclog.New(&hclog.LoggerOptions{
		Name:  "🔌🌐 kv-grpc-client",
		Level: hclog.Debug,
	})

	if c == nil {
		logger.Error("🌐❌ received nil gRPC connection")
		return nil, fmt.Errorf("nil gRPC connection")
	}

	logger.Debug("🌐🔄 initializing new gRPC client connection",
		"connection_state", c.GetState().String(),
		"target", c.Target())

	grpcClient := &GRPCClient{
		client: proto.NewKVClient(c),
		logger: logger,
	}

	logger.Debug("🌐✨ GRPCClient wrapper initialized successfully",
		"client_implementation", fmt.Sprintf("%T", grpcClient))
	return grpcClient, nil
}

func (p *KVGRPCPlugin) GRPCServer(broker *plugin.GRPCBroker, s *grpc.Server) error {
	logger := hclog.New(&hclog.LoggerOptions{
		Name:  "🔌📡 kv-grpc-server",
		Level: hclog.Debug,
	})

	logger.Debug("📡🔄 initializing gRPC server registration")

	if p.Impl == nil {
		logger.Warn("📡⚠️ no implementation provided, using default implementation")
		// Use environment variable or default to /tmp
		storageDir := os.Getenv("KV_STORAGE_DIR")
		if storageDir == "" {
			storageDir = "/tmp"
		}
		p.Impl = NewKVImpl(logger.Named("kv"), storageDir)
	}

	server := &GRPCServer{
		Impl:   p.Impl,
		logger: logger,
	}

	proto.RegisterKVServer(s, server)
	logger.Info("📡✅ gRPC server registered successfully",
		"server_type", fmt.Sprintf("%T", server))
	return nil
}

// GRPCClient is an implementation of KV that talks over RPC.
type GRPCClient struct {
	client proto.KVClient
	logger hclog.Logger
}

func (m *GRPCClient) Put(key string, value []byte) error {
	m.logger.Debug("🌐📤 initiating Put request",
		"key", key,
		"value_size", len(value))

	_, err := m.client.Put(context.Background(), &proto.PutRequest{
		Key:   key,
		Value: value,
	})

	if err != nil {
		m.logger.Error("🌐❌ Put request failed",
			"key", key,
			"error", err)
		return err
	}

	m.logger.Debug("🌐✅ Put request completed successfully",
		"key", key)
	return nil
}

func (m *GRPCClient) Get(key string) ([]byte, error) {
	m.logger.Debug("🌐📥 initiating Get request", "key", key)

	resp, err := m.client.Get(context.Background(), &proto.GetRequest{
		Key: key,
	})
	if err != nil {
		m.logger.Error("🌐❌ Get request failed", "key", key, "error", err)
		return nil, err
	}

	m.logger.Debug("🌐✅ Get request completed successfully", "key", key, "value_size", len(resp.Value))
	return resp.Value, nil
}

// GRPCServer is the gRPC server that GRPCClient talks to.
type GRPCServer struct {
	proto.UnimplementedKVServer
	Impl   KV
	logger hclog.Logger
}

func (m *GRPCServer) Put(ctx context.Context, req *proto.PutRequest) (*proto.Empty, error) {
	m.logger.Debug("📡📤 handling Put request",
		"key", req.Key,
		"value_size", len(req.Value))

	if err := m.Impl.Put(req.Key, req.Value); err != nil {
		m.logger.Error("📡❌ Put operation failed",
			"key", req.Key,
			"error", err)
		return nil, err
	}

	m.logger.Debug("📡✅ Put operation completed successfully",
		"key", req.Key)
	return &proto.Empty{}, nil
}

func (m *GRPCServer) Get(ctx context.Context, req *proto.GetRequest) (*proto.GetResponse, error) {
	m.logger.Debug("📡📥 handling Get request",
		"key", req.Key)

	v, err := m.Impl.Get(req.Key)
	if err != nil {
		// Check if this is a file not found error (key doesn't exist)
		if os.IsNotExist(err) {
			m.logger.Debug("📡📥 key not found",
				"key", req.Key)
			return nil, status.Errorf(codes.NotFound, "key not found: %s", req.Key)
		}
		m.logger.Error("📡❌ Get operation failed",
			"key", req.Key,
			"error", err)
		return nil, err
	}

	m.logger.Debug("📡✅ Get operation completed successfully",
		"key", req.Key,
		"value_size", len(v))
	return &proto.GetResponse{Value: v}, nil
}

// KVImpl provides a simple file-based KV implementation
type KVImpl struct {
	logger     hclog.Logger
	mu         sync.RWMutex
	storageDir string
}

// NewKVImpl creates a new KVImpl with a configurable storage directory
func NewKVImpl(logger hclog.Logger, storageDir string) *KVImpl {
	if storageDir == "" {
		storageDir = "/tmp"
	}
	logger.Debug("Initializing KVImpl", "storage_dir", storageDir)
	return &KVImpl{
		logger:     logger,
		mu:         sync.RWMutex{},
		storageDir: storageDir,
	}
}

func (k *KVImpl) Put(key string, value []byte) error {
	k.mu.Lock()
	defer k.mu.Unlock()

	if key == "" {
		return nil
	}

	k.logger.Debug("🗄️📤 putting value",
		"key", key,
		"value_length", len(value))

	filePath := k.storageDir + "/kv-data-" + key
	return os.WriteFile(filePath, value, 0644)
}

func (k *KVImpl) Get(key string) ([]byte, error) {
	k.mu.RLock()
	defer k.mu.RUnlock()

	if key == "" {
		return nil, nil
	}

	k.logger.Debug("🗄️📥 getting value", "key", key)
	filePath := k.storageDir + "/kv-data-" + key
	return os.ReadFile(filePath)
}
>>> EOF >>>

### FILE 37: tofusoup/harness/go/soup-go/wire.go | checksum=c4cd5aad6530... | modified=2025-09-12T09:02:54 | op=+ | size=5374 | tokens=1535 | type=x-go ###
<<< BOF <<<
package main

import (
	"encoding/json"
	"fmt"
	"io"
	"os"

	"github.com/spf13/cobra"
	"github.com/vmihailenco/msgpack/v5"
	"github.com/zclconf/go-cty/cty"
	ctyjson "github.com/zclconf/go-cty/cty/json"
	ctymsgpack "github.com/zclconf/go-cty/cty/msgpack"
)

// Wire command flags
var (
	wireInputFormat  string
	wireOutputFormat string
	wireTypeJSON     string
)

// Override the encode command with real implementation
func initWireEncodeCmd() *cobra.Command {
	cmd := &cobra.Command{
		Use:   "encode [input] [output]",
		Short: "Encode data to wire format",
		Args:  cobra.RangeArgs(1, 2),
		RunE: func(cmd *cobra.Command, args []string) error {
			inputPath := args[0]
			outputPath := "-"
			if len(args) > 1 {
				outputPath = args[1]
			}

			// Read input
			var inputData []byte
			var err error
			if inputPath == "-" {
				inputData, err = io.ReadAll(os.Stdin)
			} else {
				inputData, err = os.ReadFile(inputPath)
			}
			if err != nil {
				return fmt.Errorf("failed to read input: %w", err)
			}

			var outputData []byte

			// If a type is specified, use CTY encoding
			if wireTypeJSON != "" {
				ctyType, err := parseCtyType(json.RawMessage(wireTypeJSON))
				if err != nil {
					return fmt.Errorf("failed to parse type: %w", err)
				}

				// Parse input as JSON and build CTY value
				value, err := buildCtyValueFromJSON(ctyType, inputData)
				if err != nil {
					return fmt.Errorf("failed to build value: %w", err)
				}

				// Encode to wire format
				switch wireOutputFormat {
				case "msgpack":
					outputData, err = ctymsgpack.Marshal(value, ctyType)
				case "json":
					outputData, err = ctyjson.Marshal(value, ctyType)
				default:
					return fmt.Errorf("unsupported output format: %s", wireOutputFormat)
				}
				if err != nil {
					return fmt.Errorf("failed to encode: %w", err)
				}
			} else {
				// Generic msgpack encoding without CTY type
				var data interface{}
				if err := json.Unmarshal(inputData, &data); err != nil {
					return fmt.Errorf("failed to parse JSON: %w", err)
				}

				outputData, err = msgpack.Marshal(data)
				if err != nil {
					return fmt.Errorf("failed to encode msgpack: %w", err)
				}
			}

			// Write output
			if outputPath == "-" {
				_, err = os.Stdout.Write(outputData)
			} else {
				err = os.WriteFile(outputPath, outputData, 0644)
			}
			if err != nil {
				return fmt.Errorf("failed to write output: %w", err)
			}

			return nil
		},
	}
	
	// Add flags
	cmd.Flags().StringVar(&wireInputFormat, "input-format", "json", "Input format (json)")
	cmd.Flags().StringVar(&wireOutputFormat, "output-format", "msgpack", "Output format (msgpack, json)")
	cmd.Flags().StringVar(&wireTypeJSON, "type", "", "Type specification as JSON (optional)")
	
	return cmd
}

// Override the decode command with real implementation
func initWireDecodeCmd() *cobra.Command {
	cmd := &cobra.Command{
		Use:   "decode [input] [output]",
		Short: "Decode data from wire format",
		Args:  cobra.RangeArgs(1, 2),
		RunE: func(cmd *cobra.Command, args []string) error {
			inputPath := args[0]
			outputPath := "-"
			if len(args) > 1 {
				outputPath = args[1]
			}

			// Read input
			var inputData []byte
			var err error
			if inputPath == "-" {
				inputData, err = io.ReadAll(os.Stdin)
			} else {
				inputData, err = os.ReadFile(inputPath)
			}
			if err != nil {
				return fmt.Errorf("failed to read input: %w", err)
			}

			var outputData []byte

			// If a type is specified, use CTY decoding
			if wireTypeJSON != "" {
				ctyType, err := parseCtyType(json.RawMessage(wireTypeJSON))
				if err != nil {
					return fmt.Errorf("failed to parse type: %w", err)
				}

				// Decode from wire format
				var value cty.Value
				switch wireInputFormat {
				case "msgpack":
					value, err = ctymsgpack.Unmarshal(inputData, ctyType)
				case "json":
					value, err = ctyjson.Unmarshal(inputData, ctyType)
				default:
					return fmt.Errorf("unsupported input format: %s", wireInputFormat)
				}
				if err != nil {
					return fmt.Errorf("failed to decode: %w", err)
				}

				// Encode to output format
				switch wireOutputFormat {
				case "json":
					outputData, err = ctyjson.Marshal(value, ctyType)
				case "msgpack":
					outputData, err = ctymsgpack.Marshal(value, ctyType)
				default:
					return fmt.Errorf("unsupported output format: %s", wireOutputFormat)
				}
				if err != nil {
					return fmt.Errorf("failed to encode output: %w", err)
				}
			} else {
				// Generic msgpack decoding without CTY type
				var data interface{}
				if err := msgpack.Unmarshal(inputData, &data); err != nil {
					return fmt.Errorf("failed to decode msgpack: %w", err)
				}

				outputData, err = json.MarshalIndent(data, "", "  ")
				if err != nil {
					return fmt.Errorf("failed to encode JSON: %w", err)
				}
			}

			// Write output
			if outputPath == "-" {
				_, err = os.Stdout.Write(outputData)
			} else {
				err = os.WriteFile(outputPath, outputData, 0644)
			}
			if err != nil {
				return fmt.Errorf("failed to write output: %w", err)
			}

			return nil
		},
	}
	
	// Add flags
	cmd.Flags().StringVar(&wireInputFormat, "input-format", "msgpack", "Input format (msgpack)")
	cmd.Flags().StringVar(&wireOutputFormat, "output-format", "json", "Output format (json)")
	cmd.Flags().StringVar(&wireTypeJSON, "type", "", "Type specification as JSON (optional)")
	
	return cmd
}
>>> EOF >>>

### FILE 38: tofusoup/harness/logic.py | checksum=f59c66001a67... | modified=2025-09-17T17:32:12 | op=+ | size=5054 | tokens=1215 | type=x-python ###
<<< BOF <<<
#
# tofusoup/harness/logic.py
#
import os
import pathlib
import subprocess
from typing import Any

from provide.foundation import logger

from tofusoup.common.exceptions import TofuSoupError

GO_HARNESS_CONFIG = {
    "soup-go": {
        "source_dir": "src/tofusoup/harness/go/soup-go",
        "main_file": "main.go",
        "output_name": "soup-go",
    },
    "pspf-packager": {
        "source_dir": "pspf/src/go/pspf-packager",
        "main_file": "main.go",
        "output_name": "pspf-packager",
    },
}


class GoVersionError(TofuSoupError):
    pass


class HarnessBuildError(TofuSoupError):
    pass


class HarnessCleanError(TofuSoupError):
    pass


def _get_effective_go_harness_settings(harness_name: str, loaded_config: dict[str, Any]) -> dict[str, Any]:
    settings: dict[str, Any] = {"build_flags": [], "env_vars": {}}
    component_id = harness_name
    go_defaults = loaded_config.get("harness_defaults", {}).get("go", {})
    settings["build_flags"] = go_defaults.get("build_flags", [])
    settings["env_vars"] = go_defaults.get("common_env_vars", {})

    specific_config = loaded_config.get("harness", {}).get("go", {}).get(component_id, {})
    if "build_flags" in specific_config:
        settings["build_flags"] = specific_config["build_flags"]
    if "env_vars" in specific_config:
        settings["env_vars"].update(specific_config["env_vars"])
    return settings


def ensure_go_harness_build(
    harness_name: str,
    project_root: pathlib.Path,
    loaded_config: dict[str, Any],
    force_rebuild: bool = False,
) -> pathlib.Path:
    config = GO_HARNESS_CONFIG.get(harness_name)
    if not config:
        raise TofuSoupError(f"Configuration for Go harness '{harness_name}' not found.")

    harness_source_path = project_root / config["source_dir"]
    output_bin_dir = project_root / "bin"
    output_bin_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_bin_dir / config["output_name"]

    if not force_rebuild and output_path.exists():
        logger.info(f"Go harness '{harness_name}' already built at {output_path}. Skipping build.")
        return output_path

    logger.info(f"Building Go harness '{harness_name}' from {harness_source_path}...")

    # Get effective settings for build flags and environment variables
    settings = _get_effective_go_harness_settings(harness_name, loaded_config)
    build_flags = settings["build_flags"]
    env_vars = settings["env_vars"]

    # Construct the build command
    cmd = ["go", "build", "-o", str(output_path)]
    cmd.extend(build_flags)
    cmd.append(str(harness_source_path))

    # Set environment variables for the subprocess
    env = os.environ.copy()
    env.update(env_vars)

    try:
        subprocess.run(
            cmd,
            check=True,
            cwd=harness_source_path,
            env=env,
            capture_output=True,
            text=True,
        )
        logger.info(f"Successfully built Go harness '{harness_name}' to {output_path}")
        return output_path
    except subprocess.CalledProcessError as e:
        logger.error(f"Go build failed for '{harness_name}': {e.stderr}")
        raise HarnessBuildError(f"Failed to build Go harness '{harness_name}': {e.stderr}") from e
    except FileNotFoundError:
        raise GoVersionError("Go executable not found. Please ensure Go is installed and in your PATH.")


def clean_go_harness_artifacts(harness_name: str, project_root: pathlib.Path) -> None:
    config = GO_HARNESS_CONFIG.get(harness_name)
    if not config:
        raise TofuSoupError(f"Configuration for Go harness '{harness_name}' not found.")

    output_bin_dir = project_root / "bin"
    output_path = output_bin_dir / config["output_name"]

    if output_path.exists():
        try:
            os.remove(output_path)
            logger.info(f"Cleaned Go harness '{harness_name}' at {output_path}")
        except OSError as e:
            logger.error(f"Failed to remove Go harness '{harness_name}': {e}")
            raise HarnessCleanError(f"Failed to clean Go harness '{harness_name}': {e}") from e
    else:
        logger.info(f"Go harness '{harness_name}' not found at {output_path}. Nothing to clean.")


def start_go_plugin_server_process(
    harness_name: str,
    project_root: pathlib.Path,
    loaded_config: dict[str, Any],
    cli_log_level: str | None = None,
    additional_args: list[str] | None = None,
    custom_env: dict[str, str] | None = None,
) -> subprocess.Popen:
    """
    Ensures a Go harness is built and starts it as a server process.
    """
    harness_executable_path = ensure_go_harness_build(harness_name, project_root, loaded_config)

    process_env = os.environ.copy()
    if custom_env:
        process_env.update(custom_env)

    cmd = [str(harness_executable_path)]
    if additional_args:
        cmd.extend(additional_args)

    try:
        return subprocess.Popen(cmd, env=process_env)
    except Exception as e:
        raise TofuSoupError(f"Failed to start Go plugin server '{harness_name}': {e}") from e


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 39: tofusoup/harness/proto/__init__.py | checksum=92c959111643... | modified=2025-09-17T17:32:12 | op=+ | size=61 | tokens=29 | type=x-python ###
<<< BOF <<<
#
# tofusoup/harness/proto/__init__.py
#

# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 40: tofusoup/harness/proto/counter/kv.pb.go | checksum=f7724d127c3a... | modified=2025-08-09T10:36:34 | op=+ | size=13870 | tokens=5435 | type=x-go ###
<<< BOF <<<
//
// tofusoup/harness/proto/counter/kv.pb.go
//
package proto

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type GetRequest struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Key string `protobuf:"bytes,1,opt,name=key,proto3" json:"key,omitempty"`
}

func (x *GetRequest) Reset() {
	*x = GetRequest{}
	if protoimpl.UnsafeEnabled {
		mi := &file_proto_kv_proto_msgTypes[0]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *GetRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetRequest) ProtoMessage() {}

func (x *GetRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_kv_proto_msgTypes[0]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetRequest.ProtoReflect.Descriptor instead.
func (*GetRequest) Descriptor() ([]byte, []int) {
	return file_proto_kv_proto_rawDescGZIP(), []int{0}
}

func (x *GetRequest) GetKey() string {
	if x != nil {
		return x.Key
	}
	return ""
}

type GetResponse struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Value int64 `protobuf:"varint,1,opt,name=value,proto3" json:"value,omitempty"`
}

func (x *GetResponse) Reset() {
	*x = GetResponse{}
	if protoimpl.UnsafeEnabled {
		mi := &file_proto_kv_proto_msgTypes[1]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *GetResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetResponse) ProtoMessage() {}

func (x *GetResponse) ProtoReflect() protoreflect.Message {
	mi := &file_proto_kv_proto_msgTypes[1]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetResponse.ProtoReflect.Descriptor instead.
func (*GetResponse) Descriptor() ([]byte, []int) {
	return file_proto_kv_proto_rawDescGZIP(), []int{1}
}

func (x *GetResponse) GetValue() int64 {
	if x != nil {
		return x.Value
	}
	return 0
}

type PutRequest struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	AddServer uint32 `protobuf:"varint,1,opt,name=add_server,json=addServer,proto3" json:"add_server,omitempty"`
	Key       string `protobuf:"bytes,2,opt,name=key,proto3" json:"key,omitempty"`
	Value     int64  `protobuf:"varint,3,opt,name=value,proto3" json:"value,omitempty"`
}

func (x *PutRequest) Reset() {
	*x = PutRequest{}
	if protoimpl.UnsafeEnabled {
		mi := &file_proto_kv_proto_msgTypes[2]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *PutRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PutRequest) ProtoMessage() {}

func (x *PutRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_kv_proto_msgTypes[2]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PutRequest.ProtoReflect.Descriptor instead.
func (*PutRequest) Descriptor() ([]byte, []int) {
	return file_proto_kv_proto_rawDescGZIP(), []int{2}
}

func (x *PutRequest) GetAddServer() uint32 {
	if x != nil {
		return x.AddServer
	}
	return 0
}

func (x *PutRequest) GetKey() string {
	if x != nil {
		return x.Key
	}
	return ""
}

func (x *PutRequest) GetValue() int64 {
	if x != nil {
		return x.Value
	}
	return 0
}

type Empty struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields
}

func (x *Empty) Reset() {
	*x = Empty{}
	if protoimpl.UnsafeEnabled {
		mi := &file_proto_kv_proto_msgTypes[3]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *Empty) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Empty) ProtoMessage() {}

func (x *Empty) ProtoReflect() protoreflect.Message {
	mi := &file_proto_kv_proto_msgTypes[3]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Empty.ProtoReflect.Descriptor instead.
func (*Empty) Descriptor() ([]byte, []int) {
	return file_proto_kv_proto_rawDescGZIP(), []int{3}
}

type SumRequest struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	A int64 `protobuf:"varint,1,opt,name=a,proto3" json:"a,omitempty"`
	B int64 `protobuf:"varint,2,opt,name=b,proto3" json:"b,omitempty"`
}

func (x *SumRequest) Reset() {
	*x = SumRequest{}
	if protoimpl.UnsafeEnabled {
		mi := &file_proto_kv_proto_msgTypes[4]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *SumRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SumRequest) ProtoMessage() {}

func (x *SumRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_kv_proto_msgTypes[4]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SumRequest.ProtoReflect.Descriptor instead.
func (*SumRequest) Descriptor() ([]byte, []int) {
	return file_proto_kv_proto_rawDescGZIP(), []int{4}
}

func (x *SumRequest) GetA() int64 {
	if x != nil {
		return x.A
	}
	return 0
}

func (x *SumRequest) GetB() int64 {
	if x != nil {
		return x.B
	}
	return 0
}

type SumResponse struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	R int64 `protobuf:"varint,1,opt,name=r,proto3" json:"r,omitempty"`
}

func (x *SumResponse) Reset() {
	*x = SumResponse{}
	if protoimpl.UnsafeEnabled {
		mi := &file_proto_kv_proto_msgTypes[5]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *SumResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SumResponse) ProtoMessage() {}

func (x *SumResponse) ProtoReflect() protoreflect.Message {
	mi := &file_proto_kv_proto_msgTypes[5]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SumResponse.ProtoReflect.Descriptor instead.
func (*SumResponse) Descriptor() ([]byte, []int) {
	return file_proto_kv_proto_rawDescGZIP(), []int{5}
}

func (x *SumResponse) GetR() int64 {
	if x != nil {
		return x.R
	}
	return 0
}

var File_proto_kv_proto protoreflect.FileDescriptor

var file_proto_kv_proto_rawDesc = []byte{
	0x0a, 0x0e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x2f, 0x6b, 0x76, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f,
	0x12, 0x05, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x22, 0x1e, 0x0a, 0x0a, 0x47, 0x65, 0x74, 0x52, 0x65,
	0x71, 0x75, 0x65, 0x73, 0x74, 0x12, 0x10, 0x0a, 0x03, 0x6b, 0x65, 0x79, 0x18, 0x01, 0x20, 0x01,
	0x28, 0x09, 0x52, 0x03, 0x6b, 0x65, 0x79, 0x22, 0x23, 0x0a, 0x0b, 0x47, 0x65, 0x74, 0x52, 0x65,
	0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x12, 0x14, 0x0a, 0x05, 0x76, 0x61, 0x6c, 0x75, 0x65, 0x18,
	0x01, 0x20, 0x01, 0x28, 0x03, 0x52, 0x05, 0x76, 0x61, 0x6c, 0x75, 0x65, 0x22, 0x53, 0x0a, 0x0a,
	0x50, 0x75, 0x74, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x12, 0x1d, 0x0a, 0x0a, 0x61, 0x64,
	0x64, 0x5f, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0d, 0x52, 0x09,
	0x61, 0x64, 0x64, 0x53, 0x65, 0x72, 0x76, 0x65, 0x72, 0x12, 0x10, 0x0a, 0x03, 0x6b, 0x65, 0x79,
	0x18, 0x02, 0x20, 0x01, 0x28, 0x09, 0x52, 0x03, 0x6b, 0x65, 0x79, 0x12, 0x14, 0x0a, 0x05, 0x76,
	0x61, 0x6c, 0x75, 0x65, 0x18, 0x03, 0x20, 0x01, 0x28, 0x03, 0x52, 0x05, 0x76, 0x61, 0x6c, 0x75,
	0x65, 0x22, 0x07, 0x0a, 0x05, 0x45, 0x6d, 0x70, 0x74, 0x79, 0x22, 0x28, 0x0a, 0x0a, 0x53, 0x75,
	0x6d, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x12, 0x0c, 0x0a, 0x01, 0x61, 0x18, 0x01, 0x20,
	0x01, 0x28, 0x03, 0x52, 0x01, 0x61, 0x12, 0x0c, 0x0a, 0x01, 0x62, 0x18, 0x02, 0x20, 0x01, 0x28,
	0x03, 0x52, 0x01, 0x62, 0x22, 0x1b, 0x0a, 0x0b, 0x53, 0x75, 0x6d, 0x52, 0x65, 0x73, 0x70, 0x6f,
	0x6e, 0x73, 0x65, 0x12, 0x0c, 0x0a, 0x01, 0x72, 0x18, 0x01, 0x20, 0x01, 0x28, 0x03, 0x52, 0x01,
	0x72, 0x32, 0x5f, 0x0a, 0x07, 0x43, 0x6f, 0x75, 0x6e, 0x74, 0x65, 0x72, 0x12, 0x2c, 0x0a, 0x03,
	0x47, 0x65, 0x74, 0x12, 0x11, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x2e, 0x47, 0x65, 0x74, 0x52,
	0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x1a, 0x12, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x2e, 0x47,
	0x65, 0x74, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x12, 0x26, 0x0a, 0x03, 0x50, 0x75,
	0x74, 0x12, 0x11, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x2e, 0x50, 0x75, 0x74, 0x52, 0x65, 0x71,
	0x75, 0x65, 0x73, 0x74, 0x1a, 0x0c, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x2e, 0x45, 0x6d, 0x70,
	0x74, 0x79, 0x32, 0x39, 0x0a, 0x09, 0x41, 0x64, 0x64, 0x48, 0x65, 0x6c, 0x70, 0x65, 0x72, 0x12,
	0x2c, 0x0a, 0x03, 0x53, 0x75, 0x6d, 0x12, 0x11, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x2e, 0x53,
	0x75, 0x6d, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x1a, 0x12, 0x2e, 0x70, 0x72, 0x6f, 0x74,
	0x6f, 0x2e, 0x53, 0x75, 0x6d, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x42, 0x09, 0x5a,
	0x07, 0x2e, 0x2f, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x62, 0x06, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x33,
}

var (
	file_proto_kv_proto_rawDescOnce sync.Once
	file_proto_kv_proto_rawDescData = file_proto_kv_proto_rawDesc
)

func file_proto_kv_proto_rawDescGZIP() []byte {
	file_proto_kv_proto_rawDescOnce.Do(func() {
		file_proto_kv_proto_rawDescData = protoimpl.X.CompressGZIP(file_proto_kv_proto_rawDescData)
	})
	return file_proto_kv_proto_rawDescData
}

var file_proto_kv_proto_msgTypes = make([]protoimpl.MessageInfo, 6)
var file_proto_kv_proto_goTypes = []interface{}{
	(*GetRequest)(nil),  // 0: proto.GetRequest
	(*GetResponse)(nil), // 1: proto.GetResponse
	(*PutRequest)(nil),  // 2: proto.PutRequest
	(*Empty)(nil),       // 3: proto.Empty
	(*SumRequest)(nil),  // 4: proto.SumRequest
	(*SumResponse)(nil), // 5: proto.SumResponse
}
var file_proto_kv_proto_depIdxs = []int32{
	0, // 0: proto.Counter.Get:input_type -> proto.GetRequest
	2, // 1: proto.Counter.Put:input_type -> proto.PutRequest
	4, // 2: proto.AddHelper.Sum:input_type -> proto.SumRequest
	1, // 3: proto.Counter.Get:output_type -> proto.GetResponse
	3, // 4: proto.Counter.Put:output_type -> proto.Empty
	5, // 5: proto.AddHelper.Sum:output_type -> proto.SumResponse
	3, // [3:6] is the sub-list for method output_type
	0, // [0:3] is the sub-list for method input_type
	0, // [0:0] is the sub-list for extension type_name
	0, // [0:0] is the sub-list for extension extendee
	0, // [0:0] is the sub-list for field type_name
}

func init() { file_proto_kv_proto_init() }
func file_proto_kv_proto_init() {
	if File_proto_kv_proto != nil {
		return
	}
	if !protoimpl.UnsafeEnabled {
		file_proto_kv_proto_msgTypes[0].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*GetRequest); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_proto_kv_proto_msgTypes[1].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*GetResponse); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_proto_kv_proto_msgTypes[2].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*PutRequest); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_proto_kv_proto_msgTypes[3].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*Empty); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_proto_kv_proto_msgTypes[4].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*SumRequest); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_proto_kv_proto_msgTypes[5].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*SumResponse); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: file_proto_kv_proto_rawDesc,
			NumEnums:      0,
			NumMessages:   6,
			NumExtensions: 0,
			NumServices:   2,
		},
		GoTypes:           file_proto_kv_proto_goTypes,
		DependencyIndexes: file_proto_kv_proto_depIdxs,
		MessageInfos:      file_proto_kv_proto_msgTypes,
	}.Build()
	File_proto_kv_proto = out.File
	file_proto_kv_proto_rawDesc = nil
	file_proto_kv_proto_goTypes = nil
	file_proto_kv_proto_depIdxs = nil
}

// 🍲🥄📄🪄
>>> EOF >>>

### FILE 41: tofusoup/harness/proto/counter/kv_grpc.pb.go | checksum=e29525d24078... | modified=2025-08-09T10:36:34 | op=+ | size=7613 | tokens=1858 | type=x-go ###
<<< BOF <<<
//
// tofusoup/harness/proto/counter/kv_grpc.pb.go
//
// Code generated by protoc-gen-go-grpc. DO NOT EDIT.
// versions:
// - protoc-gen-go-grpc v1.3.0
// - protoc             (unknown)
// source: proto/kv.proto

package proto

import (
	context "context"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
)

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
// Requires gRPC-Go v1.32.0 or later.
const _ = grpc.SupportPackageIsVersion7

const (
	Counter_Get_FullMethodName = "/proto.Counter/Get"
	Counter_Put_FullMethodName = "/proto.Counter/Put"
)

// CounterClient is the client API for Counter service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type CounterClient interface {
	Get(ctx context.Context, in *GetRequest, opts ...grpc.CallOption) (*GetResponse, error)
	Put(ctx context.Context, in *PutRequest, opts ...grpc.CallOption) (*Empty, error)
}

type counterClient struct {
	cc grpc.ClientConnInterface
}

func NewCounterClient(cc grpc.ClientConnInterface) CounterClient {
	return &counterClient{cc}
}

func (c *counterClient) Get(ctx context.Context, in *GetRequest, opts ...grpc.CallOption) (*GetResponse, error) {
	out := new(GetResponse)
	err := c.cc.Invoke(ctx, Counter_Get_FullMethodName, in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *counterClient) Put(ctx context.Context, in *PutRequest, opts ...grpc.CallOption) (*Empty, error) {
	out := new(Empty)
	err := c.cc.Invoke(ctx, Counter_Put_FullMethodName, in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// CounterServer is the server API for Counter service.
// All implementations should embed UnimplementedCounterServer
// for forward compatibility
type CounterServer interface {
	Get(context.Context, *GetRequest) (*GetResponse, error)
	Put(context.Context, *PutRequest) (*Empty, error)
}

// UnimplementedCounterServer should be embedded to have forward compatible implementations.
type UnimplementedCounterServer struct {
}

func (UnimplementedCounterServer) Get(context.Context, *GetRequest) (*GetResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method Get not implemented")
}
func (UnimplementedCounterServer) Put(context.Context, *PutRequest) (*Empty, error) {
	return nil, status.Errorf(codes.Unimplemented, "method Put not implemented")
}

// UnsafeCounterServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to CounterServer will
// result in compilation errors.
type UnsafeCounterServer interface {
	mustEmbedUnimplementedCounterServer()
}

func RegisterCounterServer(s grpc.ServiceRegistrar, srv CounterServer) {
	s.RegisterService(&Counter_ServiceDesc, srv)
}

func _Counter_Get_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(GetRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(CounterServer).Get(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: Counter_Get_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(CounterServer).Get(ctx, req.(*GetRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _Counter_Put_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(PutRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(CounterServer).Put(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: Counter_Put_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(CounterServer).Put(ctx, req.(*PutRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// Counter_ServiceDesc is the grpc.ServiceDesc for Counter service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var Counter_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "proto.Counter",
	HandlerType: (*CounterServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Get",
			Handler:    _Counter_Get_Handler,
		},
		{
			MethodName: "Put",
			Handler:    _Counter_Put_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "proto/kv.proto",
}

const (
	AddHelper_Sum_FullMethodName = "/proto.AddHelper/Sum"
)

// AddHelperClient is the client API for AddHelper service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type AddHelperClient interface {
	Sum(ctx context.Context, in *SumRequest, opts ...grpc.CallOption) (*SumResponse, error)
}

type addHelperClient struct {
	cc grpc.ClientConnInterface
}

func NewAddHelperClient(cc grpc.ClientConnInterface) AddHelperClient {
	return &addHelperClient{cc}
}

func (c *addHelperClient) Sum(ctx context.Context, in *SumRequest, opts ...grpc.CallOption) (*SumResponse, error) {
	out := new(SumResponse)
	err := c.cc.Invoke(ctx, AddHelper_Sum_FullMethodName, in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// AddHelperServer is the server API for AddHelper service.
// All implementations should embed UnimplementedAddHelperServer
// for forward compatibility
type AddHelperServer interface {
	Sum(context.Context, *SumRequest) (*SumResponse, error)
}

// UnimplementedAddHelperServer should be embedded to have forward compatible implementations.
type UnimplementedAddHelperServer struct {
}

func (UnimplementedAddHelperServer) Sum(context.Context, *SumRequest) (*SumResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method Sum not implemented")
}

// UnsafeAddHelperServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to AddHelperServer will
// result in compilation errors.
type UnsafeAddHelperServer interface {
	mustEmbedUnimplementedAddHelperServer()
}

func RegisterAddHelperServer(s grpc.ServiceRegistrar, srv AddHelperServer) {
	s.RegisterService(&AddHelper_ServiceDesc, srv)
}

func _AddHelper_Sum_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(SumRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(AddHelperServer).Sum(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: AddHelper_Sum_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(AddHelperServer).Sum(ctx, req.(*SumRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// AddHelper_ServiceDesc is the grpc.ServiceDesc for AddHelper service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var AddHelper_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "proto.AddHelper",
	HandlerType: (*AddHelperServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Sum",
			Handler:    _AddHelper_Sum_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "proto/kv.proto",
}

// 🍲🥄📄🪄
>>> EOF >>>

### FILE 42: tofusoup/harness/proto/kv/__init__.py | checksum=92dc01d6e243... | modified=2025-09-17T17:32:12 | op=+ | size=186 | tokens=73 | type=x-python ###
<<< BOF <<<
#
# tofusoup/harness/proto/kv/__init__.py
#
from . import kv_pb2, kv_pb2_grpc
from .kv_protocol import KVProtocol

__all__ = ["KVProtocol", "kv_pb2", "kv_pb2_grpc"]


# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 43: tofusoup/harness/proto/kv/kv.pb.go | checksum=a82115239821... | modified=2025-08-09T10:36:34 | op=+ | size=9546 | tokens=3625 | type=x-go ###
<<< BOF <<<
//
// tofusoup/harness/proto/kv/kv.pb.go
//
package proto

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type GetRequest struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Key string `protobuf:"bytes,1,opt,name=key,proto3" json:"key,omitempty"`
}

func (x *GetRequest) Reset() {
	*x = GetRequest{}
	if protoimpl.UnsafeEnabled {
		mi := &file_proto_kv_proto_msgTypes[0]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *GetRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetRequest) ProtoMessage() {}

func (x *GetRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_kv_proto_msgTypes[0]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetRequest.ProtoReflect.Descriptor instead.
func (*GetRequest) Descriptor() ([]byte, []int) {
	return file_proto_kv_proto_rawDescGZIP(), []int{0}
}

func (x *GetRequest) GetKey() string {
	if x != nil {
		return x.Key
	}
	return ""
}

type GetResponse struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Value []byte `protobuf:"bytes,1,opt,name=value,proto3" json:"value,omitempty"`
}

func (x *GetResponse) Reset() {
	*x = GetResponse{}
	if protoimpl.UnsafeEnabled {
		mi := &file_proto_kv_proto_msgTypes[1]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *GetResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetResponse) ProtoMessage() {}

func (x *GetResponse) ProtoReflect() protoreflect.Message {
	mi := &file_proto_kv_proto_msgTypes[1]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetResponse.ProtoReflect.Descriptor instead.
func (*GetResponse) Descriptor() ([]byte, []int) {
	return file_proto_kv_proto_rawDescGZIP(), []int{1}
}

func (x *GetResponse) GetValue() []byte {
	if x != nil {
		return x.Value
	}
	return nil
}

type PutRequest struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Key   string `protobuf:"bytes,1,opt,name=key,proto3" json:"key,omitempty"`
	Value []byte `protobuf:"bytes,2,opt,name=value,proto3" json:"value,omitempty"`
}

func (x *PutRequest) Reset() {
	*x = PutRequest{}
	if protoimpl.UnsafeEnabled {
		mi := &file_proto_kv_proto_msgTypes[2]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *PutRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PutRequest) ProtoMessage() {}

func (x *PutRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_kv_proto_msgTypes[2]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PutRequest.ProtoReflect.Descriptor instead.
func (*PutRequest) Descriptor() ([]byte, []int) {
	return file_proto_kv_proto_rawDescGZIP(), []int{2}
}

func (x *PutRequest) GetKey() string {
	if x != nil {
		return x.Key
	}
	return ""
}

func (x *PutRequest) GetValue() []byte {
	if x != nil {
		return x.Value
	}
	return nil
}

type Empty struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields
}

func (x *Empty) Reset() {
	*x = Empty{}
	if protoimpl.UnsafeEnabled {
		mi := &file_proto_kv_proto_msgTypes[3]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *Empty) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Empty) ProtoMessage() {}

func (x *Empty) ProtoReflect() protoreflect.Message {
	mi := &file_proto_kv_proto_msgTypes[3]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Empty.ProtoReflect.Descriptor instead.
func (*Empty) Descriptor() ([]byte, []int) {
	return file_proto_kv_proto_rawDescGZIP(), []int{3}
}

var File_proto_kv_proto protoreflect.FileDescriptor

var file_proto_kv_proto_rawDesc = []byte{
	0x0a, 0x0e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x2f, 0x6b, 0x76, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f,
	0x12, 0x05, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x22, 0x1e, 0x0a, 0x0a, 0x47, 0x65, 0x74, 0x52, 0x65,
	0x71, 0x75, 0x65, 0x73, 0x74, 0x12, 0x10, 0x0a, 0x03, 0x6b, 0x65, 0x79, 0x18, 0x01, 0x20, 0x01,
	0x28, 0x09, 0x52, 0x03, 0x6b, 0x65, 0x79, 0x22, 0x23, 0x0a, 0x0b, 0x47, 0x65, 0x74, 0x52, 0x65,
	0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x12, 0x14, 0x0a, 0x05, 0x76, 0x61, 0x6c, 0x75, 0x65, 0x18,
	0x01, 0x20, 0x01, 0x28, 0x0c, 0x52, 0x05, 0x76, 0x61, 0x6c, 0x75, 0x65, 0x22, 0x34, 0x0a, 0x0a,
	0x50, 0x75, 0x74, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x12, 0x10, 0x0a, 0x03, 0x6b, 0x65,
	0x79, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x03, 0x6b, 0x65, 0x79, 0x12, 0x14, 0x0a, 0x05,
	0x76, 0x61, 0x6c, 0x75, 0x65, 0x18, 0x02, 0x20, 0x01, 0x28, 0x0c, 0x52, 0x05, 0x76, 0x61, 0x6c,
	0x75, 0x65, 0x22, 0x07, 0x0a, 0x05, 0x45, 0x6d, 0x70, 0x74, 0x79, 0x32, 0x5a, 0x0a, 0x02, 0x4b,
	0x56, 0x12, 0x2c, 0x0a, 0x03, 0x47, 0x65, 0x74, 0x12, 0x11, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f,
	0x2e, 0x47, 0x65, 0x74, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x1a, 0x12, 0x2e, 0x70, 0x72,
	0x6f, 0x74, 0x6f, 0x2e, 0x47, 0x65, 0x74, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x12,
	0x26, 0x0a, 0x03, 0x50, 0x75, 0x74, 0x12, 0x11, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x2e, 0x50,
	0x75, 0x74, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x1a, 0x0c, 0x2e, 0x70, 0x72, 0x6f, 0x74,
	0x6f, 0x2e, 0x45, 0x6d, 0x70, 0x74, 0x79, 0x42, 0x09, 0x5a, 0x07, 0x2e, 0x2f, 0x70, 0x72, 0x6f,
	0x74, 0x6f, 0x62, 0x06, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x33,
}

var (
	file_proto_kv_proto_rawDescOnce sync.Once
	file_proto_kv_proto_rawDescData = file_proto_kv_proto_rawDesc
)

func file_proto_kv_proto_rawDescGZIP() []byte {
	file_proto_kv_proto_rawDescOnce.Do(func() {
		file_proto_kv_proto_rawDescData = protoimpl.X.CompressGZIP(file_proto_kv_proto_rawDescData)
	})
	return file_proto_kv_proto_rawDescData
}

var file_proto_kv_proto_msgTypes = make([]protoimpl.MessageInfo, 4)
var file_proto_kv_proto_goTypes = []interface{}{
	(*GetRequest)(nil),  // 0: proto.GetRequest
	(*GetResponse)(nil), // 1: proto.GetResponse
	(*PutRequest)(nil),  // 2: proto.PutRequest
	(*Empty)(nil),       // 3: proto.Empty
}
var file_proto_kv_proto_depIdxs = []int32{
	0, // 0: proto.KV.Get:input_type -> proto.GetRequest
	2, // 1: proto.KV.Put:input_type -> proto.PutRequest
	1, // 2: proto.KV.Get:output_type -> proto.GetResponse
	3, // 3: proto.KV.Put:output_type -> proto.Empty
	2, // [2:4] is the sub-list for method output_type
	0, // [0:2] is the sub-list for method input_type
	0, // [0:0] is the sub-list for extension type_name
	0, // [0:0] is the sub-list for extension extendee
	0, // [0:0] is the sub-list for field type_name
}

func init() { file_proto_kv_proto_init() }
func file_proto_kv_proto_init() {
	if File_proto_kv_proto != nil {
		return
	}
	if !protoimpl.UnsafeEnabled {
		file_proto_kv_proto_msgTypes[0].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*GetRequest); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_proto_kv_proto_msgTypes[1].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*GetResponse); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_proto_kv_proto_msgTypes[2].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*PutRequest); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_proto_kv_proto_msgTypes[3].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*Empty); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: file_proto_kv_proto_rawDesc,
			NumEnums:      0,
			NumMessages:   4,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_proto_kv_proto_goTypes,
		DependencyIndexes: file_proto_kv_proto_depIdxs,
		MessageInfos:      file_proto_kv_proto_msgTypes,
	}.Build()
	File_proto_kv_proto = out.File
	file_proto_kv_proto_rawDesc = nil
	file_proto_kv_proto_goTypes = nil
	file_proto_kv_proto_depIdxs = nil
}

// 🍲🥄📄🪄
>>> EOF >>>

### FILE 44: tofusoup/harness/proto/kv/kv_grpc.pb.go | checksum=3c540211a056... | modified=2025-08-09T10:36:34 | op=+ | size=4475 | tokens=1169 | type=x-go ###
<<< BOF <<<
//
// tofusoup/harness/proto/kv/kv_grpc.pb.go
//
// Code generated by protoc-gen-go-grpc. DO NOT EDIT.
// versions:
// - protoc-gen-go-grpc v1.3.0
// - protoc             (unknown)
// source: proto/kv.proto

package proto

import (
	context "context"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
)

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
// Requires gRPC-Go v1.32.0 or later.
const _ = grpc.SupportPackageIsVersion7

const (
	KV_Get_FullMethodName = "/proto.KV/Get"
	KV_Put_FullMethodName = "/proto.KV/Put"
)

// KVClient is the client API for KV service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type KVClient interface {
	Get(ctx context.Context, in *GetRequest, opts ...grpc.CallOption) (*GetResponse, error)
	Put(ctx context.Context, in *PutRequest, opts ...grpc.CallOption) (*Empty, error)
}

type kVClient struct {
	cc grpc.ClientConnInterface
}

func NewKVClient(cc grpc.ClientConnInterface) KVClient {
	return &kVClient{cc}
}

func (c *kVClient) Get(ctx context.Context, in *GetRequest, opts ...grpc.CallOption) (*GetResponse, error) {
	out := new(GetResponse)
	err := c.cc.Invoke(ctx, KV_Get_FullMethodName, in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kVClient) Put(ctx context.Context, in *PutRequest, opts ...grpc.CallOption) (*Empty, error) {
	out := new(Empty)
	err := c.cc.Invoke(ctx, KV_Put_FullMethodName, in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// KVServer is the server API for KV service.
// All implementations should embed UnimplementedKVServer
// for forward compatibility
type KVServer interface {
	Get(context.Context, *GetRequest) (*GetResponse, error)
	Put(context.Context, *PutRequest) (*Empty, error)
}

// UnimplementedKVServer should be embedded to have forward compatible implementations.
type UnimplementedKVServer struct {
}

func (UnimplementedKVServer) Get(context.Context, *GetRequest) (*GetResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method Get not implemented")
}
func (UnimplementedKVServer) Put(context.Context, *PutRequest) (*Empty, error) {
	return nil, status.Errorf(codes.Unimplemented, "method Put not implemented")
}

// UnsafeKVServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to KVServer will
// result in compilation errors.
type UnsafeKVServer interface {
	mustEmbedUnimplementedKVServer()
}

func RegisterKVServer(s grpc.ServiceRegistrar, srv KVServer) {
	s.RegisterService(&KV_ServiceDesc, srv)
}

func _KV_Get_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(GetRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KVServer).Get(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: KV_Get_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KVServer).Get(ctx, req.(*GetRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _KV_Put_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(PutRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KVServer).Put(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: KV_Put_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KVServer).Put(ctx, req.(*PutRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// KV_ServiceDesc is the grpc.ServiceDesc for KV service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var KV_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "proto.KV",
	HandlerType: (*KVServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Get",
			Handler:    _KV_Get_Handler,
		},
		{
			MethodName: "Put",
			Handler:    _KV_Put_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "proto/kv.proto",
}

// 🍲🥄📄🪄
>>> EOF >>>

### FILE 45: tofusoup/harness/proto/kv/kv_protocol.py | checksum=8b084647c76e... | modified=2025-09-17T17:32:12 | op=+ | size=1194 | tokens=283 | type=x-python ###
<<< BOF <<<
#
# tofusoup/harness/proto/kv/kv_protocol.py
#
from typing import Any

from provide.foundation import logger

from pyvider.rpcplugin.protocol import RPCPluginProtocol

from . import kv_pb2_grpc


class KVProtocol(RPCPluginProtocol):
    """Protocol implementation for KV service using centralized proto."""

    async def get_grpc_descriptors(self) -> tuple[Any, str]:
        """Get the gRPC service descriptors."""
        return kv_pb2_grpc, "KV"

    async def add_to_server(self, server, handler) -> None:
        logger.debug("🔌📡🚀 KVProtocol.add_to_server: Registering KV service")

        if not hasattr(handler, "Get") or not callable(handler.Get):
            logger.error("🔌📡❌ KVProtocol handler missing required 'Get' method")
            raise ValueError("Invalid KV handler: missing 'Get' method")

        if not hasattr(handler, "Put") or not callable(handler.Put):
            logger.error("🔌📡❌ KVProtocol handler missing required 'Put' method")
            raise ValueError("Invalid KV handler: missing 'Put' method")

        # Register the KV service implementation
        kv_pb2_grpc.add_KVServicer_to_server(handler, server)


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 46: tofusoup/harness/python/conftest.py | checksum=eb757b569fc4... | modified=2025-09-17T17:32:12 | op=+ | size=10137 | tokens=2341 | type=x-python ###
<<< BOF <<<
#
# tofusoup/harness/python/conftest.py
#
from pathlib import Path
import subprocess

import pytest


def build_harness(harness_name: str, source_path: Path) -> Path:
    """Helper to build a Go harness into the venv."""
    # Assume script is run from `tofusoup` directory, so .venv is at root
    venv_bin = Path(".venv/bin")
    venv_bin.mkdir(exist_ok=True)
    executable_path = venv_bin / harness_name

    # Simple check to avoid rebuilding on every test run
    if executable_path.exists():
        return executable_path

    cmd = ["go", "build", "-o", str(executable_path), str(source_path)]
    result = subprocess.run(cmd, capture_output=True, text=True, cwd=source_path.parent)
    if result.returncode != 0:
        pytest.fail(
            f"Failed to build Go harness '{harness_name}':\n{result.stderr}",
            pytrace=False,
        )
    return executable_path


@pytest.fixture(scope="session")
def go_cty_harness(request) -> Path:
    # Use request.config.rootpath to find the harness relative to the test root
    root_path = request.config.rootpath
    # Adjusted path to new Go harness location
    source_file = root_path / "harnesses/go/cty-generic/harness.go"
    if not source_file.exists():
        # Also check the cty-owf harness as it was similar
        source_file_owf = root_path / "harnesses/go/cty-owf/main.go"  # Assuming main.go is the entry
        if source_file_owf.exists():
            source_file = source_file_owf
            harness_name = "go-cty-owf-harness"
        else:
            pytest.skip(f"Go CTY harness source not found at {source_file} or {source_file_owf}.")
            return  # Should not be reached if skip works
    else:
        harness_name = "go-cty-generic-harness"  # Default name if primary found

    return build_harness(harness_name, source_file)


@pytest.fixture(scope="session")
def go_tfwire_harness(request) -> Path:
    root_path = request.config.rootpath
    # Adjusted path to new Go harness location
    source_file = root_path / "harnesses/go/tfwire/harness.go"
    if not source_file.exists():
        pytest.skip(f"Go TF-Wire harness source not found at {source_file}.")
    return build_harness("go-tfwire-harness", source_file)


@pytest.fixture(scope="session")
def go_kvstore_harness(request) -> Path:
    root_path = request.config.rootpath
    # Path should align with where `generate-harness kvstore-go` places it or its source.
    # Assuming `harnesses/go/rpc-kvstore/server/main.go` is the source for the server part.
    # The actual binary built by `ensure_go_harness_build` (called by test logic)
    # will be used by the tests. This fixture provides the *source* path convention if needed,
    # or could directly provide the *built* path if ensure_go_harness_build is called here.
    # For now, let's assume `ensure_go_harness_build("kvstore-go", root_path)` will be called
    # by the test execution logic (e.g. in `tofusoup.testing.logic.run_test_suite`)
    # and this fixture could provide a conventional name or path if tests needed to refer to it
    # beyond what the test logic already handles.

    # For tests that need to *start* the Go server with specific crypto,
    # this fixture might need to be more complex, or the test logic itself
    # would handle calling `ensure_go_harness_build` and then running the binary with args.

    # Let's have this fixture ensure the build and return the path to the executable.
    # This centralizes the build call for this specific harness.
    try:
        from tofusoup.harness.logic import (
            ensure_go_harness_build,
        )  # Local import to avoid top-level issues if problematic

        # The name "kvstore-go" should match a key in GO_HARNESS_CONFIG in harness.logic
        ensure_go_harness_build("kvstore-go", root_path)  # ensure_go_harness_build returns the bin dir

        # The actual executable name might vary. Common patterns: <harness_name> or main
        # Based on kvproto, it's likely 'kv-go-server' or compiled from 'plugin-go-server/main.go'
        # Let's assume ensure_go_harness_build places it predictably or returns the full path.
        # For now, assume the harness logic places it as "kvstore-go-server" in the returned dir.
        # This needs to align with the output of `generate-harness kvstore-go`.
        # The `plugin-go-server/main.go` from kvproto builds to `kv-go-server`.
        # The `go-harnesses/rpc/kvstore/` (used by soup generate-harness) also has a server.
        # Let's assume `generate-harness kvstore-go` produces `kvstore-server-go` in a general bin.

        # The ensure_go_harness_build should return the path to the directory containing the binary.
        # The actual name of the binary needs to be known.
        # `soup rpc kv server-start` assumes `kvstore-server-go` in `harness_path / "bin" / "kvstore-server-go"`
        # Let's assume `ensure_go_harness_build` returns the root of the harness build (e.g. .../tofusoup/harness/go/bin/go-rpc )
        # and the binary is at a known relative path like `bin/kvstore-server-go` or the name from GO_HARNESS_CONFIG.

        # For simplicity, this fixture will just return the directory provided by ensure_go_harness_build.
        # The test will then construct the full path to the executable.
        # A more robust fixture would return the full executable path.

        # Let's refine: assume `ensure_go_harness_build` returns the specific binary path directly.
        # This requires `harness.logic.ensure_go_harness_build` to be updated or to have a helper.
        # For now, let's assume it returns the directory, and we append the known name.
        # This needs to align with `soup rpc kv server-start` logic.
        # It uses: harness_path / "bin" / "kvstore-server-go"
        # where harness_path is from ensure_go_harness_build("kvstore-go", project_root)
        # So, ensure_go_harness_build must return the root of the specific harness deployment.

        # The `ensure_go_harness_build` in `tofusoup.harness.logic` is responsible for building
        # AND returning the path to the executable (or a directory from which it can be found).
        # The key "kvstore-go" must be defined in `GO_HARNESS_CONFIG` within `harness.logic.py`.

        # This fixture will ensure it's built and return the path to the executable.
        # The current `ensure_go_harness_build` in the plan returns the harness *root* dir.
        # Let's assume the build process places the binary at a known relative path from that root.
        # Or, `ensure_go_harness_build` should be enhanced to return the direct executable path.

        # For now, let this fixture just ensure it's built. The test logic will get the path.
        # This is consistent with how `run_test_suite` calls `ensure_go_harness_build`.
        # The test itself will then need to know the path to the executable.
        # This fixture is mainly for explicit invocation in tests if needed outside `run_test_suite`.

        # A simpler fixture: just provides the *name* of the harness key.
        # The test or test runner logic (`run_test_suite`) handles the building.
        # This avoids this conftest.py needing to know too much about build outputs.
        # return "kvstore-go" # The key for GO_HARNESS_CONFIG

        # Revised: Fixture should ensure build and provide path to the executable.
        # `ensure_go_harness_build` is expected to return the path to the directory
        # where binaries are placed, or directly to the binary.
        # Let's assume it returns the directory, and we know the executable name.
        harness_info = ensure_go_harness_build("kvstore-go", root_path)  # This should give us enough info

        # harness_info could be a Path to the binary, or a dict with details.
        # Assuming harness_info is the Path to the built executable itself, as per
        # the ideal outcome of ensure_go_harness_build for a specific harness.
        # If ensure_go_harness_build returns a directory, this needs adjustment:
        # e.g., harness_executable = harness_info / "bin" / "kvstore-server-go" (or similar)
        # This depends on the contract of ensure_go_harness_build and GO_HARNESS_CONFIG in harness.logic.
        # For now, let's assume ensure_go_harness_build returns the direct path to the executable.
        if (
            not isinstance(harness_info, Path)
            or not harness_info.exists()
            or not os.access(harness_info, os.X_OK)
        ):
            # If harness_info is a directory, try to find the executable
            if isinstance(harness_info, Path) and harness_info.is_dir():
                # Attempt to find a known executable name, this must match build output
                potential_exe_name = "kvstore-server-go"  # This name is assumed by rpc.cli.py
                exe_path = harness_info / "bin" / potential_exe_name
                if exe_path.exists() and os.access(exe_path, os.X_OK):
                    return exe_path
                # Fallback for older kvproto name if needed, or other conventions.
                potential_exe_name_alt = "kv-go-server"
                exe_path_alt = harness_info / "bin" / potential_exe_name_alt
                if exe_path_alt.exists() and os.access(exe_path_alt, os.X_OK):
                    return exe_path_alt
                pytest.fail(
                    f"Go KVStore server executable ('{potential_exe_name}' or '{potential_exe_name_alt}') not found in harness build dir: {harness_info}/bin"
                )
            else:
                pytest.fail(
                    f"ensure_go_harness_build for 'kvstore-go' did not return a valid executable path or directory. Got: {harness_info}"
                )
        return harness_info  # Assuming harness_info is the direct executable path

    except ImportError:
        pytest.skip(
            "TofuSoup harness logic (ensure_go_harness_build) not available, skipping Go KVStore harness dependent tests."
        )
    except Exception as e:
        pytest.fail(f"Failed to prepare Go KVStore harness fixture: {e}")


# 🍲🥄🧪🪄
>>> EOF >>>

### FILE 47: tofusoup/harness/python/py-cty/main.py | checksum=b885e0e0b38e... | modified=2025-10-10T13:10:53 | op=+ | size=1151 | tokens=281 | type=x-python ###
<<< BOF <<<
#!/usr/bin/env python3
#
# tofusoup/harness/python/py-cty/main.py
#
import json
import sys

sys.path.append("/app/pyvider-cty/src")

import click


@click.group()
def cli() -> None:
    pass


@cli.command()
@click.argument("input_file", type=click.File("r"))
def from_hcl_json(input_file) -> None:
    """
    Convert a CTY-JSON file (from go-hcl) to a JSONComparableValue.

    NOTE: This is a placeholder implementation for testing harness infrastructure.
    Currently performs pass-through. Full conversion logic to be implemented when needed.
    """
    hcl_json = json.load(input_file)
    print(json.dumps(hcl_json, indent=2))


@cli.command()
@click.argument("input_file", type=click.File("r"))
def to_hcl_json(input_file) -> None:
    """
    Convert a JSONComparableValue file back to a CTY-JSON file.

    NOTE: This is a placeholder implementation for testing harness infrastructure.
    Currently performs pass-through. Full conversion logic to be implemented when needed.
    """
    comparable_value = json.load(input_file)
    print(json.dumps(comparable_value, indent=2))


if __name__ == "__main__":
    cli()


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 48: tofusoup/harness/python/py-hcl/main.py | checksum=b3937e86f39e... | modified=2025-09-17T17:32:12 | op=+ | size=557 | tokens=160 | type=x-python ###
<<< BOF <<<
#!/usr/bin/env python3
#
# tofusoup/harness/python/py-hcl/main.py
#
import json
import sys

sys.path.append("/app/pyvider-hcl/src")
sys.path.append("/app/pyvider-cty/src")

import click

from pyvider import hcl


@click.group()
def cli() -> None:
    pass


@click.command()
@click.argument("input_file", type=click.File("r"))
def parse(input_file) -> None:
    """Parse an HCL file and print its structure as JSON."""
    hcl_dict = hcl.load(input_file)
    print(json.dumps(hcl_dict, indent=2))


if __name__ == "__main__":
    cli()


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 49: tofusoup/harness/python/py-wire/main.py | checksum=2177081b93d2... | modified=2025-09-17T17:32:12 | op=+ | size=410 | tokens=117 | type=x-python ###
<<< BOF <<<
#!/usr/bin/env python3
#
# tofusoup/harness/python/py-wire/main.py
#
import json

import click


@click.group()
def cli() -> None:
    pass


@cli.command()
@click.argument("input_file", type=click.File("r"))
def encode(input_file) -> None:
    """Encode data to JSON format."""
    data = json.load(input_file)
    print(json.dumps(data, indent=2))


if __name__ == "__main__":
    cli()


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 50: tofusoup/harness/python/tests_rpc/__init__.py | checksum=260d6bc5f20a... | modified=2025-09-17T17:32:12 | op=+ | size=72 | tokens=31 | type=x-python ###
<<< BOF <<<
#
# tofusoup/harness/python/tests_rpc/__init__.py
#

# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 51: tofusoup/harness/python/tests_rpc/souptest_rpc_pyclient_goserver.py | checksum=4391b9bbb828... | modified=2025-09-17T17:32:12 | op=+ | size=3430 | tokens=809 | type=x-python ###
<<< BOF <<<
#
# tofusoup/harness/python/tests_rpc/souptest_rpc_pyclient_goserver.py
#
# tofusoup/harness/python/tests_rpc/souptest_rpc_pyclient_goserver.py
#
# tofusoup/harness/python/tests_rpc/souptest_rpc_pyclient_goserver.py
#

import os  # For os.access and crypto options via env for client
from pathlib import Path

import pytest

from tofusoup.rpc.client import KVClient

# This test relies on the `go_kvstore_harness` fixture defined in
# `tofusoup/src/tofusoup/harness/python/conftest.py` (or eventually `conformance/conftest.py`)
# That fixture is responsible for ensuring the Go KVStore server harness is built
# and returning the path to its executable.


@pytest.mark.asyncio
async def test_pyclient_goserver_put_get(go_kvstore_harness: Path, tmp_path: Path) -> None:
    """
    Tests Put and Get operations between Python KVClient and the Go KVServer harness.
    The go_kvstore_harness fixture provides the path to the compiled Go server executable.
    The KVClient will start this Go server as a subprocess.
    """
    if not go_kvstore_harness.exists() or not os.access(go_kvstore_harness, os.X_OK):
        pytest.skip(f"Go KVStore harness executable not found or not executable at {go_kvstore_harness}")

    # For the Go server, crypto options are passed as command-line arguments to the harness.
    # The KVClient starts the server executable directly.
    # To test different crypto parameters for the Go server, the `go_kvstore_harness` fixture
    # itself would need to be parameterized to launch the Go server with different CLI args,
    # or the test would need to orchestrate this launch with specific args.

    # For this test, we'll use the default cert generation of the Go server harness.
    # Client-side crypto options are passed to KVClient constructor.
    # These will set env vars like PLUGIN_CLIENT_CERT_ALGO.
    # Their effectiveness depends on pyvider-rpcplugin client part.

    # Example: Test with specific client-side crypto settings (effectiveness depends on pyvider-rpcplugin)
    # For now, let's test without specific client crypto to ensure baseline works.
    client = KVClient(server_path=str(go_kvstore_harness))

    # To test with client crypto options:
    # client = KVClient(
    #     server_path=str(go_kvstore_harness),
    #     cert_algo="ecdsa", # Example
    #     cert_curve="P256"  # Example
    # )

    try:
        await client.start()  # This starts the Go server subprocess

        key = "test_py_go_key"
        value_str = "Hello from PyClient to GoServer!"
        value_bytes = value_str.encode("utf-8")

        await client.put(key, value_bytes)

        retrieved_value = await client.get(key)

        assert retrieved_value is not None
        assert retrieved_value.decode("utf-8") == value_str

        # Test getting a non-existent key
        retrieved_non_existent = await client.get("non_existent_key_py_go")
        assert retrieved_non_existent is None

    except Exception as e:
        # Attempt to include server's stderr if available (KVClient's _relay_stderr logs it)
        # For more direct access, KVClient might need to store last few stderr lines.
        pytest.fail(
            f"PyClient-GoServer test failed: {e}. Check logs for Go server stderr via KVClient's relay."
        )
    finally:
        if client:
            await client.close()  # This stops the Go server subprocess


# <3 🍲 🍜 🍥>


# 🍲🥄🧪🪄
>>> EOF >>>

### FILE 52: tofusoup/harness/python/tests_rpc/souptest_rpc_pyclient_pyserver.py | checksum=b4ec2bc04290... | modified=2025-09-17T17:32:12 | op=+ | size=9205 | tokens=2091 | type=x-python ###
<<< BOF <<<
#
# tofusoup/harness/python/tests_rpc/souptest_rpc_pyclient_pyserver.py
#
# tofusoup/harness/python/tests_rpc/souptest_rpc_pyclient_pyserver.py
#
# tofusoup/harness/python/tests_rpc/souptest_rpc_pyclient_pyserver.py
#

from pathlib import Path

import pytest

# Unused: import subprocess, time, tempfile, os
from tofusoup.rpc.client import KVClient

# For starting the server, we'd typically call the tofusoup CLI command
# or directly use the server's start function if it's easily importable and manageable.


# Placeholder for server process management.
# A proper fixture in conftest.py would be better.
@pytest.fixture(scope="module")
async def python_kv_server_process():
    """Starts the Python KV server as a subprocess for testing."""
    # Assuming tofusoup is installed and in path, or use sys.executable
    # We need to ensure the server runs in the background and we can get its port/endpoint.
    # The current tofusoup.rpc.server.start_kv_server() is a blocking call.
    # For testing, it might need to be adapted or run via `soup rpc kv server-start --py`
    # and its process managed.

    # This is a simplified placeholder. Real implementation needs robust process management
    # and a way to know when the server is ready (e.g., specific log output or health check).
    # The current `start_kv_server` blocks, so it's not directly usable in a fixture background.
    # We'll assume for now that `soup rpc kv server-start --py` can be run.
    # The `pyvider-rpcplugin` uses environment variables for communication, not a fixed port for TCP.
    # It typically uses named pipes or UDS on Unix.

    # For this placeholder, we'll just note that a server needs to be running.
    # In a real scenario, we'd start `soup rpc kv server-start --py`
    # and manage its lifecycle.
    # For now, this fixture doesn't actually start a server, tests will need a live one
    # or this needs to be implemented properly.

    # Let's try to run it as a subprocess.
    # This requires finding the tofusoup executable or using python -m tofusoup.cli

    # Using a temporary directory for KV store data, if server uses relative paths or specific tmp locations.
    # The current server uses /tmp/kv-data-*

    # Need to capture server output to know when it's ready, or wait a fixed time.
    # Also need to manage PLUGIN_HOST_ADDRESS for the client if the server outputs it.
    # pyvider-rpcplugin server usually prints "plugin address" to stdout.

    try:
        # Start the server process
        # Redirect stdout to capture the plugin address
        # Set a unique PLUGIN_SERVER_PATH for this server instance for the client to pick up.
        # This is complex because the client also tries to start the server if not using a fixed path.
        # For PyClient vs PyServer, they would typically run in the same process for test simplicity
        # or the test would orchestrate two separate processes.

        # Let's assume for this test, the server is started MANUALLY or by a higher-level test runner.
        # This test will try to connect to a server whose details are passed via env.
        # This fixture will be a NO-OP for now, highlighting the need for external server setup
        # or a more sophisticated fixture.
        # logger.warning("Python KV server fixture is a placeholder and does not start a server automatically.")
        # For now, these tests will likely fail unless a server is running.
        # A better approach for testing PyClient vs PyServer would be in-process if possible,
        # or a test harness that launches the server via `soup rpc kv server-start --py`
        # and then launches the client actions.

        # For the purpose of this file creation, let's assume a very basic subprocess management
        # that might not be robust enough for actual CI.
        # The server writes to /tmp, so no special data dir needed for this basic test.
        # The client connects using a path to the server executable, which is not what we're testing here.
        # This test is PyClient vs PyServer.

        # The `tofusoup.rpc.server.start_kv_server()` is an async function that blocks.
        # We need to run it in a separate process for the client to connect.
        # This is more of an integration test.

        # This fixture needs to be more advanced, likely using `multiprocessing` or `asyncio.create_subprocess_exec`
        # and managing the server lifecycle.
        # For now, we'll skip automatic server startup in this fixture.
        # The tests will assume the server is started by some other means if these are run directly.
        # Or, these tests would be integration tests run by `soup test rpc`.

        # This placeholder is insufficient. Actual RPC tests will require proper server lifecycle management.
        # For now, I will write a test that *would* run if a server was available.
        yield None
    finally:
        # if process and process.poll() is None:
        #     process.terminate()
        #     process.wait(timeout=5)
        pass


# This client also needs a server path. For Py-Py tests, this is tricky.
# If the server is run as a plugin by pyvider-rpcplugin, it's via a path to a script.
# For now, let's assume the client will connect to a server started by `soup rpc kv server-start --py`
# and the address is somehow known (e.g. fixed if not using go-plugin style dynamic addressing).
# The current `KVClient` requires a `server_path` to an executable, which is not how Py-Py usually works
# unless the Python server is also launched as a "plugin" executable by the client.

# The `tofusoup.rpc.cli.kv_server_start_command` when using `--py` directly calls `python_start_kv_server()`.
# This server uses `pyvider.rpcplugin.server.RPCPluginServer`.
# The `pyvider.rpcplugin.client.RPCPluginClient` expects a command to run for the server.

# This suggests that for PyClient vs PyServer tests using this framework,
# the Python server itself should be packaged or invoked as an executable script.
# Let `tofusoup/src/tofusoup/rpc/server.py` be that script.
# The client will then be configured with the path to this script.


@pytest.mark.asyncio
async def test_pyclient_pyserver_put_get(tmp_path) -> None:
    """
    Tests Put and Get operations between Python KVClient and Python KVServer.
    This test assumes `tofusoup/src/tofusoup/rpc/server.py` can act as a server executable.
    It further assumes that the `RPCPluginServer` started by `server.py`
    and `RPCPluginClient` used by `KVClient` can communicate (e.g. mTLS auto-negotiation).
    """
    python_server_script_path = Path(__file__).resolve().parents[4] / "src/tofusoup/rpc/server.py"
    if not python_server_script_path.exists():
        pytest.skip(f"Python KV server script not found at {python_server_script_path}")

    # The KVClient will attempt to start the server_path as a subprocess.
    # We need to ensure that the environment is set up correctly for this subprocess,
    # especially PYTHONPATH if tofusoup and pyvider are not installed globally in that env.
    # The `env.sh` script sets up the venv. When subprocess Popen is called, it might inherit env.

    # Create a unique temp directory for this test's server data to avoid collisions
    # The server currently writes to /tmp/kv-data-{key}. This needs to be made configurable
    # or tests need to manage this. For now, we accept this global state.

    # The client internally starts the server process.
    # The `plugin_env_for_server` in KVClient includes PLUGIN_AUTO_MTLS="true"
    # The `RPCPluginServer` in `server.py` also defaults to mTLS. They should work together.

    client = KVClient(server_path=str(python_server_script_path))

    try:
        await client.start()

        key = "test_py_py_key"
        value_str = "Hello from PyClient to PyServer!"
        value_bytes = value_str.encode("utf-8")

        await client.put(key, value_bytes)

        retrieved_value = await client.get(key)

        assert retrieved_value is not None
        assert retrieved_value.decode("utf-8") == value_str

        # Test getting a non-existent key
        retrieved_non_existent = await client.get("non_existent_key_py_py")
        assert retrieved_non_existent is None

    except Exception as e:
        # Log stderr from client._client._process if available
        stderr_output = "N/A"
        if (
            client
            and client._client
            and client._client._process
            and hasattr(client._client._process, "stderr_output_for_test")
        ):
            stderr_output = client._client._process.stderr_output_for_test  # type: ignore
        pytest.fail(f"PyClient-PyServer test failed: {e}\nServer stderr:\n{stderr_output}")
    finally:
        if client:
            await client.close()


# Note: This test structure relies heavily on RPCPluginClient being able to launch
# the rpc/server.py script and establish communication. This is essentially an integration
# test of the Python client and server using the pyvider-rpcplugin mechanisms.
# Simpler unit tests for KVHandler logic (if isolated from gRPC) would also be valuable.

# <3 🍲 🍜 🍥>


# 🍲🥄🧪🪄
>>> EOF >>>

### FILE 53: tofusoup/hcl/__init__.py | checksum=c014297f1d26... | modified=2025-09-17T17:32:12 | op=+ | size=51 | tokens=28 | type=x-python ###
<<< BOF <<<
#
# tofusoup/hcl/__init__.py
#

# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 54: tofusoup/hcl/cli.py | checksum=8427b128b7f6... | modified=2025-09-17T17:32:12 | op=+ | size=7031 | tokens=1651 | type=x-python ###
<<< BOF <<<
#!/usr/bin/env python3
#
# tofusoup/hcl/cli.py
#
"""
CLI commands for HCL operations.
"""

import pathlib
import sys

import click
from provide.foundation import logger  # Changed import
from rich import print as rich_print
from rich.tree import Tree

from tofusoup.common.exceptions import ConversionError, TofuSoupError

# from tofusoup.common.rich_utils import build_rich_tree_from_cty_json_comparable # Moved to common
from tofusoup.common.rich_utils import build_rich_tree_from_cty_json_comparable
from tofusoup.cty.logic import cty_value_to_json_comparable_dict  # For view command

from .logic import convert_hcl_file_to_output_format, load_hcl_file_as_cty

# logger = telemetry.get_logger(__name__) # Removed old way


@click.group("hcl")
def hcl_cli() -> None:
    """Commands for HCL (HashiCorp Configuration Language) operations."""
    pass


@hcl_cli.command("view")
@click.argument("filepath", type=click.Path(exists=True, dir_okay=False, readable=True))
@click.pass_context
def view_command(ctx, filepath: str) -> None:
    """Parses an HCL file and displays its structure as a CTY representation."""
    verbose = ctx.obj.get("VERBOSE", False)
    input_file_path = pathlib.Path(filepath)

    try:
        cty_value = load_hcl_file_as_cty(filepath)
        # Convert the CtyValue to the JSON-comparable dictionary structure for tree building
        comparable_dict = cty_value_to_json_comparable_dict(cty_value)

        tree_title = (
            f":page_facing_up: [bold blue]{input_file_path.name}[/bold blue] ([italic]HCL as CTY[/italic])"
        )
        rich_tree = Tree(tree_title)
        build_rich_tree_from_cty_json_comparable(rich_tree, comparable_dict, "HCL Root (as CTY)")
        rich_print(rich_tree)

    except ConversionError as e:  # Catch specific conversion errors from logic.py
        logger.error(
            f"Error processing HCL file: {e}", exc_info=verbose
        )  # exc_info=False if e.message is good
        sys.exit(1)
    except TofuSoupError as e:
        logger.error(f"Error: {e}", exc_info=verbose)
        sys.exit(1)
    except Exception as e:  # Catch-all for other unexpected issues
        logger.error(
            f"An unexpected error occurred while viewing HCL file: {e}",
            exc_info=verbose,
        )
        sys.exit(1)


@hcl_cli.command("convert")
@click.argument("input_file", type=click.Path(exists=True, dir_okay=False, readable=True))
@click.argument("output_file", type=click.Path(dir_okay=False, writable=True, allow_dash=True))
@click.option(
    "--output-format",
    "-of",
    "output_format_opt",
    type=click.Choice(["json", "msgpack"], case_sensitive=False),
    default=None,
    help='Format for the output. Inferred if not provided. Default can be set in soup.toml via command_options."hcl.convert".default_output_format.',
)
@click.pass_context
def convert_command(ctx, input_file: str, output_file: str, output_format_opt: str | None) -> None:
    """
    Converts an HCL file to JSON or Msgpack (via CTY representation).

    INPUT_FILE must be an HCL file.
    OUTPUT_FILE can be a file path or '-' for stdout.

    Examples:
      soup hcl convert my_config.tfvars output.json
      soup hcl convert deployment.hcl deployment.mpk
      soup hcl convert variables.tf - --output-format json # Output JSON to stdout
    """
    verbose = ctx.obj.get("VERBOSE", False)
    loaded_config = ctx.obj.get("TOFUSOUP_CONFIG", {})
    cmd_opts = loaded_config.get("command_options", {}).get("hcl.convert", {})

    actual_output_format = _determine_output_format(output_format_opt, cmd_opts, output_file)

    if verbose:  # Log final decision
        logger.info(
            f"Output: {output_file}, Using format: {actual_output_format} "
            f"(CLI option: {output_format_opt}, Config: {cmd_opts.get('default_output_format')})"
        )

    try:
        content_or_none = convert_hcl_file_to_output_format(
            input_filepath_str=input_file,
            output_filepath_str=output_file,
            output_format=actual_output_format,  # type: ignore
            output_to_stdout=(output_file == "-"),
        )

        if output_file == "-":
            _handle_stdout_output(content_or_none)
        else:
            rich_print(
                f"[green]HCL file '{input_file}' converted to {actual_output_format.upper()} "
                f"and saved to '{output_file}'[/green]"
            )

    except ConversionError as e:
        logger.error(f"HCL conversion failed: {e}", exc_info=verbose)
        sys.exit(1)
    except TofuSoupError as e:
        logger.error(f"Error: {e}", exc_info=verbose)
        sys.exit(1)
    except Exception as e:
        logger.error(f"An unexpected error occurred during HCL conversion: {e}", exc_info=verbose)
        sys.exit(1)


def _determine_output_format(output_format_opt: str | None, cmd_opts: dict, output_file: str) -> str:
    """Determine the output format from CLI, config, or file extension inference."""
    # CLI option takes precedence
    if output_format_opt:
        return output_format_opt

    # Try configuration default
    config_format = cmd_opts.get("default_output_format")
    if config_format:
        logger.debug(f"Using default output format '{config_format}' from soup.toml for hcl.convert")
        return config_format

    # Try inference from output file
    return _infer_output_format(output_file)


def _infer_output_format(output_file: str) -> str:
    """Infer output format from file extension."""
    if output_file == "-":
        logger.error(
            "Cannot infer output format when writing to stdout ('-'). "
            "Specify --output-format or set default_output_format in soup.toml for hcl.convert."
        )
        sys.exit(1)

    output_file_path_obj = pathlib.Path(output_file)
    ext_out = output_file_path_obj.suffix.lower()

    if ext_out == ".json":
        format_name = "json"
    elif ext_out in [".mpk", ".msgpack"]:
        format_name = "msgpack"
    else:
        logger.error(
            f"Could not infer output format for '{output_file}' from extension '{ext_out}'. "
            f"Supported: .json, .mpk, .msgpack. Specify --output-format or "
            f"set default_output_format in soup.toml for hcl.convert."
        )
        sys.exit(1)

    logger.debug(f"Inferred output format for HCL conversion as: {format_name}")
    return format_name


def _handle_stdout_output(content_or_none: str | bytes | None) -> None:
    """Handle output to stdout."""
    if isinstance(content_or_none, str):
        click.echo(content_or_none, nl=False)
        if not content_or_none.endswith("\n"):
            sys.stdout.write("\n")
    elif isinstance(content_or_none, bytes):
        if sys.stdout.isatty():
            rich_print(
                "[yellow]Warning:[/yellow] Msgpack output to TTY is binary. "
                "Consider saving to a file or piping."
            )
        sys.stdout.buffer.write(content_or_none)
        sys.stdout.buffer.flush()


# 🍲🥄🖥️🪄
>>> EOF >>>

### FILE 55: tofusoup/hcl/logic.py | checksum=0c063d4a839f... | modified=2025-09-17T17:32:12 | op=+ | size=2819 | tokens=677 | type=x-python ###
<<< BOF <<<
#
# tofusoup/hcl/logic.py
#
"""
Core HCL processing and conversion logic.
"""

import pathlib
from typing import Literal

from provide.foundation import logger

# Optional CTY integration
try:
    from pyvider.cty import CtyValue
    from pyvider.cty.conversion import cty_to_native

    HAS_CTY = True
except ImportError:
    HAS_CTY = False
    CtyValue = None

from tofusoup.common.exceptions import TofuSoupError
from tofusoup.common.serialization import (
    dump_python_to_json_string,
    dump_python_to_msgpack_bytes,
)

# FIX: Import the HCL parser from the centralized CTY logic module.
from tofusoup.cty.logic import load_cty_file_to_cty_value


def load_hcl_file_as_cty(filepath_str: str) -> CtyValue:
    """
    Loads an HCL file and parses it directly into a CtyValue.
    This is now a wrapper around the centralized CTY logic.
    """
    if not HAS_CTY:
        raise ImportError("HCL support requires 'pip install tofusoup[hcl]'")
    return load_cty_file_to_cty_value(filepath_str, "hcl")


def convert_hcl_file_to_output_format(
    input_filepath_str: str,
    output_filepath_str: str,
    output_format: Literal["json", "msgpack"],
    output_to_stdout: bool = False,
) -> str | bytes | None:
    """
    Converts an HCL file to either JSON or Msgpack format.
    If output_to_stdout is True, returns the content string/bytes, otherwise writes to file.
    """
    if not HAS_CTY:
        raise ImportError("HCL support requires 'pip install tofusoup[hcl]'")

    cty_from_hcl = load_hcl_file_as_cty(input_filepath_str)
    native_python_obj = cty_to_native(cty_from_hcl)

    output_content: str | bytes | None = None

    if output_format == "json":
        output_content = dump_python_to_json_string(native_python_obj, pretty=True)
    elif output_format == "msgpack":
        output_content = dump_python_to_msgpack_bytes(native_python_obj)
    else:
        raise TofuSoupError(f"Internal error: Unsupported output format '{output_format}' for HCL conversion.")

    if output_to_stdout:
        return output_content
    else:
        output_p = pathlib.Path(output_filepath_str)
        output_p.parent.mkdir(parents=True, exist_ok=True)
        if isinstance(output_content, str):
            with open(output_p, "w", encoding="utf-8") as f:
                f.write(output_content)
                if not output_content.endswith("\n"):
                    f.write("\n")
        elif isinstance(output_content, bytes):
            with open(output_p, "wb") as f:
                f.write(output_content)
        else:
            raise TofuSoupError("No output content generated during HCL conversion.")
        logger.info(
            f"HCL file '{input_filepath_str}' converted to {output_format.upper()} and saved to '{output_p}'."
        )
        return None


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 56: tofusoup/provider/__init__.py | checksum=130e13800791... | modified=2025-09-17T17:32:12 | op=+ | size=101 | tokens=34 | type=x-python ###
<<< BOF <<<
#
# tofusoup/provider/__init__.py
#
"""Provider project management commands."""


# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 57: tofusoup/provider/cli.py | checksum=39fc626c2602... | modified=2025-09-17T17:32:12 | op=+ | size=873 | tokens=205 | type=x-python ###
<<< BOF <<<
#!/usr/bin/env python3
#
# tofusoup/provider/cli.py
#
"""CLI for provider project lifecycle management."""

from pathlib import Path

import click

from tofusoup.scaffolding.generator import scaffold_new_provider


@click.group("provider")
def provider_cli() -> None:
    """Commands for managing provider projects."""
    pass


@provider_cli.command("new")
@click.argument("project_dir", type=click.Path(file_okay=False, writable=True))
def new_provider_command(project_dir: str) -> None:
    """Initialize a new Pyvider provider project."""
    try:
        project_path = scaffold_new_provider(Path(project_dir))
        click.secho(f"✅ New provider project created at {project_path}", fg="green")
    except Exception as e:
        click.secho(f"❌ Project initialization failed: {e}", fg="red", err=True)
        raise click.Abort() from e


# 🍲🥄🖥️🪄
>>> EOF >>>

### FILE 58: tofusoup/registry/__init__.py | checksum=91033b558d7f... | modified=2025-09-17T17:32:12 | op=+ | size=355 | tokens=113 | type=x-python ###
<<< BOF <<<
#
# tofusoup/registry/__init__.py
#
"""Registry component for tfbrowser."""

from .base import BaseTfRegistry, RegistryConfig
from .opentofu import OpenTofuRegistry
from .terraform import IBMTerraformRegistry

__all__ = [
    "BaseTfRegistry",
    "IBMTerraformRegistry",
    "OpenTofuRegistry",
    "RegistryConfig",
]

# 🐍⚙️


# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 59: tofusoup/registry/base.py | checksum=42ff9333cffe... | modified=2025-09-17T17:32:12 | op=+ | size=1627 | tokens=393 | type=x-python ###
<<< BOF <<<
#
# tofusoup/registry/base.py
#
from abc import ABC, abstractmethod

from attrs import define
import httpx
from provide.foundation import logger

from tofusoup.registry.models.module import Module, ModuleVersion
from tofusoup.registry.models.provider import Provider, ProviderVersion


@define
class RegistryConfig:
    base_url: str


class BaseTfRegistry(ABC):
    def __init__(self, config: RegistryConfig) -> None:
        self.config = config
        self._client: httpx.AsyncClient | None = None
        logger.debug(f"BaseTfRegistry initialized for {config.base_url}")

    async def __aenter__(self):
        if self._client is None:
            self._client = httpx.AsyncClient(base_url=self.config.base_url)
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self._client:
            await self._client.aclose()
            self._client = None

    @abstractmethod
    async def list_providers(self, query: str | None = None) -> list[Provider]:
        pass

    @abstractmethod
    async def get_provider_details(self, namespace: str, name: str) -> dict:
        pass

    @abstractmethod
    async def list_provider_versions(self, provider_id: str) -> list[ProviderVersion]:
        pass

    @abstractmethod
    async def list_modules(self, query: str | None = None) -> list[Module]:
        pass

    @abstractmethod
    async def get_module_details(self, namespace: str, name: str, provider: str, version: str) -> dict:
        pass

    @abstractmethod
    async def list_module_versions(self, module_id: str) -> list[ModuleVersion]:
        pass


# 🍲🥄🏛️🪄
>>> EOF >>>

### FILE 60: tofusoup/registry/cli.py | checksum=0dbd83eb70fc... | modified=2025-09-17T17:32:12 | op=+ | size=17363 | tokens=3727 | type=x-python ###
<<< BOF <<<
#!/usr/bin/env python3
#
# tofusoup/registry/cli.py
#

import asyncio

import click
from provide.foundation import logger


def safe_async_run(coro_func):
    """
    Safely run async function, handling both testing and production contexts.

    Uses asyncio.run() directly to avoid event loop conflicts in testing.
    """
    return asyncio.run(coro_func())


from tofusoup.config.defaults import DEFAULT_REGISTRY_SOURCE, TERRAFORM_REGISTRY_URL
from tofusoup.registry.base import RegistryConfig
from tofusoup.registry.opentofu import OpenTofuRegistry
from tofusoup.registry.search.engine import (
    async_search_runner,
)
from tofusoup.registry.terraform import IBMTerraformRegistry


@click.group("registry")
@click.pass_context
def registry_cli(ctx: click.Context) -> None:
    """Commands for querying and managing Terraform/OpenTofu registries."""
    logger.debug("TofuSoup 'registry' command group invoked.")
    pass


# Provider subcommands
@registry_cli.group("provider")
def provider_group() -> None:
    """Commands for working with providers."""
    pass


@provider_group.command("info")
@click.argument("provider", metavar="NAMESPACE/NAME")
@click.option(
    "-r",
    "--registry",
    type=click.Choice(["terraform", "opentofu", "both"], case_sensitive=False),
    default=DEFAULT_REGISTRY_SOURCE,
    help="Registry to query.",
)
@click.pass_context
def provider_info(ctx: click.Context, provider: str, registry: str) -> None:
    """Get detailed information about a provider."""
    try:
        namespace, name = provider.split("/")
    except ValueError:
        click.echo("Error: Provider must be in format 'namespace/name'", err=True)
        return

    async def fetch_info() -> None:
        registries = []
        if registry in ["terraform", "both"]:
            registries.append(IBMTerraformRegistry(RegistryConfig(base_url=TERRAFORM_REGISTRY_URL)))
        if registry in ["opentofu", "both"]:
            registries.append(OpenTofuRegistry())

        for reg in registries:
            async with reg:
                reg_name = reg.__class__.__name__.replace("Registry", "")
                try:
                    provider_data = await reg.get_provider_details(namespace, name)
                    click.echo(f"\n=== {reg_name} Registry ===")
                    click.echo(f"Provider: {namespace}/{name}")
                    click.echo(f"Description: {provider_data.get('description', 'N/A')}")
                    click.echo(f"Source: {provider_data.get('source', 'N/A')}")
                    click.echo(f"Downloads: {provider_data.get('download_count', 'N/A')}")
                except Exception as e:
                    click.echo(f"\n=== {reg_name} Registry ===")
                    click.echo(f"Error: {e}")

    safe_async_run(fetch_info)


@provider_group.command("versions")
@click.argument("provider", metavar="NAMESPACE/NAME")
@click.option(
    "-r",
    "--registry",
    type=click.Choice(["terraform", "opentofu", "both"], case_sensitive=False),
    default=DEFAULT_REGISTRY_SOURCE,
    help="Registry to query.",
)
@click.option("--latest", is_flag=True, help="Show only the latest version.")
@click.pass_context
def provider_versions(ctx: click.Context, provider: str, registry: str, latest: bool) -> None:
    """List all versions of a provider."""
    try:
        namespace, name = provider.split("/")
    except ValueError:
        click.echo("Error: Provider must be in format 'namespace/name'", err=True)
        return

    async def fetch_versions() -> None:
        registries = []
        if registry in ["terraform", "both"]:
            registries.append(IBMTerraformRegistry(RegistryConfig(base_url=TERRAFORM_REGISTRY_URL)))
        if registry in ["opentofu", "both"]:
            registries.append(OpenTofuRegistry())

        for reg in registries:
            async with reg:
                reg_name = reg.__class__.__name__.replace("Registry", "")
                try:
                    await reg.get_provider_details(namespace, name)
                    versions = await reg.list_provider_versions(f"{namespace}/{name}")

                    click.echo(f"\n=== {reg_name} Registry ===")
                    click.echo(f"Provider: {namespace}/{name}")

                    if latest and versions:
                        click.echo(f"Latest version: {versions[0].version}")
                    else:
                        click.echo(f"Versions ({len(versions)} total):")
                        for v in versions[:10]:  # Show first 10
                            platforms = f" ({len(v.platforms)} platforms)" if v.platforms else ""
                            click.echo(f"  - {v.version}{platforms}")
                        if len(versions) > 10:
                            click.echo(f"  ... and {len(versions) - 10} more")
                except Exception as e:
                    click.echo(f"\n=== {reg_name} Registry ===")
                    click.echo(f"Error: {e}")

    safe_async_run(fetch_versions)


# Module subcommands
@registry_cli.group("module")
def module_group() -> None:
    """Commands for working with modules."""
    pass


@module_group.command("info")
@click.argument("module", metavar="NAMESPACE/NAME/PROVIDER")
@click.option(
    "-r",
    "--registry",
    type=click.Choice(["terraform", "opentofu", "both"], case_sensitive=False),
    default=DEFAULT_REGISTRY_SOURCE,
    help="Registry to query.",
)
@click.pass_context
def module_info(ctx: click.Context, module: str, registry: str) -> None:
    """Get detailed information about a module."""
    parts = module.split("/")
    if len(parts) != 3:
        click.echo("Error: Module must be in format 'namespace/name/provider'", err=True)
        return

    namespace, name, provider_name = parts

    async def fetch_info() -> None:
        registries = []
        if registry in ["terraform", "both"]:
            registries.append(IBMTerraformRegistry(RegistryConfig(base_url=TERRAFORM_REGISTRY_URL)))
        if registry in ["opentofu", "both"]:
            registries.append(OpenTofuRegistry())

        for reg in registries:
            async with reg:
                reg_name = reg.__class__.__name__.replace("Registry", "")
                try:
                    module_data = await reg.get_module_details(namespace, name, provider_name, "latest")
                    click.echo(f"\n=== {reg_name} Registry ===")
                    click.echo(f"Module: {namespace}/{name}/{provider_name}")
                    click.echo(f"Description: {module_data.get('description', 'N/A')}")
                    click.echo(f"Source: {module_data.get('source', 'N/A')}")
                    click.echo(f"Downloads: {module_data.get('download_count', 'N/A')}")
                except Exception as e:
                    click.echo(f"\n=== {reg_name} Registry ===")
                    click.echo(f"Error: {e}")

    safe_async_run(fetch_info)


@module_group.command("versions")
@click.argument("module", metavar="NAMESPACE/NAME/PROVIDER")
@click.option(
    "-r",
    "--registry",
    type=click.Choice(["terraform", "opentofu", "both"], case_sensitive=False),
    default=DEFAULT_REGISTRY_SOURCE,
    help="Registry to query.",
)
@click.option("--latest", is_flag=True, help="Show only the latest version.")
@click.pass_context
def module_versions(ctx: click.Context, module: str, registry: str, latest: bool) -> None:
    """List all versions of a module."""
    parts = module.split("/")
    if len(parts) != 3:
        click.echo("Error: Module must be in format 'namespace/name/provider'", err=True)
        return

    namespace, name, provider_name = parts

    async def fetch_versions() -> None:
        registries = []
        if registry in ["terraform", "both"]:
            registries.append(IBMTerraformRegistry(RegistryConfig(base_url=TERRAFORM_REGISTRY_URL)))
        if registry in ["opentofu", "both"]:
            registries.append(OpenTofuRegistry())

        for reg in registries:
            async with reg:
                reg_name = reg.__class__.__name__.replace("Registry", "")
                try:
                    await reg.get_module_details(namespace, name, provider_name, "latest")
                    versions = await reg.list_module_versions(f"{namespace}/{name}/{provider_name}")

                    click.echo(f"\n=== {reg_name} Registry ===")
                    click.echo(f"Module: {namespace}/{name}/{provider_name}")

                    if latest and versions:
                        click.echo(f"Latest version: {versions[0].version}")
                    else:
                        click.echo(f"Versions ({len(versions)} total):")
                        for v in versions[:10]:  # Show first 10
                            published = f" (published: {v.published_at})" if v.published_at else ""
                            click.echo(f"  - {v.version}{published}")
                        if len(versions) > 10:
                            click.echo(f"  ... and {len(versions) - 10} more")
                except Exception as e:
                    click.echo(f"\n=== {reg_name} Registry ===")
                    click.echo(f"Error: {e}")

    safe_async_run(fetch_versions)


# Search command (moved from sui)
@registry_cli.command("search")
@click.argument("term", nargs=-1)
@click.option(
    "-r",
    "--registry",
    "registry_name",
    type=click.Choice(["terraform", "opentofu", "all"], case_sensitive=False),
    default="all",
    show_default=True,
    help="Registry to search.",
)
@click.option(
    "-t",
    "--type",
    "resource_type",
    type=click.Choice(["provider", "module", "all"], case_sensitive=False),
    default="all",
    help="Type of resource to search.",
)
def search_command(term: tuple[str, ...], registry_name: str, resource_type: str) -> None:
    """Search registries for providers and modules."""
    search_term = " ".join(term)
    if not search_term:
        click.echo("Please provide a search term.", err=True)
        return

    logger.info(f"Initiating registry search for term: '{search_term}' on registry: '{registry_name}'")

    try:
        results = safe_async_run(lambda: async_search_runner(search_term, registry_name))

        # Filter by type if specified
        if resource_type != "all":
            results = [r for r in results if r.type == resource_type]

        if results:
            click.echo(f"Found {len(results)} results for '{search_term}':")

            # Sort results
            results.sort(
                key=lambda r: (
                    r.registry_source == "both",
                    r.total_versions is not None,
                    r.total_versions,
                ),
                reverse=True,
            )

            # Format output
            max_name_len = (
                max(
                    len(f"{r.namespace}/{r.name}/{r.provider_name}")
                    if r.type == "module"
                    else len(f"{r.namespace}/{r.name}")
                    for r in results
                )
                if results
                else 10
            )
            has_versions = any(r.total_versions is not None for r in results)

            if has_versions:
                max_latest_len = max(len(r.latest_version or "N/A") for r in results) if results else 10
                header = f"| R | T | {'Name':<{max_name_len}} | {'Latest':<{max_latest_len}} | {'Total':<5} | Description"
            else:
                header = f"| R | T | {'Name':<{max_name_len}} | Description"

            click.echo(header)
            click.echo("-" * len(header))

            for result in results:
                desc = result.description or "N/A"
                if len(desc) > 70:
                    desc = desc[:67] + "..."

                registry_emoji = (
                    "🤝"
                    if result.registry_source == "both"
                    else "🍲"
                    if result.registry_source == "opentofu"
                    else "🏗️"
                )
                type_emoji = "📦" if result.type == "module" else "🔌"
                name = (
                    f"{result.namespace}/{result.name}/{result.provider_name}"
                    if result.type == "module"
                    else f"{result.namespace}/{result.name}"
                )

                if has_versions:
                    latest = result.latest_version or "N/A"
                    total = str(result.total_versions) if result.total_versions is not None else "N/A"
                    click.echo(
                        f"| {registry_emoji} | {type_emoji} | {name:<{max_name_len}} | {latest:<{max_latest_len}} | {total:<5} | {desc}"
                    )
                else:
                    click.echo(f"| {registry_emoji} | {type_emoji} | {name:<{max_name_len}} | {desc}")

            click.echo("\nKey: 🤝 Both | 🍲 OpenTofu | 🏗️ Terraform | 📦 Module | 🔌 Provider")
        else:
            click.echo(f"No results found for '{search_term}' on {registry_name} registry.")

    except Exception as e:
        logger.error(f"Error in search_command: {e}", exc_info=True)
        click.echo(f"A critical error occurred: {e}", err=True)


# Compare command
@registry_cli.command("compare")
@click.argument("resource", metavar="NAMESPACE/NAME[/PROVIDER]")
def compare_command(resource: str) -> None:
    """Compare a resource across Terraform and OpenTofu registries."""
    parts = resource.split("/")

    if len(parts) == 2:
        # Provider comparison
        namespace, name = parts
        resource_type = "provider"
    elif len(parts) == 3:
        # Module comparison
        namespace, name, provider_name = parts
        resource_type = "module"
    else:
        click.echo(
            "Error: Resource must be 'namespace/name' for providers or 'namespace/name/provider' for modules",
            err=True,
        )
        return

    async def compare_resources() -> None:
        tf_registry = IBMTerraformRegistry(RegistryConfig(base_url="https://registry.terraform.io"))
        tofu_registry = OpenTofuRegistry()

        click.echo(f"\nComparing {resource_type}: {resource}")
        click.echo("=" * 60)

        async with tf_registry, tofu_registry:
            # Terraform Registry
            try:
                if resource_type == "provider":
                    tf_data = await tf_registry.get_provider_details(namespace, name)
                    tf_versions = await tf_registry.list_provider_versions(f"{namespace}/{name}")
                else:
                    tf_data = await tf_registry.get_module_details(namespace, name, provider_name, "latest")
                    tf_versions = await tf_registry.list_module_versions(f"{namespace}/{name}/{provider_name}")

                tf_latest = tf_versions[0].version if tf_versions else "N/A"
                tf_count = len(tf_versions)
            except Exception:
                tf_data = None
                tf_latest = "Not found"
                tf_count = 0

            # OpenTofu Registry
            try:
                if resource_type == "provider":
                    tofu_data = await tofu_registry.get_provider_details(namespace, name)
                    tofu_versions = await tofu_registry.list_provider_versions(f"{namespace}/{name}")
                else:
                    tofu_data = await tofu_registry.get_module_details(
                        namespace, name, provider_name, "latest"
                    )
                    tofu_versions = await tofu_registry.list_module_versions(
                        f"{namespace}/{name}/{provider_name}"
                    )

                tofu_latest = tofu_versions[0].version if tofu_versions else "N/A"
                tofu_count = len(tofu_versions)
            except Exception:
                tofu_data = None
                tofu_latest = "Not found"
                tofu_count = 0

            # Display comparison
            click.echo(f"\n{'Registry':<20} | {'Status':<12} | {'Latest':<10} | {'Versions':<8}")
            click.echo("-" * 60)

            tf_status = "Available" if tf_data else "Not found"
            click.echo(f"{'Terraform Registry':<20} | {tf_status:<12} | {tf_latest:<10} | {tf_count:<8}")

            tofu_status = "Available" if tofu_data else "Not found"
            click.echo(f"{'OpenTofu Registry':<20} | {tofu_status:<12} | {tofu_latest:<10} | {tofu_count:<8}")

            # Version comparison if both exist
            if tf_data and tofu_data and tf_versions and tofu_versions:
                click.echo("\nVersion Availability:")
                all_versions = sorted(
                    set([v.version for v in tf_versions] + [v.version for v in tofu_versions]),
                    reverse=True,
                )

                for version in all_versions[:10]:  # Show top 10
                    tf_has = "✓" if any(v.version == version for v in tf_versions) else "✗"
                    tofu_has = "✓" if any(v.version == version for v in tofu_versions) else "✗"
                    click.echo(f"  {version:<15} TF: {tf_has}  OpenTofu: {tofu_has}")

                if len(all_versions) > 10:
                    click.echo(f"  ... and {len(all_versions) - 10} more versions")

    safe_async_run(compare_resources)


# 🍲🥄🖥️🪄
>>> EOF >>>

### FILE 61: tofusoup/registry/models/__init__.py | checksum=95859dc489a9... | modified=2025-09-17T17:32:12 | op=+ | size=473 | tokens=126 | type=x-python ###
<<< BOF <<<
#
# tofusoup/registry/models/__init__.py
#
"""Data models for tfbrowser entities."""

from .module import Module, ModuleVersion  # Example, adjust to actual class names
from .provider import Provider, ProviderVersion  # Example, adjust to actual class names
from .version import VersionInfo  # Example, adjust to actual class names

__all__ = [
    "Module",
    "ModuleVersion",
    "Provider",
    "ProviderVersion",
    "VersionInfo",
]

# 🧱🧩


# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 62: tofusoup/registry/models/module.py | checksum=0c9cc2945376... | modified=2025-09-17T17:32:12 | op=+ | size=1519 | tokens=368 | type=x-python ###
<<< BOF <<<
#
# tofusoup/registry/models/module.py
#
from datetime import datetime
from typing import Any

from attrs import define, field


@define
class ModuleInput:
    """Represents an input variable of a module."""

    name: str
    type: Any
    description: str | None = field(default=None)
    default: Any | None = field(default=None)
    required: bool = field(default=True)


@define
class ModuleOutput:
    """Represents an output value of a module."""

    name: str
    description: str | None = field(default=None)


@define
class ModuleResource:
    """Represents a resource managed by a module."""

    name: str
    type: str


@define
class ModuleVersion:
    """Represents a specific version of a module."""

    version: str
    published_at: datetime | None = field(default=None)
    readme_content: str | None = field(default=None)
    inputs: list[ModuleInput] = field(factory=list)
    outputs: list[ModuleOutput] = field(factory=list)
    resources: list[ModuleResource] = field(factory=list)


@define
class Module:
    """Represents a module in a registry."""

    id: str
    namespace: str
    name: str
    provider_name: str
    description: str | None = field(default=None)
    source_url: str | None = field(default=None)
    downloads: int = field(default=0)
    verified: bool = field(default=False)
    versions: list[ModuleVersion] = field(factory=list)
    latest_version: ModuleVersion | None = field(default=None)
    registry_source: str | None = field(default=None)


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 63: tofusoup/registry/models/provider.py | checksum=a051d0f9070c... | modified=2025-09-17T17:32:12 | op=+ | size=960 | tokens=230 | type=x-python ###
<<< BOF <<<
#
# tofusoup/registry/models/provider.py
#
from datetime import datetime

from attrs import define, field


@define
class ProviderPlatform:
    """Represents a specific platform for a provider version."""

    os: str
    arch: str


@define
class ProviderVersion:
    """Represents a specific version of a provider."""

    version: str
    protocols: list[str] = field(factory=list)
    platforms: list[ProviderPlatform] = field(factory=list)
    published_at: datetime | None = field(default=None)


@define
class Provider:
    """Represents a provider in a registry."""

    id: str
    namespace: str
    name: str
    description: str | None = field(default=None)
    source_url: str | None = field(default=None)
    tier: str | None = field(default=None)
    versions: list[ProviderVersion] = field(factory=list)
    latest_version: ProviderVersion | None = field(default=None)
    registry_source: str | None = field(default=None)


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 64: tofusoup/registry/models/version.py | checksum=80649a9e2209... | modified=2025-09-17T17:32:12 | op=+ | size=2306 | tokens=525 | type=x-python ###
<<< BOF <<<
#
# tofusoup/registry/models/version.py
#
"""Data models for versioning information."""

from datetime import datetime

from attrs import define, field
import semver  # Using a library for robust semver parsing/comparison


@define
class VersionInfo:
    """Represents a semantic version, potentially with build metadata or other info."""

    raw_version: str = field()  # The original version string, e.g., "1.2.3-alpha+build.123"
    semantic_version: semver.Version = field(init=False)  # Parsed semver object
    published_at: datetime | None = field(default=None)
    # Add other generic version metadata if applicable

    def __attrs_post_init__(self) -> None:
        try:
            self.semantic_version = semver.Version.parse(self.raw_version)
        except ValueError as e:
            # Handle cases where raw_version might not be a strict semver string
            # Or raise a custom exception, or set a default/invalid state
            # For now, re-raise or log, depending on desired strictness
            # This example assumes strict parsing is desired.
            # Consider using semver.VersionInfo for the type if you don't need to re-parse often.
            print(f"Error parsing version '{self.raw_version}': {e}")  # Or use structlog
            # Fallback or error state for semantic_version if parsing fails
            # For simplicity in stub, we might let it raise or set to a known invalid state
            # For a robust app, you'd want a clear strategy here.
            # self.semantic_version = semver.Version(0,0,0,"invalid") # Example fallback
            raise  # Re-raising for now to indicate parsing failure

    @property
    def major(self) -> int:
        return self.semantic_version.major

    @property
    def minor(self) -> int:
        return self.semantic_version.minor

    @property
    def patch(self) -> int:
        return self.semantic_version.patch

    @property
    def prerelease(self) -> str | None:
        return self.semantic_version.prerelease

    @property
    def build(self) -> str | None:
        return self.semantic_version.build

    def __str__(self) -> str:
        return str(self.semantic_version)

    # Add comparison methods if needed, though semver.Version already provides them


# 🏷️🔢


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 65: tofusoup/registry/opentofu.py | checksum=19a8a3fba1bd... | modified=2025-09-17T17:32:12 | op=+ | size=6682 | tokens=1341 | type=x-python ###
<<< BOF <<<
#
# tofusoup/registry/opentofu.py
#
from typing import Any, cast

import httpx
from provide.foundation import logger

from tofusoup.config.defaults import OPENTOFU_REGISTRY_URL
from tofusoup.registry.models.module import Module, ModuleVersion
from tofusoup.registry.models.provider import (
    Provider,
    ProviderPlatform,
    ProviderVersion,
)

from .base import BaseTfRegistry, RegistryConfig


class OpenTofuRegistry(BaseTfRegistry):
    def __init__(self, config: RegistryConfig | None = None) -> None:
        super().__init__(config or RegistryConfig(base_url=OPENTOFU_REGISTRY_URL))

    async def _search_api_opentofu(self, query: str | None) -> list[dict[str, Any]]:
        if not self._client:
            return []
        api_search_url = "https://api.opentofu.org/registry/docs/search"
        params: dict[str, Any] = {"limit": 20}
        if query:
            params["q"] = query
        try:
            response = await self._client.get(api_search_url, params=params)
            response.raise_for_status()
            data = response.json()
            return cast(
                list[dict[str, Any]],
                data if isinstance(data, list) else data.get("items", []),
            )
        except (httpx.HTTPStatusError, httpx.RequestError) as e:
            logger.error(
                "Error during OpenTofu API search",
                request_url=e.request.url,
                exc_info=True,
            )
            return []

    async def list_modules(self, query: str | None) -> list[Module]:
        items_data = await self._search_api_opentofu(query)
        result_modules: list[Module] = []
        for item in items_data:
            if item and item.get("id", "").startswith("modules/"):
                parts = item["id"].split("/")
                if len(parts) == 4:
                    result_modules.append(
                        Module(
                            id=item["id"],
                            namespace=parts[1],
                            name=parts[2],
                            provider_name=parts[3],
                            description=item.get("description"),
                        )
                    )
        return result_modules

    async def list_providers(self, query: str | None = None) -> list[Provider]:
        items_data = await self._search_api_opentofu(query)
        result_providers: list[Provider] = []
        for item in items_data:
            if item and item.get("id", "").startswith("providers/"):
                parts = item["id"].split("/")
                if len(parts) == 3:
                    result_providers.append(
                        Provider(
                            id=item["id"],
                            namespace=parts[1],
                            name=parts[2],
                            description=item.get("description"),
                            tier=item.get("tier"),
                        )
                    )
        return result_providers

    async def get_provider_details(self, namespace: str, name: str) -> dict[str, Any]:
        if not self._client:
            return {}
        endpoint = f"/v1/providers/{namespace}/{name}"
        try:
            response = await self._client.get(endpoint)
            if response.status_code == 404:
                return {}
            response.raise_for_status()
            return response.json()
        except (httpx.HTTPStatusError, httpx.RequestError) as e:
            logger.error(
                f"Error fetching OpenTofu provider details for '{namespace}/{name}'",
                request_url=e.request.url,
                exc_info=True,
            )
            return {}

    async def list_provider_versions(self, provider_id: str) -> list[ProviderVersion]:
        if not self._client or "/" not in provider_id:
            return []
        namespace, name = provider_id.split("/", 1)
        endpoint = f"/v1/providers/{namespace}/{name}/versions"
        try:
            response = await self._client.get(endpoint)
            if response.status_code == 404:
                return []
            response.raise_for_status()
            data = response.json()
            return [
                ProviderVersion(
                    version=v.get("version", ""),
                    protocols=v.get("protocols", []),
                    platforms=[
                        ProviderPlatform(os=p.get("os", ""), arch=p.get("arch", ""))
                        for p in v.get("platforms", [])
                    ],
                )
                for v in data.get("versions", [])
            ]
        except (httpx.HTTPStatusError, httpx.RequestError) as e:
            logger.error(
                f"Error fetching OpenTofu provider versions for '{provider_id}'",
                request_url=e.request.url,
                exc_info=True,
            )
            return []

    async def get_module_details(
        self, namespace: str, name: str, provider: str, version: str
    ) -> dict[str, Any]:
        if not self._client:
            return {}
        endpoint = f"/v1/modules/{namespace}/{name}/{provider}/{version}"
        try:
            response = await self._client.get(endpoint)
            if response.status_code == 404:
                return {}
            response.raise_for_status()
            return response.json()
        except (httpx.HTTPStatusError, httpx.RequestError) as e:
            logger.error(
                f"Error fetching OpenTofu module details for '{namespace}/{name}/{provider}/{version}'",
                request_url=e.request.url,
                exc_info=True,
            )
            return {}

    async def list_module_versions(self, module_id: str) -> list[ModuleVersion]:
        if not self._client or module_id.count("/") != 2:
            return []
        namespace, name, provider = module_id.split("/")
        endpoint = f"/v1/modules/{namespace}/{name}/{provider}/versions"
        try:
            response = await self._client.get(endpoint)
            if response.status_code == 404:
                return []
            response.raise_for_status()
            data = response.json()
            versions_data = data.get("modules", [{}])[0].get("versions", [])
            return [ModuleVersion(version=v.get("version", "")) for v in versions_data if v.get("version")]
        except (httpx.HTTPStatusError, httpx.RequestError) as e:
            logger.error(
                f"Error fetching OpenTofu module versions for '{module_id}'",
                request_url=e.request.url,
                exc_info=True,
            )
            return []


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 66: tofusoup/registry/search/__init__.py | checksum=0ea9dde211a3... | modified=2025-09-17T17:32:12 | op=+ | size=287 | tokens=85 | type=x-python ###
<<< BOF <<<
#
# tofusoup/registry/search/__init__.py
#
"""Search component for tfbrowser."""

from .cache import SearchCache  # Assuming SearchCache will be the class in cache.py
from .engine import SearchEngine

__all__ = [
    "SearchCache",
    "SearchEngine",
]

# 🔎📚


# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 67: tofusoup/registry/search/cache.py | checksum=af420bb1e99d... | modified=2025-09-17T17:32:12 | op=+ | size=2635 | tokens=621 | type=x-python ###
<<< BOF <<<
#
# tofusoup/registry/search/cache.py
#
"""Caching layer for search results and queries."""

from typing import Any

from attrs import define  # If using attrs for cache entry structure

from tofusoup.config.defaults import CACHE_MAX_SIZE, CACHE_TTL_SECONDS

# from .engine import SearchQuery, SearchResult # Types for cached items


@define
class CacheEntry:
    """Represents a cached search result list or other search-related data."""

    query_key: str  # A unique key generated from a SearchQuery
    results: list[Any]  # list[SearchResult] ideally
    timestamp: float  # Unix timestamp of when the entry was created
    # Add TTL, metadata, etc.


class SearchCache:
    """Handles caching of search queries and results."""

    def __init__(self, max_size: int = CACHE_MAX_SIZE, ttl_seconds: int = CACHE_TTL_SECONDS) -> None:
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
        self._cache: dict[str, CacheEntry] = {}  # In-memory cache for now

    async def get(self, query: Any) -> list[Any] | None:  # query: SearchQuery
        """Retrieve cached results for a given query."""
        query_key = self._generate_key(query)
        entry = self._cache.get(query_key)
        if entry:
            # Check TTL
            # import time
            # if time.time() - entry.timestamp < self.ttl_seconds:
            # return entry.results
            # else:
            # self.delete(query_key) # Expired
            return entry.results  # Simplified for stub
        return None

    async def put(
        self, query: Any, results: list[Any]
    ) -> None:  # query: SearchQuery, results: list[SearchResult]
        """Cache the results for a given query."""
        query_key = self._generate_key(query)
        # import time
        # entry = CacheEntry(query_key=query_key, results=results, timestamp=time.time())
        # self._cache[query_key] = entry
        # Enforce max_size if necessary (e.g., LRU eviction)
        print(f"SearchCache: Caching results for query key '{query_key}'")

    async def delete(self, query_key: str) -> None:
        """Delete a specific entry from the cache."""
        if query_key in self._cache:
            del self._cache[query_key]

    async def clear(self) -> None:
        """Clear the entire search cache."""
        self._cache.clear()

    def _generate_key(self, query: Any) -> str:  # query: SearchQuery
        """Generate a unique string key from a SearchQuery object."""
        # Placeholder implementation
        # return f"{query.term}_{sorted(query.filters.items())}"
        return str(query)


# 💾🔍


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 68: tofusoup/registry/search/engine.py | checksum=db8705c65498... | modified=2025-09-17T17:32:12 | op=+ | size=8410 | tokens=1507 | type=x-python ###
<<< BOF <<<
#
# tofusoup/registry/search/engine.py
#
import asyncio
from collections.abc import AsyncGenerator

from attrs import define, field
from provide.foundation import logger
import semver

from tofusoup.registry.base import BaseTfRegistry


@define
class SearchQuery:
    """Represents a search query."""

    term: str = ""


@define
class SearchResult:
    """Represents a single item in the search results."""

    id: str
    name: str
    namespace: str
    type: str
    registry_source: str
    provider_name: str | None = field(default=None)
    description: str | None = field(default=None)
    latest_version: str | None = field(default=None)
    total_versions: int | None = field(default=None)


class SearchEngine:
    def __init__(self, registries: list[BaseTfRegistry]) -> None:
        self.registries: list[BaseTfRegistry] = registries
        logger.debug(f"SearchEngine initialized with {len(self.registries)} registries.")

    async def search(self, query: SearchQuery) -> AsyncGenerator[SearchResult]:
        """
        FIX: Refactored to an async generator.
        Performs a search across all configured registries and yields results
        as they become available from each registry.
        """
        logger.info("SearchEngine.search started", query_term=query.term)

        search_tasks = [
            asyncio.create_task(self._search_single_registry(registry, query)) for registry in self.registries
        ]

        # Use asyncio.as_completed to process results as they finish
        for task in asyncio.as_completed(search_tasks):
            try:
                results_from_registry = await task
                logger.debug(f"Received {len(results_from_registry)} results from a registry.")
                for result in results_from_registry:
                    yield result
            except Exception as e:
                logger.error(f"Error processing a registry's search results: {e}", exc_info=True)

        logger.info("SearchEngine.search finished streaming results.")

    async def _search_single_registry(
        self, registry: BaseTfRegistry, query: SearchQuery
    ) -> list[SearchResult]:
        registry_identifier = registry.__class__.__name__.replace("Registry", "").lower()
        logger.info(
            f"Enter _search_single_registry for {registry_identifier}",
            query_term=query.term,
        )
        registry_results: list[SearchResult] = []
        try:
            async with registry:
                logger.debug(f"Registry context entered for {registry_identifier}.")
                effective_query_term = query.term if query.term else None

                modules = await registry.list_modules(query=effective_query_term)
                if modules is None:
                    modules = []
                logger.debug(f"{registry_identifier}.list_modules returned {len(modules)} modules.")
                for mod in modules:
                    versions = await registry.list_module_versions(
                        f"{mod.namespace}/{mod.name}/{mod.provider_name}"
                    )
                    if versions is None:
                        versions = []

                    latest_version = None
                    valid_versions = []
                    for v in versions:
                        try:
                            valid_versions.append(semver.Version.parse(v.version))
                        except ValueError:
                            logger.warning(
                                f"Skipping invalid semver version '{v.version}' for module {mod.id}"
                            )
                    if valid_versions:
                        latest_version = max(valid_versions)

                    registry_results.append(
                        SearchResult(
                            id=mod.id,
                            name=mod.name,
                            namespace=mod.namespace,
                            provider_name=mod.provider_name,
                            type="module",
                            registry_source=registry_identifier,
                            description=mod.description,
                            latest_version=str(latest_version) if latest_version else None,
                            total_versions=len(versions),
                        )
                    )

                providers = await registry.list_providers(query=effective_query_term)
                if providers is None:
                    providers = []
                logger.debug(f"{registry_identifier}.list_providers returned {len(providers)} providers.")
                for prov in providers:
                    versions = await registry.list_provider_versions(f"{prov.namespace}/{prov.name}")
                    if versions is None:
                        versions = []

                    latest_version = None
                    valid_versions = []
                    for v in versions:
                        try:
                            valid_versions.append(semver.Version.parse(v.version))
                        except ValueError:
                            logger.warning(
                                f"Skipping invalid semver version '{v.version}' for provider {prov.id}"
                            )
                    if valid_versions:
                        latest_version = max(valid_versions)

                    registry_results.append(
                        SearchResult(
                            id=prov.id,
                            name=prov.name,
                            namespace=prov.namespace,
                            type="provider",
                            registry_source=registry_identifier,
                            description=prov.description,
                            latest_version=str(latest_version) if latest_version else None,
                            total_versions=len(versions),
                        )
                    )
            logger.debug(f"Registry context exited for {registry_identifier}.")
            return registry_results
        except Exception as e:
            logger.error(f"Error searching registry {registry_identifier}: {e}", exc_info=True)
            raise

    async def close(self) -> None:
        logger.debug("SearchEngine.close called, no specific resources to clean up here.")
        pass


async def async_search_runner(search_term: str, registry_choice: str) -> list[SearchResult]:
    """Asynchronously performs the search operation against specified registries.

    This is a convenience function that sets up registries based on the choice,
    executes the search, and returns results.

    Args:
        search_term: The term to search for
        registry_choice: One of 'terraform', 'opentofu', or 'all'

    Returns:
        List of SearchResult objects
    """
    from ..base import RegistryConfig
    from ..opentofu import OpenTofuRegistry
    from ..terraform import IBMTerraformRegistry

    logger.debug(
        "async_search_runner started",
        search_term=search_term,
        registry_choice=registry_choice,
    )
    registries_to_search: list[BaseTfRegistry] = []

    if registry_choice in ["terraform", "all"]:
        tf_config = RegistryConfig(base_url="https://registry.terraform.io")
        registries_to_search.append(IBMTerraformRegistry(config=tf_config))
        logger.debug("TerraformRegistry added to search targets.")

    if registry_choice in ["opentofu", "all"]:
        registries_to_search.append(OpenTofuRegistry())
        logger.debug("OpenTofuRegistry added to search targets.")

    if not registries_to_search:
        logger.warning("No registries selected for search.")
        return []

    engine = SearchEngine(registries=registries_to_search)
    query = SearchQuery(term=search_term)

    results: list[SearchResult] = []
    try:
        logger.info(f"Executing search with SearchEngine for term: '{search_term}' on '{registry_choice}'")
        async for result in engine.search(query):
            results.append(result)
        logger.info(f"SearchEngine returned {len(results)} results.")
    except Exception as e:
        logger.error(f"Exception during search execution: {e}", exc_info=True)
        raise
    finally:
        await engine.close()
        logger.debug("SearchEngine closed.")

    return results


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 69: tofusoup/registry/terraform.py | checksum=2d08afa88d3e... | modified=2025-09-17T17:32:12 | op=+ | size=6231 | tokens=1228 | type=x-python ###
<<< BOF <<<
#
# tofusoup/registry/terraform.py
#
from typing import Any

import httpx
from provide.foundation import logger

from tofusoup.registry.models.module import Module, ModuleVersion
from tofusoup.registry.models.provider import (
    Provider,
    ProviderPlatform,
    ProviderVersion,
)

from .base import BaseTfRegistry, RegistryConfig


class IBMTerraformRegistry(BaseTfRegistry):
    def __init__(self, config: RegistryConfig) -> None:
        super().__init__(config)

    async def list_providers(self, query: str | None = None) -> list[Provider]:
        if not self._client:
            return []
        params: dict[str, Any] = {"limit": 50}
        endpoint = "/v1/providers"
        if query:
            params["q"] = query
        try:
            response = await self._client.get(endpoint, params=params)
            response.raise_for_status()
            data = response.json()
            return [
                Provider(
                    id=p.get("id"),
                    namespace=p.get("namespace"),
                    name=p.get("name"),
                    description=p.get("description"),
                    tier=p.get("tier"),
                )
                for p in data.get("providers", [])
            ]
        except (httpx.HTTPStatusError, httpx.RequestError) as e:
            logger.error(
                "Error searching Terraform providers",
                request_url=e.request.url,
                exc_info=True,
            )
            return []

    async def list_modules(self, query: str | None = None) -> list[Module]:
        if not self._client:
            return []
        endpoint = "/v1/modules/search"
        params: dict[str, Any] = {"limit": 20}
        if query:
            params["q"] = query
        try:
            response = await self._client.get(endpoint, params=params)
            response.raise_for_status()
            data = response.json()
            return [
                Module(
                    id=m.get("id", ""),
                    namespace=m.get("namespace", ""),
                    name=m.get("name", ""),
                    provider_name=m.get("provider", ""),
                    description=m.get("description"),
                )
                for m in data.get("modules", [])
            ]
        except (httpx.HTTPStatusError, httpx.RequestError) as e:
            logger.error(
                "Error searching Terraform modules",
                request_url=e.request.url,
                exc_info=True,
            )
            return []

    async def get_provider_details(self, namespace: str, name: str) -> dict[str, Any]:
        if not self._client:
            return {}
        endpoint = f"/v1/providers/{namespace}/{name}"
        try:
            response = await self._client.get(endpoint)
            if response.status_code == 404:
                return {}
            response.raise_for_status()
            return response.json()
        except (httpx.HTTPStatusError, httpx.RequestError) as e:
            logger.error(
                f"Error fetching Terraform provider details for '{namespace}/{name}'",
                request_url=e.request.url,
                exc_info=True,
            )
            return {}

    async def list_provider_versions(self, provider_id: str) -> list[ProviderVersion]:
        if not self._client or "/" not in provider_id:
            return []
        namespace, name = provider_id.split("/", 1)
        endpoint = f"/v1/providers/{namespace}/{name}/versions"
        try:
            response = await self._client.get(endpoint)
            if response.status_code == 404:
                return []
            response.raise_for_status()
            data = response.json()
            return [
                ProviderVersion(
                    version=v.get("version", ""),
                    protocols=v.get("protocols", []),
                    platforms=[
                        ProviderPlatform(os=p.get("os", ""), arch=p.get("arch", ""))
                        for p in v.get("platforms", [])
                    ],
                )
                for v in data.get("versions", [])
            ]
        except (httpx.HTTPStatusError, httpx.RequestError) as e:
            logger.error(
                f"Error fetching Terraform provider versions for '{provider_id}'",
                request_url=e.request.url,
                exc_info=True,
            )
            return []

    async def get_module_details(
        self, namespace: str, name: str, provider: str, version: str
    ) -> dict[str, Any]:
        if not self._client:
            return {}
        endpoint = f"/v1/modules/{namespace}/{name}/{provider}/{version}"
        try:
            response = await self._client.get(endpoint)
            if response.status_code == 404:
                return {}
            response.raise_for_status()
            return response.json()
        except (httpx.HTTPStatusError, httpx.RequestError) as e:
            logger.error(
                f"Error fetching Terraform module details for '{namespace}/{name}/{provider}/{version}'",
                request_url=e.request.url,
                exc_info=True,
            )
            return {}

    async def list_module_versions(self, module_id: str) -> list[ModuleVersion]:
        if not self._client or module_id.count("/") != 2:
            return []
        namespace, name, provider = module_id.split("/")
        endpoint = f"/v1/modules/{namespace}/{name}/{provider}/versions"
        try:
            response = await self._client.get(endpoint)
            if response.status_code == 404:
                return []
            response.raise_for_status()
            data = response.json()
            versions_data = data.get("modules", [{}])[0].get("versions", [])
            return [ModuleVersion(version=v.get("version", "")) for v in versions_data if v.get("version")]
        except (httpx.HTTPStatusError, httpx.RequestError) as e:
            logger.error(
                f"Error fetching Terraform module versions for '{module_id}'",
                request_url=e.request.url,
                exc_info=True,
            )
            return []


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 70: tofusoup/rpc/__init__.py | checksum=c6bf3b6328b1... | modified=2025-09-17T17:32:12 | op=+ | size=51 | tokens=28 | type=x-python ###
<<< BOF <<<
#
# tofusoup/rpc/__init__.py
#

# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 71: tofusoup/rpc/cli.py | checksum=cc6506527d36... | modified=2025-09-17T17:32:12 | op=+ | size=4308 | tokens=1020 | type=x-python ###
<<< BOF <<<
#!/usr/bin/env python3
#
# tofusoup/rpc/cli.py
#
import os
import sys

import click
import grpc

from tofusoup.config.defaults import DEFAULT_GRPC_ADDRESS

# Use correct relative import for generated protobuf modules.
from ..harness.proto.kv import kv_pb2, kv_pb2_grpc
from .server import start_kv_server


@click.group("rpc")
def rpc_cli() -> None:
    """Commands for interacting with gRPC services."""
    pass


@rpc_cli.command("kv-put")
@click.option("--address", default=DEFAULT_GRPC_ADDRESS, help="Address of the gRPC server.")
@click.argument("key")
@click.argument("value")
def kv_put(address: str, key: str, value: str) -> None:
    """Puts a key-value pair into the KV store."""
    try:
        with grpc.insecure_channel(address) as channel:
            stub = kv_pb2_grpc.KVStub(channel)
            # The Put RPC returns an Empty message. Its successful return is the confirmation.
            stub.Put(kv_pb2.PutRequest(key=key.encode(), value=value.encode()))
            # FIX: The Empty response has no fields. Success is implied by no exception.
            click.echo(f"Successfully put key '{key}'")
    except grpc.RpcError as e:
        click.echo(f"RPC Error: {e.details()}", err=True)


@rpc_cli.command("kv-get")
@click.option("--address", default=DEFAULT_GRPC_ADDRESS, help="Address of the gRPC server.")
@click.argument("key")
def kv_get(address: str, key: str) -> None:
    """Gets a value from the KV store by key."""
    try:
        with grpc.insecure_channel(address) as channel:
            stub = kv_pb2_grpc.KVStub(channel)
            response = stub.Get(kv_pb2.GetRequest(key=key.encode()))
            if response.value:
                click.echo(response.value.decode())
            else:
                click.echo(f"Key '{key}' not found.", err=True)
    except grpc.RpcError as e:
        click.echo(f"RPC Error: {e.details()}", err=True)


@rpc_cli.command("server-start")
@click.option(
    "--tls-mode",
    type=click.Choice(["disabled", "auto", "manual"]),
    default="disabled",
    help="TLS mode: 'disabled', 'auto', or 'manual'",
)
@click.option(
    "--tls-key-type",
    type=click.Choice(["ec", "rsa"]),
    default="ec",
    help="Key type for auto TLS: 'ec' or 'rsa'",
)
@click.option("--cert-file", help="Path to certificate file (required for manual TLS)")
@click.option("--key-file", help="Path to private key file (required for manual TLS)")
def server_start(tls_mode: str, tls_key_type: str, cert_file: str | None, key_file: str | None) -> None:
    """Starts the KV plugin server."""
    from provide.foundation import logger

    # Validate TLS configuration
    if tls_mode == "manual":
        if not cert_file or not key_file:
            click.echo(
                "Error: --cert-file and --key-file are required when --tls-mode is 'manual'",
                err=True,
            )
            sys.exit(1)
    elif tls_mode == "auto" and tls_key_type not in ["ec", "rsa"]:
        click.echo(
            "Error: --tls-key-type must be 'ec' or 'rsa' when --tls-mode is 'auto'",
            err=True,
        )
        sys.exit(1)

    # Check for magic cookie (required for go-plugin compatibility)
    magic_cookie_key = os.getenv("PLUGIN_MAGIC_COOKIE_KEY", "BASIC_PLUGIN")
    magic_cookie_value = os.getenv(magic_cookie_key)

    if not magic_cookie_value:
        logger.error(
            f"Magic cookie mismatch. Environment variable '{magic_cookie_key}' not set. "
            "This server is a plugin and not meant to be executed directly."
        )
        sys.exit(1)

    expected_value = "hello"  # This should match the Go implementation
    if magic_cookie_value != expected_value:
        logger.error(
            f"Magic cookie mismatch. Expected '{expected_value}', got '{magic_cookie_value}'. "
            "This server is a plugin and not meant to be executed directly."
        )
        sys.exit(1)

    logger.info(
        "Starting KV plugin server...",
        tls_mode=tls_mode,
        tls_key_type=tls_key_type,
        cert_file=cert_file,
        key_file=key_file,
    )

    # Start the server with the specified TLS configuration
    start_kv_server(
        tls_mode=tls_mode,
        tls_key_type=tls_key_type,
        cert_file=cert_file,
        key_file=key_file,
    )


# 🍲🥄🖥️🪄
>>> EOF >>>

### FILE 72: tofusoup/rpc/client.py | checksum=133c8e7eaa7e... | modified=2025-10-10T12:05:53 | op=+ | size=19266 | tokens=3864 | type=x-python ###
<<< BOF <<<
#
# tofusoup/rpc/client.py
#
import asyncio
import logging
import os
import time

import grpc
from provide.foundation import logger

from tofusoup.config.defaults import (
    CONNECTION_TIMEOUT,
    ENV_GRPC_DEFAULT_CLIENT_CERTIFICATE_PATH,
    ENV_GRPC_DEFAULT_CLIENT_PRIVATE_KEY_PATH,
    ENV_GRPC_DEFAULT_SSL_ROOTS_FILE_PATH,
    REQUEST_TIMEOUT,
)

# Optional RPC integration
try:
    from pyvider.rpcplugin.client import RPCPluginClient
    from pyvider.rpcplugin.config import rpcplugin_config

    HAS_RPC = True
except ImportError:
    HAS_RPC = False
    RPCPluginClient = None
    rpcplugin_config = {}
from tofusoup.harness.proto.kv import KVProtocol, kv_pb2, kv_pb2_grpc

logging.basicConfig(
    level=logging.WARNING,
    format="%(asctime)s.%(msecs)03d [%(levelname)-7s] %(name)s: 🐍 C> %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)


class KVClient:
    """Client for KV plugin server with mTLS and explicit config capabilities."""

    def __init__(
        self,
        server_path: str,
        tls_mode: str = "disabled",
        tls_key_type: str = "ec",
        cert_file: str | None = None,
        key_file: str | None = None,
    ) -> None:
        self.tls_mode = tls_mode
        self.tls_key_type = tls_key_type
        self.server_path = server_path
        self.cert_file = cert_file
        self.key_file = key_file
        self._client: RPCPluginClient | None = None
        self._stub: kv_pb2_grpc.KVStub | None = None
        self.is_started = False
        self.connection_timeout = CONNECTION_TIMEOUT

        # Map tls_mode to enable_mtls for internal use
        self.enable_mtls = self.tls_mode != "disabled"

        go_server_expected_cookie_key = "BASIC_PLUGIN"
        go_server_expected_cookie_value = "hello"
        go_server_protocol_version = "1"

        self.subprocess_env = {
            "PLUGIN_MAGIC_COOKIE_KEY": go_server_expected_cookie_key,
            go_server_expected_cookie_key: go_server_expected_cookie_value,
            "PLUGIN_PROTOCOL_VERSIONS": go_server_protocol_version,
            "LOG_LEVEL": os.getenv("LOG_LEVEL", logger.level.name if hasattr(logger, "level") else "INFO"),  # type: ignore
            "PYTHONUNBUFFERED": "1",
            "GODEBUG": os.getenv("GODEBUG", "asyncpreemptoff=1,panicasync=1"),
            "PLUGIN_AUTO_MTLS": "true" if self.enable_mtls else "false",
        }

        # Map TLS key type to legacy environment variables if needed
        if self.tls_key_type == "ec":
            self.subprocess_env["PYVIDER_CLIENT_CERT_ALGO"] = "ecdsa"
            self.subprocess_env["PYVIDER_CLIENT_CERT_CURVE"] = "P-256"
        elif self.tls_key_type == "rsa":
            self.subprocess_env["PYVIDER_CLIENT_CERT_ALGO"] = "rsa"

        logger.info(
            f"[KVClient.__init__] Before update: rpcplugin_config.PLUGIN_MAGIC_COOKIE_KEY = {rpcplugin_config.plugin_magic_cookie_key}"
        )
        logger.info(
            f"[KVClient.__init__] Before update: rpcplugin_config.PLUGIN_MAGIC_COOKIE_VALUE = {rpcplugin_config.plugin_magic_cookie_value}"
        )

        if rpcplugin_config.plugin_magic_cookie_key != go_server_expected_cookie_key:
            logger.info(
                f"Updating rpcplugin_config PLUGIN_MAGIC_COOKIE_KEY to '{go_server_expected_cookie_key}'"
            )
            rpcplugin_config.plugin_magic_cookie_key = go_server_expected_cookie_key
        else:
            logger.info(f"rpcplugin_config.PLUGIN_MAGIC_COOKIE_KEY already '{go_server_expected_cookie_key}'")

        if rpcplugin_config.plugin_magic_cookie_value != go_server_expected_cookie_value:
            logger.info(
                f"Updating rpcplugin_config PLUGIN_MAGIC_COOKIE_VALUE to '{go_server_expected_cookie_value}'"
            )
            rpcplugin_config.plugin_magic_cookie_value = go_server_expected_cookie_value
        else:
            logger.info(
                f"rpcplugin_config.PLUGIN_MAGIC_COOKIE_VALUE already '{go_server_expected_cookie_value}'"
            )

        logger.info(
            f"[KVClient.__init__] After update: rpcplugin_config.PLUGIN_MAGIC_COOKIE_KEY = {rpcplugin_config.plugin_magic_cookie_key}"
        )
        logger.info(
            f"[KVClient.__init__] After update: rpcplugin_config.PLUGIN_MAGIC_COOKIE_VALUE = {rpcplugin_config.plugin_magic_cookie_value}"
        )
        logger.info(f"[KVClient.__init__] self.subprocess_env for plugin: {self.subprocess_env}")

    async def start(self) -> None:
        start_time = time.time()
        self.is_started = False
        try:
            pyvider_client_mtls_mode = "true" if self.enable_mtls else "false"
            logger.info(f"Setting rpcplugin_config.PLUGIN_AUTO_MTLS to: {pyvider_client_mtls_mode}")
            rpcplugin_config.plugin_auto_mtls = pyvider_client_mtls_mode

            if self.enable_mtls:
                client_cert_env = os.getenv("PLUGIN_CLIENT_CERT")
                client_key_env = os.getenv("PLUGIN_CLIENT_KEY")
                server_ca_env = os.getenv("PLUGIN_SERVER_CERT_CHAIN")

                if client_cert_env:
                    logger.info(f"Updating rpcplugin_config with PLUGIN_CLIENT_CERT: {client_cert_env}")
                    rpcplugin_config.plugin_client_cert = client_cert_env
                if client_key_env:
                    logger.info(f"Updating rpcplugin_config with PLUGIN_CLIENT_KEY: {client_key_env}")
                    rpcplugin_config.plugin_client_key = client_key_env
                if server_ca_env:
                    logger.info(f"Updating rpcplugin_config with PLUGIN_SERVER_CERT_CHAIN: {server_ca_env}")
                    rpcplugin_config.plugin_server_cert_chain = server_ca_env

            logger.debug(f"KVClient attempting to start server: {self.server_path}")

            if not os.path.exists(self.server_path):
                raise FileNotFoundError(f"Server executable not found: {self.server_path}")
            if not os.access(self.server_path, os.X_OK):
                raise PermissionError(f"Server executable not executable: {self.server_path}")

            server_command = [self.server_path]
            # Prepare effective_env early as it might be modified
            effective_env = (
                os.environ.copy()
            )  # Start with current env, which includes what tests monkeypatched
            effective_env.update(
                self.subprocess_env
            )  # Merge KVClient's base env for plugin (e.g., GODEBUG, PYTHONUNBUFFERED)
            # Note: self.subprocess_env contains PLUGIN_AUTO_MTLS which pyvider-rpcplugin client might read via rpcplugin_config
            # This is separate from how the server is told to configure its TLS.

            # Add TLS configuration arguments
            # Check if binary name suggests it needs subcommands
            binary_name = os.path.basename(self.server_path)
            if binary_name in ["soup-go", "go-harness"]:
                # New harnesses expect rpc server-start subcommand
                server_command.extend(["rpc", "server-start"])
            # For existing go-rpc binary, just pass flags directly

            server_command.extend(["--tls-mode", self.tls_mode])

            if self.tls_mode == "auto":
                server_command.extend(["--tls-key-type", self.tls_key_type])
                logger.info(f"KVClient: Auto TLS enabled with key type: {self.tls_key_type}")
            elif self.tls_mode == "manual":
                if self.cert_file and self.key_file:
                    server_command.extend(["--cert-file", self.cert_file])
                    server_command.extend(["--key-file", self.key_file])
                    logger.info(
                        f"KVClient: Manual TLS enabled with cert: {self.cert_file}, key: {self.key_file}"
                    )
                else:
                    # Fallback: try to get paths from environment variables
                    server_cert_path = os.getenv("PLUGIN_SERVER_CERT")
                    server_key_path = os.getenv("PLUGIN_SERVER_KEY")
                    if server_cert_path and server_key_path:
                        server_command.extend(["--cert-file", server_cert_path])
                        server_command.extend(["--key-file", server_key_path])
                        logger.info(
                            f"KVClient: Manual TLS enabled using env vars - cert: {server_cert_path}, key: {server_key_path}"
                        )
                    else:
                        logger.error("KVClient: Manual TLS mode requires cert-file and key-file")
                        raise ValueError(
                            "Manual TLS mode requires cert_file and key_file parameters or PLUGIN_SERVER_CERT/PLUGIN_SERVER_KEY environment variables"
                        )
            else:  # disabled
                logger.info("KVClient: TLS disabled - running in insecure mode")

            logger.info(f"Effective server command for plugin: {' '.join(server_command)}")

            # Ensure PLUGIN_AUTO_MTLS in effective_env (for pyvider-rpcplugin client itself) matches KVClient's intent
            effective_env["PLUGIN_AUTO_MTLS"] = "true" if self.enable_mtls else "false"

            # Set up magic cookies in the server's effective_env.
            go_server_expected_cookie_key_name = "BASIC_PLUGIN"
            go_server_expected_cookie_value = "hello"
            effective_env["PLUGIN_MAGIC_COOKIE_KEY"] = go_server_expected_cookie_key_name
            effective_env[go_server_expected_cookie_key_name] = go_server_expected_cookie_value
            if (
                "PLUGIN_MAGIC_COOKIE" in effective_env
                and go_server_expected_cookie_key_name != "PLUGIN_MAGIC_COOKIE"
            ):
                del effective_env["PLUGIN_MAGIC_COOKIE"]
            logger.info(
                f"Final effective_env for subprocess will include: PLUGIN_MAGIC_COOKIE_KEY={effective_env.get('PLUGIN_MAGIC_COOKIE_KEY')}, {go_server_expected_cookie_key_name}={effective_env.get(go_server_expected_cookie_key_name)}"
            )

            # --- Configure RPCPluginClient (the Python gRPC client part) ---
            client_constructor_config = {
                "plugins": {"kv": KVProtocol()},
                "env": effective_env,  # Env for the server subprocess it launches
                # Ensure RPCPluginClient knows mTLS is desired for its gRPC channel
                "enable_mtls": self.enable_mtls,
            }

            if self.enable_mtls:
                # Tests use GRPC_DEFAULT_* env vars for client's mTLS materials.
                # RPCPluginClient's explicit mTLS path expects these in its config dict.
                client_cert_path_env = os.getenv(ENV_GRPC_DEFAULT_CLIENT_CERTIFICATE_PATH)
                client_key_path_env = os.getenv(ENV_GRPC_DEFAULT_CLIENT_PRIVATE_KEY_PATH)
                server_ca_path_env = os.getenv(
                    ENV_GRPC_DEFAULT_SSL_ROOTS_FILE_PATH
                )  # CA client uses to verify server

                if client_cert_path_env and client_key_path_env and server_ca_path_env:
                    logger.info(
                        "KVClient: Populating RPCPluginClient config for mTLS with paths from GRPC_DEFAULT_* env vars."
                    )
                    client_constructor_config["client_cert_path"] = client_cert_path_env
                    client_constructor_config["client_key_path"] = client_key_path_env
                    client_constructor_config["server_root_ca_path"] = server_ca_path_env
                else:
                    logger.warning(
                        f"KVClient: mTLS enabled for KVClient, but not all {ENV_GRPC_DEFAULT_CLIENT_CERTIFICATE_PATH}, "
                        f"{ENV_GRPC_DEFAULT_CLIENT_PRIVATE_KEY_PATH}, or {ENV_GRPC_DEFAULT_SSL_ROOTS_FILE_PATH} env vars are set. "
                        "RPCPluginClient might not establish mTLS correctly if it relies on these config paths."
                    )

            logger.debug(
                f"KVClient: Final client_constructor_config for RPCPluginClient: {client_constructor_config}"
            )
            self._client = RPCPluginClient(
                command=server_command,
                config=client_constructor_config,
            )

            logger.debug(f"Starting RPCPluginClient (pyvider), timeout={self.connection_timeout}s")
            await asyncio.wait_for(self._client.start(), timeout=self.connection_timeout)

            if self._client._process and self._client._process.stderr:
                self._relay_stderr()

            self._stub = kv_pb2_grpc.KVStub(self._client.grpc_channel)
            self.is_started = True
            logger.info(
                f"KVClient connected to server in {time.time() - start_time:.3f}s. Server PID: {self._client._process.pid if self._client._process else 'N/A'}"
            )

        except TimeoutError:
            logger.error(f"KVClient connection to server timed out after {time.time() - start_time:.3f}s")
            if self._client and self._client._process and self._client._process.poll() is None:
                logger.debug("Server process was still running after client timeout.")
            self.is_started = False
            raise
        except Exception as e:
            logger.error(
                f"KVClient failed to connect/start server: {type(e).__name__} - {e}",
                exc_info=True,
            )
            self.is_started = False
            raise

    def _relay_stderr(self) -> None:
        import threading

        if not (self._client and self._client._process and self._client._process.stderr):
            logger.warning("stderr relay: client process or stderr not available.")
            return
        stderr_pipe = self._client._process.stderr

        def read_stderr_thread() -> None:
            logger.debug("stderr relay thread started.")
            while True:
                try:
                    if stderr_pipe.closed:
                        break
                    if not self._client or not self._client._process:
                        break
                    line_bytes = stderr_pipe.readline()
                    if not line_bytes:
                        break
                    decoded = line_bytes.decode("utf-8", errors="replace").strip()
                    if decoded:
                        logger.debug(f"SERVER_STDERR: {decoded}")
                except ValueError:
                    break
                except Exception as e:
                    logger.error(
                        f"Error in stderr relay thread: {type(e).__name__} - {e}",
                        exc_info=True,
                    )
                    break
            logger.debug("stderr relay thread finished.")

        thread = threading.Thread(target=read_stderr_thread, daemon=True)
        thread.start()

    async def close(self) -> None:
        if self._client:
            logger.debug("KVClient closing connection...")
            self.is_started = False
            try:
                if self._client._process and self._client._process.returncode is None:
                    if hasattr(self._client, "close") and asyncio.iscoroutinefunction(self._client.close):
                        await self._client.close()
                    elif hasattr(self._client, "close"):
                        self._client.close()
                    logger.debug("RPCPluginClient close called.")
                else:
                    logger.debug("RPCPluginClient process already terminated or not started.")
            except Exception as e:
                logger.error(
                    f"Error during RPCPluginClient.close(): {type(e).__name__} - {e}",
                    exc_info=True,
                )
            finally:
                self._client = None
                self._stub = None
                logger.debug("KVClient connection closed and attributes reset.")
        else:
            self.is_started = False
            logger.debug("KVClient.close() called but client was not initialized or already closed.")

    async def put(self, key: str, value: bytes) -> None:
        if not self.is_started or not self._stub:
            raise RuntimeError("KVClient not connected to server.")
        if not isinstance(value, bytes):
            raise TypeError("Value for put must be bytes.")
        try:
            logger.debug(f"KVClient: Sending Put - key='{key}', value_size={len(value)} bytes.")
            await asyncio.wait_for(
                self._stub.Put(kv_pb2.PutRequest(key=key, value=value)), timeout=REQUEST_TIMEOUT
            )
            logger.info(f"KVClient: Put successful for key='{key}'.")
        except TimeoutError:
            logger.error(f"KVClient: Put operation timed out for key='{key}'.")
            raise
        except Exception as e:
            logger.error(
                f"KVClient: Put failed for key='{key}'. Error: {type(e).__name__} - {e}",
                exc_info=True,
            )
            raise

    async def get(self, key: str) -> bytes | None:
        if not self.is_started or not self._stub:
            raise RuntimeError("KVClient not connected to server.")
        try:
            logger.debug(f"KVClient: Sending Get - key='{key}'.")
            response = await asyncio.wait_for(
                self._stub.Get(kv_pb2.GetRequest(key=key)), timeout=REQUEST_TIMEOUT
            )

            if response is not None:
                # In proto3, a bytes field defaults to empty bytes if not explicitly set.
                # The server's Get RPC implementation for a non-existent key returns a gRPC NOT_FOUND error,
                # which is caught by the AioRpcError handler below.
                # So, if we get here with a non-None response, the key was found.
                # response.value will be the bytes (could be empty if an empty value was stored).
                logger.info(
                    f"KVClient: Get successful for key='{key}', retrieved {len(response.value)} bytes."
                )
                return response.value
            else:
                # This path should ideally not be reached given gRPC behavior (either response or error).
                logger.warning(f"KVClient: Get for key='{key}' returned a None response object (unexpected).")
                return None
        except grpc.aio.AioRpcError as e:
            if e.code() == grpc.StatusCode.NOT_FOUND:
                logger.info(f"KVClient: Key='{key}' not found on server (gRPC StatusCode.NOT_FOUND).")
                return None  # Correctly return None for not found
            logger.error(
                f"KVClient: Get for key='{key}' failed with gRPC error {e.code()}: {e.details()}",
                exc_info=True,
            )
            raise
        except TimeoutError:  # Keep specific timeout error handling
            logger.error(f"KVClient: Get operation timed out for key='{key}'.")
            raise
        except Exception as e:
            logger.error(
                f"KVClient: Get for key='{key}' failed. Error: {type(e).__name__} - {e}",
                exc_info=True,
            )
            raise


# 🍲🥄🖥️🪄
>>> EOF >>>

### FILE 73: tofusoup/rpc/logic.py | checksum=d1c7b7166ba5... | modified=2025-10-10T12:39:02 | op=+ | size=6164 | tokens=1376 | type=x-python ###
<<< BOF <<<
#
# tofusoup/rpc/logic.py
#
"""
Core logic for RPC operations, including test orchestration.
"""

import asyncio
import pathlib

from provide.foundation import logger

# from typing import Tuple, Any, Coroutine # Not used
from rich import print as rich_print

from tofusoup.harness.logic import ensure_go_harness_build
from tofusoup.rpc.client import KVClient

# Configuration
GO_KV_HARNESS_NAME = "go-rpc"  # Updated from "kvstore-go" to align with harness.logic
# GO_KV_SERVER_BINARY_NAME = "kvstore-server-go" # Seems unused
# PYTHON_SERVER_PORT = 50051 # Unused with dynamic addressing
# GO_SERVER_PORT = 50052 # Unused with dynamic addressing

TEST_KEY = "compat_test_key"
TEST_VALUE_PY = b"value_from_python_client_for_python_server"
TEST_VALUE_GO = b"value_from_python_client_for_go_server"


async def _run_client_operations(client: KVClient, key: str, value_to_put: bytes, server_type: str) -> bool:
    """Helper to run Put and Get operations and verify."""
    try:
        await client.put(key, value_to_put)
        logger.info(f"Client PUT '{key}' to {server_type} server successful.")
        retrieved_value = await client.get(key)
        if retrieved_value == value_to_put:
            logger.info(f"Client GET '{key}' from {server_type} server successful and value matches.")
            return True
        else:
            logger.error(
                f"Client GET from {server_type} server: Value mismatch. Expected '{value_to_put}', got '{retrieved_value}'"
            )
            return False
    except Exception as e:
        logger.error(f"Client operations against {server_type} server failed: {e}", exc_info=True)
        return False


async def _test_with_python_server(project_root: pathlib.Path, loaded_config: dict) -> bool:
    logger.info("Starting Python KV server for testing...")
    python_server_script_path = project_root / "src" / "tofusoup" / "rpc" / "server.py"
    if not python_server_script_path.exists():
        logger.error(f"Python KV server script not found at {python_server_script_path}.")
        return False

    client = None
    success = False
    try:
        # KVClient will start server.py as a subprocess.
        client = KVClient(
            server_path=str(python_server_script_path),
            tls_mode="auto",
            tls_key_type="ec",
        )

        await client.start()
        logger.info("Python client connected to Python KV server (via subprocess).")
        success = await _run_client_operations(client, TEST_KEY, TEST_VALUE_PY, "Python (subprocess)")
    except Exception as e:
        logger.error(f"Python Client vs Python Server test failed: {e}", exc_info=True)
        success = False
    finally:
        if client:
            await client.close()
    return success


async def _test_with_go_server(
    project_root: pathlib.Path, go_server_executable: pathlib.Path, loaded_config: dict
) -> bool:
    logger.info(f"Testing with Go KV server from: {go_server_executable}")
    client = None
    success = False
    try:
        # KVClient handles starting the Go server subprocess.
        client = KVClient(
            server_path=str(go_server_executable),
            tls_mode="auto",
            tls_key_type="ec",
        )
        await client.start()
        logger.info("Python client connected to Go KV server.")
        success = await _run_client_operations(client, TEST_KEY, TEST_VALUE_GO, "Go")

    except FileNotFoundError:
        logger.error(f"Go KV server executable not found at {go_server_executable}.")
        return False
    except Exception as e:
        logger.error(f"Error during Go KV server test: {e}", exc_info=True)
        return False
    finally:
        if client:
            await client.close()
    return success


def run_rpc_compatibility_tests(project_root: pathlib.Path, loaded_config: dict) -> bool:
    """
    Runs RPC compatibility tests:
    - Python Client vs Go Server
    - Python Client vs Python Server
    """
    logger.info("Running RPC compatibility tests...")
    overall_success = True

    # --- Test Python Client vs Go Server ---
    rich_print("\n[bold cyan]--- Testing: Python Client vs. Go KV Server ---[/bold cyan]")
    try:
        go_server_executable = ensure_go_harness_build(GO_KV_HARNESS_NAME, project_root, loaded_config)
        if not go_server_executable or not go_server_executable.exists():
            logger.error(
                f"Go KV server executable (from harness '{GO_KV_HARNESS_NAME}') not found or build failed."
            )
            py_client_vs_go_server_success = False
        else:
            logger.info(f"Found Go KV server executable: {go_server_executable}")
            py_client_vs_go_server_success = asyncio.run(
                _test_with_go_server(project_root, go_server_executable, loaded_config)
            )
    except Exception as e:
        logger.error(f"Failed to build or locate Go KV server harness: {e}", exc_info=True)
        py_client_vs_go_server_success = False

    if py_client_vs_go_server_success:
        rich_print("[bold green]Python Client vs. Go Server: PASSED[/bold green]")
    else:
        rich_print("[bold red]Python Client vs. Go Server: FAILED[/bold red]")
        overall_success = False

    # --- Test Python Client vs Python Server ---
    rich_print("\n[bold cyan]--- Testing: Python Client vs. Python KV Server ---[/bold cyan]")
    try:
        py_client_vs_py_server_success = asyncio.run(_test_with_python_server(project_root, loaded_config))
    except Exception as e:
        logger.error(f"Python Client vs Python Server test execution failed: {e}", exc_info=True)
        py_client_vs_py_server_success = False

    if py_client_vs_py_server_success:
        rich_print("[bold green]Python Client vs. Python Server: PASSED[/bold green]")
    else:
        rich_print("[bold red]Python Client vs. Python Server: FAILED[/bold red]")
        overall_success = False

    if overall_success:
        logger.info("All RPC compatibility tests passed.")
    else:
        logger.error("One or more RPC compatibility tests failed.")

    return overall_success


# <3 🍲 🍜 🍥>


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 74: tofusoup/rpc/plugin_server.py | checksum=c1148bad9d3e... | modified=2025-09-17T17:32:12 | op=+ | size=2733 | tokens=604 | type=x-python ###
<<< BOF <<<
#!/usr/bin/env python3
#
# tofusoup/rpc/plugin_server.py
#
"""
TofuSoup Python KV Plugin Server

A go-plugin compatible Python server that implements the KV interface
using pyvider-rpcplugin framework. This server is compatible with
hashicorp/go-plugin protocol and can be used for cross-language testing.
"""

import asyncio
import os
import sys
from typing import Any

from provide.foundation import logger

from pyvider.rpcplugin.factories import plugin_server
from pyvider.rpcplugin.protocol.base import RPCPluginProtocol
from tofusoup.harness.proto.kv import kv_pb2_grpc
from tofusoup.rpc.server import KV


class KVProtocol(RPCPluginProtocol):
    """Protocol implementation for the KV service"""

    async def get_grpc_descriptors(self) -> tuple[Any, str]:
        """Return the gRPC descriptor and service name"""
        return kv_pb2_grpc, "kv.KVService"

    async def add_to_server(self, server: Any, handler: Any) -> None:
        """Add the KV service to the gRPC server"""
        kv_pb2_grpc.add_KVServicer_to_server(handler, server)
        logger.info("KV service registered with gRPC server")


async def start_kv_server() -> None:
    """Start the KV plugin server - this is the expected entry point"""
    logger.info("Starting KV plugin server...")

    # Create the KV handler
    handler = KV()

    # Create the protocol wrapper
    protocol = KVProtocol()

    # Create the plugin server using the factory function
    server = plugin_server(protocol=protocol, handler=handler)

    try:
        # This handles all the go-plugin handshake and serving
        await server.serve()
    except KeyboardInterrupt:
        logger.info("Received shutdown signal")
    except Exception as e:
        logger.error(f"Plugin server error: {e}")
        sys.exit(1)
    finally:
        logger.info("Plugin server shut down")


async def main() -> None:
    """Main entry point for the plugin server executable"""
    # Check for magic cookie - this indicates it's being run by go-plugin
    magic_cookie_key = os.getenv("PLUGIN_MAGIC_COOKIE_KEY", "BASIC_PLUGIN")
    magic_cookie_value = os.getenv(magic_cookie_key)
    expected_magic_value = os.getenv("PLUGIN_MAGIC_COOKIE_VALUE", "hello")

    if magic_cookie_value != expected_magic_value:
        logger.error(
            "Magic cookie mismatch. This binary is a plugin and not meant to be executed directly.",
            expected_key=magic_cookie_key,
            expected_value=expected_magic_value,
            actual_value=magic_cookie_value,
        )
        logger.error("Please execute the program that consumes these plugins.")
        sys.exit(1)

    await start_kv_server()


if __name__ == "__main__":
    asyncio.run(main())


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 75: tofusoup/rpc/server.py | checksum=d244342bad80... | modified=2025-10-10T12:05:26 | op=+ | size=8096 | tokens=1772 | type=x-python ###
<<< BOF <<<
#!/usr/bin/env python3
#
# tofusoup/rpc/server.py
#
from concurrent import futures
import re
import sys
import time

import grpc
from provide.foundation import logger

from tofusoup.config.defaults import DEFAULT_GRPC_PORT
from tofusoup.harness.proto.kv import kv_pb2, kv_pb2_grpc


class KV(kv_pb2_grpc.KVServicer):
    def __init__(self, storage_dir: str = "/tmp") -> None:
        """
        Initialize KV servicer with configurable storage directory.

        Args:
            storage_dir: Directory to store KV data files. Defaults to /tmp.
        """
        self.storage_dir = storage_dir
        self.key_pattern = re.compile(r"^[a-zA-Z0-9.-]+$")
        logger.debug("Initialized KV servicer", storage_dir=storage_dir)

    def _validate_key(self, key: str) -> bool:
        """Validate that key contains only allowed characters [a-zA-Z0-9.-]"""
        return bool(self.key_pattern.match(key))

    def _get_file_path(self, key: str) -> str:
        """Get the file path for a given key"""
        return f"{self.storage_dir}/soup-kv-{key}"

    def Get(self, request: kv_pb2.GetRequest, context: grpc.ServicerContext) -> kv_pb2.GetResponse:
        logger.info("🔌➡️📥 Received Get request", key=request.key)

        if not self._validate_key(request.key):
            logger.error("Invalid key for Get operation", key=request.key)
            context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
            context.set_details(
                f'Key "{request.key}" contains invalid characters, only [a-zA-Z0-9.-] are allowed'
            )
            return kv_pb2.GetResponse()

        file_path = self._get_file_path(request.key)
        logger.debug("Retrieving value from file", key=request.key, file=file_path)

        try:
            with open(file_path, "rb") as f:
                value = f.read()
            logger.info(
                "Successfully retrieved value",
                key=request.key,
                file=file_path,
                bytes=len(value),
            )
            return kv_pb2.GetResponse(value=value)
        except FileNotFoundError:
            logger.warn("Key not found during Get operation", key=request.key, file=file_path)
            context.set_code(grpc.StatusCode.NOT_FOUND)
            context.set_details(f"Key not found: {request.key}")
            return kv_pb2.GetResponse()
        except Exception as e:
            logger.error(
                "Failed to read value from file",
                key=request.key,
                file=file_path,
                error=str(e),
            )
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f'Failed to read key "{request.key}" from file: {e}')
            return kv_pb2.GetResponse()

    def Put(self, request: kv_pb2.PutRequest, context: grpc.ServicerContext) -> kv_pb2.Empty:
        logger.info("🔌➡️📥 Received Put request", key=request.key)

        if not self._validate_key(request.key):
            logger.error("Invalid key for Put operation", key=request.key)
            context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
            context.set_details(
                f'Key "{request.key}" contains invalid characters, only [a-zA-Z0-9.-] are allowed'
            )
            return kv_pb2.Empty()

        file_path = self._get_file_path(request.key)
        logger.debug("Storing value to file", key=request.key, file=file_path)

        try:
            with open(file_path, "wb") as f:
                f.write(request.value)
            logger.info(
                "Successfully stored value",
                key=request.key,
                file=file_path,
                bytes=len(request.value),
            )
            return kv_pb2.Empty()
        except Exception as e:
            logger.error(
                "Failed to write value to file",
                key=request.key,
                file=file_path,
                error=str(e),
            )
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f'Failed to write key "{request.key}" to file: {e}')
            return kv_pb2.Empty()


def serve(server: grpc.Server, storage_dir: str = "/tmp") -> KV:
    """
    Add KV servicer to gRPC server.

    Args:
        server: gRPC server instance
        storage_dir: Directory to store KV data files. Defaults to /tmp.

    Returns:
        The KV servicer instance
    """
    servicer = KV(storage_dir=storage_dir)
    kv_pb2_grpc.add_KVServicer_to_server(servicer, server)
    return servicer


def main() -> None:
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    serve(server)
    port = server.add_insecure_port(f"[::]:{DEFAULT_GRPC_PORT}")
    logger.info(f"Server started on port {port}")
    server.start()
    try:
        while True:
            time.sleep(86400)
    except KeyboardInterrupt:
        server.stop(0)


def start_kv_server(
    tls_mode: str = "disabled",
    tls_key_type: str = "ec",
    cert_file: str | None = None,
    key_file: str | None = None,
    storage_dir: str = "/tmp",
) -> None:
    """
    Start the KV plugin server with TLS configuration matching the Go implementation.
    This function is designed to work within the go-plugin framework when called by a client.

    Args:
        tls_mode: TLS mode (disabled, auto, or manual)
        tls_key_type: Key type for TLS (ec or rsa)
        cert_file: Path to certificate file (required for manual TLS)
        key_file: Path to private key file (required for manual TLS)
        storage_dir: Directory to store KV data files. Defaults to /tmp.
    """
    logger.info(
        "Starting KV plugin server with Python implementation",
        tls_mode=tls_mode,
        tls_key_type=tls_key_type,
        cert_file=cert_file,
        key_file=key_file,
        storage_dir=storage_dir,
    )

    # Create gRPC server
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))

    # Add the KV servicer with configurable storage directory
    serve(server, storage_dir=storage_dir)

    # Configure TLS based on mode
    if tls_mode == "disabled":
        logger.info("TLS disabled - running in insecure mode")
        port = server.add_insecure_port("[::]:0")  # Use 0 to let OS choose port
        logger.info(f"Server listening on insecure port {port}")

    elif tls_mode == "auto":
        logger.info("Auto TLS mode not fully implemented in Python server - falling back to insecure")
        logger.warning(
            "Python server does not yet support auto-generated certificates like Go's go-plugin framework"
        )
        port = server.add_insecure_port("[::]:0")
        logger.info(f"Server listening on insecure port {port} (auto TLS fallback)")

    elif tls_mode == "manual":
        if not cert_file or not key_file:
            logger.error("Manual TLS mode requires both cert_file and key_file")
            sys.exit(1)

        try:
            logger.info("Manual TLS enabled", cert_file=cert_file, key_file=key_file)

            # Load certificate and private key
            with open(cert_file, "rb") as f:
                cert_data = f.read()
            with open(key_file, "rb") as f:
                key_data = f.read()

            # Create SSL credentials
            server_credentials = grpc.ssl_server_credentials([(key_data, cert_data)])
            port = server.add_secure_port("[::]:0", server_credentials)
            logger.info(f"Server listening on secure port {port}")

        except Exception as e:
            logger.error("Failed to configure manual TLS", error=str(e))
            sys.exit(1)

    else:
        logger.error("Invalid TLS mode", mode=tls_mode)
        sys.exit(1)

    # Start the server
    server.start()
    logger.info("KV plugin server started successfully")

    try:
        # Keep the server running
        while True:
            time.sleep(86400)  # Sleep for a day
    except KeyboardInterrupt:
        logger.info("Shutting down KV plugin server")
        server.stop(0)


if __name__ == "__main__":
    main()


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 76: tofusoup/rpc/stock_cli.py | checksum=62312c3ab96a... | modified=2025-10-10T13:10:39 | op=+ | size=8246 | tokens=1973 | type=x-python ###
<<< BOF <<<
#!/usr/bin/env python3
#
# tofusoup/rpc/stock_cli.py
#
"""
Stock service CLI commands for direct gRPC testing.
Supports multiple language implementations without plugin handshake.
"""

from pathlib import Path
import subprocess
import sys

import click
from provide.foundation import logger
from rich.console import Console
from rich.table import Table

from tofusoup.config.defaults import (
    DEFAULT_CLIENT_LANGUAGE,
    DEFAULT_GRPC_ADDRESS,
    DEFAULT_GRPC_PORT,
    DEFAULT_TLS_MODE,
)

console = Console()

# Supported languages for Stock implementations
SUPPORTED_LANGUAGES = [
    "go",
    "python",
    "java",
    "ruby",
    "csharp",
    "rust",
    "cpp",
    "nodejs",
]


def get_stock_binary_path(language: str, role: str) -> Path:
    """
    Get the path to the stock binary for a given language and role.

    Note: Paths are currently hardcoded. Future enhancement will read from soup.toml configuration.
    """
    base_dir = Path(__file__).parent.parent.parent.parent / "direct" / language

    binary_map = {
        "go": base_dir / "bin" / f"stock-{role}",
        "python": base_dir / f"stock_{role}.py",
        "java": base_dir / "target" / f"stock-{role}.jar",
        "ruby": base_dir / f"stock_{role}.rb",
        "csharp": base_dir / "bin" / f"Stock{role.title()}",
        "rust": base_dir / "target" / "release" / f"stock-{role}",
        "cpp": base_dir / "build" / f"stock_{role}",
        "nodejs": base_dir / f"stock-{role}.js",
    }

    return binary_map.get(language, base_dir / f"stock-{role}")


@click.group("stock")
def stock_cli() -> None:
    """Direct gRPC Stock service commands (no plugin handshake)."""
    pass


@stock_cli.command("server")
@click.argument("language", type=click.Choice(SUPPORTED_LANGUAGES))
@click.option("--port", default=DEFAULT_GRPC_PORT, help="Port to listen on")
@click.option("--tls-mode", type=click.Choice(["none", "auto", "manual"]), default=DEFAULT_TLS_MODE)
@click.option("--cert-file", help="TLS certificate file (manual mode)")
@click.option("--key-file", help="TLS key file (manual mode)")
def server_cmd(
    language: str,
    port: int,
    tls_mode: str,
    cert_file: str | None,
    key_file: str | None,
) -> None:
    """Start a Stock server in the specified language."""
    binary_path = get_stock_binary_path(language, "server")

    if not binary_path.exists():
        console.print(f"[red]Error: {language} server not found at {binary_path}[/red]")
        console.print(f"[yellow]Run 'soup harness build stock-{language}' first[/yellow]")
        sys.exit(1)

    cmd = [str(binary_path), "--port", str(port), "--tls-mode", tls_mode]

    if tls_mode == "manual":
        if not cert_file or not key_file:
            console.print("[red]Error: --cert-file and --key-file required for manual TLS[/red]")
            sys.exit(1)
        cmd.extend(["--cert-file", cert_file, "--key-file", key_file])

    console.print(f"[green]Starting {language} Stock server on port {port}...[/green]")
    logger.info("Starting Stock server", language=language, port=port, tls_mode=tls_mode)

    try:
        # For interpreted languages, we might need to prepend the interpreter
        if language == "python":
            cmd = ["python3", *cmd]
        elif language == "ruby":
            cmd = ["ruby", *cmd]
        elif language == "nodejs":
            cmd = ["node", *cmd]
        elif language == "java":
            cmd = ["java", "-jar", *cmd]

        subprocess.run(cmd)
    except KeyboardInterrupt:
        console.print("\n[yellow]Server stopped[/yellow]")
    except Exception as e:
        console.print(f"[red]Error running server: {e}[/red]")
        sys.exit(1)


@stock_cli.command("client")
@click.argument("language", type=click.Choice(SUPPORTED_LANGUAGES))
@click.argument("operation", type=click.Choice(["get", "put", "monitor", "inventory"]))
@click.argument("args", nargs=-1)
@click.option("--server", default=DEFAULT_GRPC_ADDRESS, help="Server address")
@click.option("--tls/--no-tls", default=False, help="Use TLS")
@click.option("--ca-file", help="CA certificate file for TLS")
def client_cmd(
    language: str,
    operation: str,
    args: tuple,
    server: str,
    tls: bool,
    ca_file: str | None,
) -> None:
    """Run a Stock client operation in the specified language."""
    binary_path = get_stock_binary_path(language, "client")

    if not binary_path.exists():
        console.print(f"[red]Error: {language} client not found at {binary_path}[/red]")
        console.print(f"[yellow]Run 'soup harness build stock-{language}' first[/yellow]")
        sys.exit(1)

    cmd = [str(binary_path), operation, "--server", server]

    if tls:
        cmd.append("--tls")
        if ca_file:
            cmd.extend(["--ca-file", ca_file])

    # Add operation-specific arguments
    cmd.extend(args)

    logger.info("Running Stock client", language=language, operation=operation, server=server)

    try:
        # For interpreted languages, prepend interpreter
        if language == "python":
            cmd = ["python3", *cmd]
        elif language == "ruby":
            cmd = ["ruby", *cmd]
        elif language == "nodejs":
            cmd = ["node", *cmd]
        elif language == "java":
            cmd = ["java", "-jar", *cmd]

        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.stdout:
            console.print(result.stdout.strip())
        if result.stderr and result.returncode != 0:
            console.print(f"[red]{result.stderr.strip()}[/red]", file=sys.stderr)
            sys.exit(result.returncode)
    except Exception as e:
        console.print(f"[red]Error running client: {e}[/red]")
        sys.exit(1)


@stock_cli.command("matrix")
@click.option("--client", multiple=True, help="Client languages to test")
@click.option("--server", multiple=True, help="Server languages to test")
@click.option("--quick", is_flag=True, help="Run quick subset of tests")
def matrix_cmd(client: tuple, server: tuple, quick: bool) -> None:
    """Run Stock service matrix tests across languages."""
    clients = list(client) if client else SUPPORTED_LANGUAGES
    servers = list(server) if server else SUPPORTED_LANGUAGES

    if quick:
        # Quick mode: just test a few key combinations
        clients = ["go", "python", "java"]
        servers = ["go", "python"]

    total = len(clients) * len(servers)

    table = Table(title="Stock Service Test Matrix")
    table.add_column("Client", style="cyan")
    table.add_column("Server", style="magenta")
    table.add_column("Status", style="green")

    console.print(f"\n[bold]Running {total} test combinations...[/bold]\n")

    passed = 0
    for server_lang in servers:
        for client_lang in clients:
            # NOTE: Test matrix functionality not yet implemented
            # This command shows the test plan but doesn't execute tests
            # Use individual 'client' and 'server' commands for actual testing
            status = "⏸️  Not Implemented"
            table.add_row(client_lang, server_lang, status)

    console.print(table)
    console.print(f"\n[bold]Results: {passed}/{total} passed[/bold]")


# Convenience commands that map to the original KV interface
@stock_cli.command("get")
@click.argument("key")
@click.option("--client", default=DEFAULT_CLIENT_LANGUAGE, help="Client language to use")
@click.option("--server", default=DEFAULT_GRPC_ADDRESS, help="Server address")
def get_cmd(key: str, client: str, server: str) -> None:
    """Get a value using Stock service (convenience wrapper)."""
    ctx = click.get_current_context()
    ctx.invoke(client_cmd, language=client, operation="get", args=(key,), server=server)


@stock_cli.command("put")
@click.argument("key")
@click.argument("value")
@click.option("--client", default=DEFAULT_CLIENT_LANGUAGE, help="Client language to use")
@click.option("--server", default=DEFAULT_GRPC_ADDRESS, help="Server address")
def put_cmd(key: str, value: str, client: str, server: str) -> None:
    """Put a key-value pair using Stock service (convenience wrapper)."""
    ctx = click.get_current_context()
    ctx.invoke(client_cmd, language=client, operation="put", args=(key, value), server=server)


# 🍲🥄🖥️🪄
>>> EOF >>>

### FILE 77: tofusoup/scaffolding/__init__.py | checksum=6cfe7ea91477... | modified=2025-09-17T17:32:12 | op=+ | size=107 | tokens=38 | type=x-python ###
<<< BOF <<<
#
# tofusoup/scaffolding/__init__.py
#
"""Project and component scaffolding tools."""


# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 78: tofusoup/scaffolding/env_generator.py | checksum=53b15ce198c5... | modified=2025-09-17T17:32:12 | op=+ | size=4646 | tokens=1018 | type=x-python ###
<<< BOF <<<
#
# tofusoup/scaffolding/env_generator.py
#
"""Generate env.sh and env.ps1 scripts from templates."""

from pathlib import Path
from typing import Any

from jinja2 import Environment, FileSystemLoader, select_autoescape


class EnvScriptGenerator:
    """Generate environment setup scripts for both bash and PowerShell."""

    def __init__(self, template_base_dir: Path | None = None) -> None:
        """Initialize the generator with template directory."""
        if template_base_dir is None:
            template_base_dir = Path(__file__).parent / "templates" / "env"

        self.template_base_dir = template_base_dir

        # Create separate environments for sh and pwsh templates
        self.sh_env = Environment(
            loader=FileSystemLoader(template_base_dir / "sh"),
            autoescape=select_autoescape(),
            trim_blocks=True,
            lstrip_blocks=True,
        )

        self.ps1_env = Environment(
            loader=FileSystemLoader(template_base_dir / "pwsh"),
            autoescape=select_autoescape(),
            trim_blocks=True,
            lstrip_blocks=True,
        )

    def generate_env_script(
        self,
        project_name: str,
        output_path: Path,
        script_type: str = "sh",
        **kwargs: Any,
    ) -> None:
        """Generate an environment setup script.

        Args:
            project_name: Name of the project
            output_path: Path to write the script
            script_type: Either "sh" for bash or "ps1" for PowerShell
            **kwargs: Additional template variables
        """
        # Default configuration
        config = {
            "project_name": project_name,
            "env_profile_var": f"{project_name.upper()}_WORKENV_PROFILE",
            "venv_prefix": project_name.lower(),
            "use_spinner": script_type == "sh",  # PowerShell doesn't need spinner
            "strict_project_check": False,
            "install_siblings": True,
            "sibling_patterns": ["pyvider*"],
            "special_siblings": [
                {"name": "tofusoup", "var_name": "TOFUSOUP", "with_deps": True},
            ],
            "create_log_dir": True,
            "deduplicate_path": True,
            "include_tool_verification": False,
            "cleanup_logs": True,
            "useful_commands": [
                {
                    "command": f"{project_name.lower()} --help",
                    "description": f"{project_name} CLI",
                },
                {"command": "pytest", "description": "Run tests"},
                {"command": "deactivate", "description": "Exit environment"},
            ],
        }

        # Update with user-provided kwargs
        config.update(kwargs)

        # Select appropriate template and environment
        if script_type == "sh":
            template = self.sh_env.get_template("base.sh.j2")
        elif script_type == "ps1":
            template = self.ps1_env.get_template("base.ps1.j2")
        else:
            raise ValueError(f"Unknown script type: {script_type}")

        # Render and write
        content = template.render(**config)
        output_path.write_text(content)

        # Make executable if it's a shell script
        if script_type == "sh":
            output_path.chmod(output_path.stat().st_mode | 0o111)

    def generate_both_scripts(
        self,
        project_name: str,
        project_dir: Path,
        **kwargs: Any,
    ) -> tuple[Path, Path]:
        """Generate both env.sh and env.ps1 scripts.

        Returns:
            Tuple of (env.sh path, env.ps1 path)
        """
        sh_path = project_dir / "env.sh"
        ps1_path = project_dir / "env.ps1"

        self.generate_env_script(project_name, sh_path, "sh", **kwargs)
        self.generate_env_script(project_name, ps1_path, "ps1", **kwargs)

        return sh_path, ps1_path


def create_project_env_scripts(project_dir: Path) -> None:
    """Create environment scripts for a project based on its pyproject.toml."""
    pyproject_path = project_dir / "pyproject.toml"

    if not pyproject_path.exists():
        raise FileNotFoundError(f"No pyproject.toml found in {project_dir}")

    # Parse project name from pyproject.toml
    import tomllib

    with open(pyproject_path, "rb") as f:
        pyproject = tomllib.load(f)

    project_name = pyproject.get("project", {}).get("name", project_dir.name)

    # Generate scripts
    generator = EnvScriptGenerator()
    sh_path, ps1_path = generator.generate_both_scripts(project_name, project_dir)

    print(f"✅ Generated {sh_path}")
    print(f"✅ Generated {ps1_path}")


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 79: tofusoup/scaffolding/generator.py | checksum=82fb03234b92... | modified=2025-09-17T17:32:12 | op=+ | size=1897 | tokens=473 | type=x-python ###
<<< BOF <<<
#
# tofusoup/scaffolding/generator.py
#
"""Logic for scaffolding new provider projects and components."""

from pathlib import Path
import re

import jinja2

_TEMPLATE_DIR = Path(__file__).parent / "templates"


def _get_template_env() -> jinja2.Environment:
    return jinja2.Environment(
        loader=jinja2.FileSystemLoader(_TEMPLATE_DIR),
        trim_blocks=True,
        lstrip_blocks=True,
    )


def scaffold_new_provider(project_dir: Path) -> Path:
    """Scaffolds a new Pyvider provider project structure."""
    if project_dir.exists() and any(project_dir.iterdir()):
        raise FileExistsError(f"Directory is not empty: {project_dir}")

    project_dir.mkdir(exist_ok=True)

    provider_name_match = re.search(r"terraform-provider-([\w-]+)", project_dir.name)
    if not provider_name_match:
        raise ValueError("Project directory name must be in the format 'terraform-provider-<name>'")
    provider_name = provider_name_match.group(1)

    src_root = project_dir / "src"
    provider_src_dir = src_root / provider_name
    provider_src_dir.mkdir(parents=True, exist_ok=True)

    env = _get_template_env()
    pyproject_template = env.get_template("pyproject.toml.j2")
    pyproject_content = pyproject_template.render(provider_name=provider_name)
    (project_dir / "pyproject.toml").write_text(pyproject_content)

    main_py_content = f'"""Main entry point for the {provider_name} provider."""\nfrom pyvider.provider_core import setup_provider\n\ndef serve():\n    setup_provider()\n'
    (provider_src_dir / "main.py").write_text(main_py_content)

    gitignore_content = "# Python\n__pycache__/\n*.py[cod]\n*$py.class\n*.egg-info/\n.env\n.venv\ndist/\nbuild/\n*.egg\n\n# Terraform\n.terraform/\n.terraform.lock.hcl\n*.tfstate\n*.tfstate.backup\ncrash.log\n"
    (project_dir / ".gitignore").write_text(gitignore_content)
    return project_dir


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 80: tofusoup/scaffolding/templates/data_source/data_source.py.j2 | checksum=e1282c08da4e... | modified=2025-08-07T18:12:49 | op=+ | size=473 | tokens=98 ###
<<< BOF <<<
"""
Data source for {{ component_name }}
"""

from pyvider.data_sources.base import BaseDataSource
from pyvider.hub import register_data_source


@register_data_source("{{ provider_name }}_{{ component_name }}")
class {{ component_class_name }}DataSource(BaseDataSource):
    """
    This is a sample data source.
    """

    def __init__(self):
        super().__init__()

    def get_schema(self):
        return {}

    def read(self, state, config):
        return {}
>>> EOF >>>

### FILE 81: tofusoup/scaffolding/templates/env/pwsh/base.ps1.j2 | checksum=0e1ba9aaa7dd... | modified=2025-08-09T10:25:31 | op=+ | size=896 | tokens=235 ###
<<< BOF <<<
# env.ps1 - {{ project_name }} Development Environment Setup
#
# This script sets up a clean, isolated development environment for {{ project_name }}
# using 'uv' for high-performance virtual environment and dependency management.
#
# Usage: .\env.ps1
#

# --- Configuration ---
$ErrorActionPreference = "Stop"
$ProgressPreference = "SilentlyContinue"

{% include 'print_helpers.ps1.j2' %}

{% include 'cleanup.ps1.j2' %}

{% include 'validation.ps1.j2' %}

{% include 'uv_installation.ps1.j2' %}

{% include 'platform_detection.ps1.j2' %}

{% include 'venv_setup.ps1.j2' %}

{% include 'dependency_installation.ps1.j2' %}

{% if install_siblings %}
{% include 'sibling_packages.ps1.j2' %}
{% endif %}

{% include 'environment_config.ps1.j2' %}

{% if include_tool_verification %}
{% include 'tool_verification.ps1.j2' %}
{% endif %}

{% include 'final_summary.ps1.j2' %}

# Return success
exit 0
>>> EOF >>>

### FILE 82: tofusoup/scaffolding/templates/env/pwsh/cleanup.ps1.j2 | checksum=04359ad16799... | modified=2025-08-09T10:25:48 | op=+ | size=569 | tokens=130 ###
<<< BOF <<<
# --- Cleanup Previous Environment ---
Write-Header "🧹 Cleaning Previous Environment"

# Remove any existing Python aliases
Remove-Alias -Name python -ErrorAction SilentlyContinue
Remove-Alias -Name python3 -ErrorAction SilentlyContinue
Remove-Alias -Name pip -ErrorAction SilentlyContinue
Remove-Alias -Name pip3 -ErrorAction SilentlyContinue

# Clear existing PYTHONPATH
Remove-Item Env:PYTHONPATH -ErrorAction SilentlyContinue

# Store original PATH for restoration if needed
$script:OriginalPath = $env:PATH

Write-Success "Cleared Python aliases and PYTHONPATH"
>>> EOF >>>

### FILE 83: tofusoup/scaffolding/templates/env/pwsh/dependency_installation.ps1.j2 | checksum=96ce320dde37... | modified=2025-08-09T10:26:57 | op=+ | size=1187 | tokens=328 ###
<<< BOF <<<
# --- Dependency Installation ---
Write-Header "📦 Installing Dependencies"

{% if create_log_dir %}
# Create log directory
$LogDir = Join-Path $env:TEMP "{{ project_name }}_setup"
New-Item -ItemType Directory -Force -Path $LogDir | Out-Null
{% endif %}

Write-Host "Syncing dependencies..." -NoNewline
try {
    {% if create_log_dir %}
    & uv sync --all-groups 2>&1 | Out-File -FilePath (Join-Path $LogDir "sync.log")
    {% else %}
    & uv sync --all-groups
    {% endif %}
    Write-Success " Dependencies synced"
}
catch {
    Write-Error " Dependency sync failed"
    {% if create_log_dir %}
    Write-Host "Check log at: $(Join-Path $LogDir 'sync.log')"
    {% endif %}
    exit 1
}

Write-Host "Installing {{ project_name }} in editable mode..." -NoNewline
try {
    {% if create_log_dir %}
    & uv pip install --no-deps -e . 2>&1 | Out-File -FilePath (Join-Path $LogDir "install.log")
    {% else %}
    & uv pip install --no-deps -e .
    {% endif %}
    Write-Success " {{ project_name }} installed"
}
catch {
    Write-Error " Installation failed"
    {% if create_log_dir %}
    Write-Host "Check log at: $(Join-Path $LogDir 'install.log')"
    {% endif %}
    exit 1
}
>>> EOF >>>

### FILE 84: tofusoup/scaffolding/templates/env/pwsh/environment_config.ps1.j2 | checksum=d082d77c690d... | modified=2025-08-09T10:33:25 | op=+ | size=678 | tokens=202 ###
<<< BOF <<<
# --- Environment Configuration ---
Write-Header "🔧 Configuring Environment"

# Set clean PYTHONPATH
$env:PYTHONPATH = "$(Get-Location)/src;$(Get-Location)"
Write-Host "PYTHONPATH: $env:PYTHONPATH"

{% if deduplicate_path %}
# Clean up PATH - remove duplicates and handle cross-platform
if ($IsWindows) {
    $PathSeparator = ';'
    $VenvBin = Join-Path $VenvDir "Scripts"
} else {
    $PathSeparator = ':'
    $VenvBin = Join-Path $VenvDir "bin"
}

$PathArray = $env:PATH -split $PathSeparator | Where-Object { $_ -ne '' } | Select-Object -Unique
$NewPath = @($VenvBin) + ($PathArray | Where-Object { $_ -ne $VenvBin })
$env:PATH = $NewPath -join $PathSeparator
{% endif %}
>>> EOF >>>

### FILE 85: tofusoup/scaffolding/templates/env/pwsh/final_summary.ps1.j2 | checksum=d5f1acfbb447... | modified=2025-08-09T10:27:47 | op=+ | size=706 | tokens=187 ###
<<< BOF <<<
# --- Final Summary ---
Write-Header "✅ Environment Ready!"

Write-Host "`n$("{{ project_name }} development environment activated" | Write-Host -ForegroundColor Green)"
Write-Host "Virtual environment: $VenvDir"
Write-Host "Profile: $Profile"
{% if useful_commands %}
Write-Host "`nUseful commands:"
{% for cmd in useful_commands %}
Write-Host "  {{ cmd.command }}  # {{ cmd.description }}"
{% endfor %}
{% endif %}

{% if cleanup_logs %}
# --- Cleanup ---
# Remove temporary log files older than 1 day
if (Test-Path $LogDir) {
    Get-ChildItem -Path $LogDir -Filter "*.log" | Where-Object { $_.LastWriteTime -lt (Get-Date).AddDays(-1) } | Remove-Item -Force -ErrorAction SilentlyContinue
}
{% endif %}
>>> EOF >>>

### FILE 86: tofusoup/scaffolding/templates/env/pwsh/platform_detection.ps1.j2 | checksum=8c9d2e641e0b... | modified=2025-08-09T10:26:17 | op=+ | size=750 | tokens=211 ###
<<< BOF <<<
# --- Platform Detection ---
$TFOS = if ($IsWindows) { "windows" } elseif ($IsMacOS) { "darwin" } else { "linux" }
$TFARCH = switch ([System.Environment]::Is64BitOperatingSystem) {
    $true { 
        if ([System.Runtime.InteropServices.RuntimeInformation]::ProcessArchitecture -eq [System.Runtime.InteropServices.Architecture]::Arm64) {
            "arm64"
        } else {
            "amd64"
        }
    }
    $false { "386" }
}

# Workenv directory setup
$Profile = if ($env:{{ env_profile_var }}) { $env:{{ env_profile_var }} } else { "default" }
if ($Profile -eq "default") {
    $VenvDir = "workenv/{{ venv_prefix }}_${TFOS}_${TFARCH}"
} else {
    $VenvDir = "workenv/${Profile}_${TFOS}_${TFARCH}"
}

$env:UV_PROJECT_ENVIRONMENT = $VenvDir
>>> EOF >>>

### FILE 87: tofusoup/scaffolding/templates/env/pwsh/print_helpers.ps1.j2 | checksum=3083f92fbb83... | modified=2025-08-09T10:25:38 | op=+ | size=479 | tokens=119 ###
<<< BOF <<<
# Helper functions for formatted output
function Write-Header {
    param([string]$Message)
    Write-Host "`n--- $Message ---" -ForegroundColor Blue
}

function Write-Success {
    param([string]$Message)
    Write-Host "✅ $Message" -ForegroundColor Green
}

function Write-Error {
    param([string]$Message)
    Write-Host "❌ $Message" -ForegroundColor Red
}

function Write-Warning {
    param([string]$Message)
    Write-Host "⚠️  $Message" -ForegroundColor Yellow
}
>>> EOF >>>

### FILE 88: tofusoup/scaffolding/templates/env/pwsh/sibling_packages.ps1.j2 | checksum=85e08b238b83... | modified=2025-08-09T10:27:14 | op=+ | size=1680 | tokens=421 ###
<<< BOF <<<
# --- Sibling Packages ---
Write-Header "🤝 Installing Sibling Packages"

$ParentDir = Split-Path -Parent (Get-Location)
$SiblingCount = 0

{% for sibling_pattern in sibling_patterns %}
Get-ChildItem -Path $ParentDir -Directory -Filter "{{ sibling_pattern }}" | ForEach-Object {
    $SiblingName = $_.Name
    Write-Host "Installing $SiblingName..." -NoNewline
    try {
        {% if create_log_dir %}
        & uv pip install --no-deps -e $_.FullName 2>&1 | Out-File -FilePath (Join-Path $LogDir "$SiblingName.log")
        {% else %}
        & uv pip install --no-deps -e $_.FullName
        {% endif %}
        Write-Success " $SiblingName installed"
        $SiblingCount++
    }
    catch {
        Write-Warning " Failed to install $SiblingName"
    }
}
{% endfor %}

{% if special_siblings %}
# Special handling for specific packages
{% for special in special_siblings %}
${{ special.var_name }}Dir = Join-Path $ParentDir "{{ special.name }}"
if (Test-Path ${{ special.var_name }}Dir) {
    Write-Host "Found {{ special.name }} package. Installing in editable mode{{ ' with dependencies' if special.with_deps else '' }}..." -NoNewline
    try {
        {% if special.with_deps %}
        & uv pip install -e ${{ special.var_name }}Dir
        {% else %}
        & uv pip install --no-deps -e ${{ special.var_name }}Dir
        {% endif %}
        Write-Success " {{ special.name }} installed"
    }
    catch {
        Write-Warning " Failed to install {{ special.name }} package from '${{ special.var_name }}Dir'"
        Write-Host "Attempting to continue..."
    }
}
{% endfor %}
{% endif %}

if ($SiblingCount -eq 0) {
    Write-Warning "No sibling packages found"
}
>>> EOF >>>

### FILE 89: tofusoup/scaffolding/templates/env/pwsh/tool_verification.ps1.j2 | checksum=d8b346d63633... | modified=2025-08-09T10:27:38 | op=+ | size=1196 | tokens=364 ###
<<< BOF <<<
# --- Tool Verification ---
Write-Header "🔍 Verifying Installation"

Write-Host "`nTool Locations & Versions:" -ForegroundColor Green
Write-Host ("━" * 40)

{% for tool in tools_to_verify %}
# {{ tool.name }}
{% if tool.check_type == "command" %}
${{ tool.var_name }}Cmd = Get-Command {{ tool.command }} -ErrorAction SilentlyContinue
if (${{ tool.var_name }}Cmd) {
    Write-Host ("{0,-12}: {1}" -f "{{ tool.name }}", ${{ tool.var_name }}Cmd.Source)
    {% if tool.version_cmd %}
    $Version = & {{ tool.version_cmd }} 2>&1 | Select-Object -First 1
    Write-Host ("{0,-12}  {1}" -f "", $Version)
    {% endif %}
}
{% elif tool.check_type == "file" %}
${{ tool.var_name }}Path = Join-Path $VenvDir "Scripts/{{ tool.command }}.exe"
if (Test-Path ${{ tool.var_name }}Path) {
    Write-Host ("{0,-12}: {1}" -f "{{ tool.name }}", ${{ tool.var_name }}Path)
    {% if tool.version_cmd %}
    $Version = & ${{ tool.var_name }}Path {{ tool.version_args }} 2>&1 | Select-Object -First 1
    Write-Host ("{0,-12}  {1}" -f "", $Version)
    {% elif tool.description %}
    Write-Host ("{0,-12}  {1}" -f "", "{{ tool.description }}")
    {% endif %}
}
{% endif %}

{% endfor %}

Write-Host ("━" * 40)
>>> EOF >>>

### FILE 90: tofusoup/scaffolding/templates/env/pwsh/uv_installation.ps1.j2 | checksum=42f32cd2f361... | modified=2025-08-09T10:26:05 | op=+ | size=966 | tokens=229 ###
<<< BOF <<<
# --- UV Installation ---
Write-Header "🚀 Checking UV Package Manager"

$uvCommand = Get-Command uv -ErrorAction SilentlyContinue
if (-not $uvCommand) {
    Write-Host "Installing UV..."
    
    # Install UV using the official PowerShell installer
    try {
        powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
        
        # Refresh PATH
        $env:PATH = [System.Environment]::GetEnvironmentVariable("PATH", "Machine") + ";" + [System.Environment]::GetEnvironmentVariable("PATH", "User")
        
        # Check if UV is now available
        $uvCommand = Get-Command uv -ErrorAction SilentlyContinue
        if ($uvCommand) {
            Write-Success "UV installed successfully"
        } else {
            Write-Error "UV installation failed"
            exit 1
        }
    }
    catch {
        Write-Error "UV installation failed: $_"
        exit 1
    }
} else {
    Write-Success "UV already installed"
}
>>> EOF >>>

### FILE 91: tofusoup/scaffolding/templates/env/pwsh/validation.ps1.j2 | checksum=016ec07ca58f... | modified=2025-08-09T10:25:55 | op=+ | size=465 | tokens=118 ###
<<< BOF <<<
# --- Project Validation ---
if (-not (Test-Path "pyproject.toml")) {
    Write-Error "No 'pyproject.toml' found in current directory"
    Write-Host "Please run this script from the {{ project_name }} root directory"
    exit 1
}

$ProjectName = Split-Path -Leaf (Get-Location)
{% if strict_project_check %}
if ($ProjectName -ne "{{ project_name }}") {
    Write-Warning "This script is optimized for {{ project_name }} but running in '$ProjectName'"
}
{% endif %}
>>> EOF >>>

### FILE 92: tofusoup/scaffolding/templates/env/pwsh/venv_setup.ps1.j2 | checksum=9c9c7ccd517b... | modified=2025-08-09T10:33:11 | op=+ | size=1445 | tokens=393 ###
<<< BOF <<<
# --- Virtual Environment ---
Write-Header "🐍 Setting Up Virtual Environment"
Write-Host "Directory: $VenvDir"

# Check for existing venv - handle cross-platform paths
if ($IsWindows) {
    $VenvExists = (Test-Path $VenvDir) -and (Test-Path "$VenvDir/Scripts/activate.ps1") -and (Test-Path "$VenvDir/Scripts/python.exe")
} else {
    $VenvExists = (Test-Path $VenvDir) -and (Test-Path "$VenvDir/bin/activate.ps1") -and (Test-Path "$VenvDir/bin/python")
}

if ($VenvExists) {
    Write-Success "Virtual environment exists"
} else {
    Write-Host "Creating virtual environment..." -NoNewline
    try {
        & uv venv $VenvDir
        Write-Success " Virtual environment created"
    }
    catch {
        Write-Error " Virtual environment creation failed: $_"
        exit 1
    }
}

# Activate virtual environment - handle cross-platform paths
if ($IsWindows) {
    $ActivateScript = Join-Path $VenvDir "Scripts/Activate.ps1"
} else {
    # On macOS/Linux, activation script is in bin directory with lowercase name
    $ActivateScript = Join-Path $VenvDir "bin/activate.ps1"
}

if (Test-Path $ActivateScript) {
    & $ActivateScript
    $env:VIRTUAL_ENV = Join-Path (Get-Location) $VenvDir
} else {
    Write-Error "Could not find activation script at $ActivateScript"
    Write-Host "Note: Virtual environment created but activation failed."
    Write-Host "For macOS/Linux, you may need to use: source $VenvDir/bin/activate"
    exit 1
}
>>> EOF >>>

### FILE 93: tofusoup/scaffolding/templates/pyproject.toml.j2 | checksum=5ff8d9e19963... | modified=2025-08-08T19:26:50 | op=+ | size=829 | tokens=225 ###
<<< BOF <<<
# pyproject.toml for terraform-provider-{{ provider_name }}

[project]
name = "terraform-provider-{{ provider_name }}"
version = "0.1.0"
description = "A Terraform provider for {{ provider_name }}, built with Pyvider."
requires-python = ">=3.13"
dependencies = [
    "pyvider>=0.1.0",
]

[project.scripts]
"terraform-provider-{{ provider_name }}" = "{{ provider_name }}.main:serve"

[build-system]
requires = ["pspf>=0.1.0"]
build-backend = "pspf.build_backend"

[tool.pspf]
provider_name = "{{ provider_name }}"
entry_point = "{{ provider_name }}.main:serve"
python_version = "3.13"
targets = []

[tool.pspf.build]
dependencies = []
exclude = [
    "**/.terraform/**",
    "**/.venv/**",
    "**/__pycache__/**",
]

[tool.pspf.signing]
private_key_path = "keys/provider-private.key"
public_key_path = "keys/provider-public.key"
>>> EOF >>>

### FILE 94: tofusoup/scaffolding/templates/resource/resource.py.j2 | checksum=840f3b6f7be2... | modified=2025-10-10T13:11:14 | op=+ | size=4492 | tokens=933 ###
<<< BOF <<<
"""
Scaffolded Pyvider Resource: {{ component_name }}
"""
from typing import Any
import attrs
from pyvider.hub import register_resource
from pyvider.resources.base import BaseResource
from pyvider.resources.context import ResourceContext
from pyvider.schema import PvsSchema, a_str, s_resource
from provide.foundation import logger

# Define an attrs class for this resource's configuration.
@attrs.define(frozen=True)
class {{ component_name | capitalize }}Config:
    example_attribute: str = attrs.field()

# Define an attrs class for this resource's state.
@attrs.define(frozen=True)
class {{ component_name | capitalize }}State:
    id: str = attrs.field()
    example_attribute: str = attrs.field()

@register_resource("{{ provider_name }}_{{ component_name | lower }}")
class {{ component_name | capitalize }}Resource(
    BaseResource[
        "{{ provider_name }}_{{ component_name | lower }}",
        {{ component_name | capitalize }}State,
        {{ component_name | capitalize }}Config
    ]
):
    """Manages the {{ component_name }} resource."""
    
    config_class = {{ component_name | capitalize }}Config
    state_class = {{ component_name | capitalize }}State

    @classmethod
    def get_schema(cls) -> PvsSchema:
        """Defines the schema for the {{ component_name }} resource."""
        return s_resource({
            "id": a_str(computed=True, description="Unique identifier for the resource."),
            "example_attribute": a_str(
                required=True, 
                description="An example configurable attribute."
            ),
        })

    async def read(self, ctx: ResourceContext) -> {{ component_name | capitalize }}State | None:
        """Reads the current state of the resource from the real world."""
        logger.info(f"Reading resource {ctx.state.id if ctx.state else 'new'}")

        # TODO: Implement your read logic here
        # Fetch the resource's actual state from your service/API
        # Return a State object if the resource exists, None if it doesn't
        #
        # Example:
        #   response = await your_api_client.get_resource(ctx.state.id)
        #   if response.found:
        #       return self.state_class(id=response.id, example_attribute=response.value)
        #   return None

        if ctx.state:
            return ctx.state
        return None

    async def plan(self, ctx: ResourceContext) -> tuple[{{ component_name | capitalize }}State | None, None]:
        """Calculates the planned state of the resource."""
        logger.info("Planning resource changes for {{ component_name }}")
        
        # If there is no prior state, we are creating a new resource.
        # We must predict the value of all computed attributes.
        resource_id = ctx.state.id if ctx.state else f"res-{{ component_name | lower }}-{id(ctx)}[:8]"
        
        planned_state = self.state_class(
            id=resource_id,
            example_attribute=ctx.config.example_attribute,
        )
        
        return planned_state, None

    async def apply(self, ctx: ResourceContext) -> tuple[{{ component_name | capitalize }}State | None, None]:
        """Creates or updates the resource to match the planned state."""
        logger.info("Applying resource changes for {{ component_name }}")

        # TODO: Implement your create/update logic here
        # Make API calls to create or update the resource
        # This method MUST be idempotent
        #
        # Example:
        #   if ctx.state is None:
        #       response = await your_api_client.create_resource(ctx.planned_state)
        #   else:
        #       response = await your_api_client.update_resource(ctx.state.id, ctx.planned_state)
        #
        # IMPORTANT: The returned state MUST match ctx.planned_state exactly
        return ctx.planned_state, None

    async def delete(self, ctx: ResourceContext) -> None:
        """Deletes the resource."""
        logger.info(f"Deleting resource {ctx.state.id if ctx.state else 'unknown'}")

        # TODO: Implement your delete logic here
        # Make API calls to delete the resource
        # This method MUST be idempotent (safe to call multiple times)
        #
        # Example:
        #   try:
        #       await your_api_client.delete_resource(ctx.state.id)
        #   except ResourceNotFoundError:
        #       logger.info(f"Resource {ctx.state.id} already deleted")
        #       pass  # Idempotent - already deleted is OK

        pass
>>> EOF >>>

### FILE 95: tofusoup/state.py | checksum=ca7565895e0e... | modified=2025-09-17T17:32:12 | op=+ | size=12555 | tokens=2650 | type=x-python ###
<<< BOF <<<
#
# tofusoup/state.py
#
"""
TofuSoup State Commands

Provides commands for inspecting and manipulating Terraform state,
including decrypting private state data for debugging.
"""

import base64
import json
from pathlib import Path
from typing import Any

import click
import msgpack
from provide.foundation import logger
from rich.console import Console
from rich.panel import Panel
from rich.syntax import Syntax
from rich.table import Table
from rich.tree import Tree

from pyvider.common.encryption import decrypt
from tofusoup.config.defaults import DEFAULT_OUTPUT_FORMAT, DEFAULT_TFSTATE_FILE

console = Console()


def load_terraform_state(state_file: Path) -> dict[str, Any]:
    """Load and parse Terraform state file."""
    try:
        with open(state_file) as f:
            return json.load(f)
    except json.JSONDecodeError as e:
        raise click.ClickException(f"Invalid JSON in state file: {e}")
    except FileNotFoundError:
        raise click.ClickException(f"State file not found: {state_file}")


def find_resources_with_private_state(state: dict[str, Any]) -> list[dict[str, Any]]:
    """Find all resources in state that have private state data."""
    resources_with_private = []

    for resource in state.get("resources", []):
        for instance in resource.get("instances", []):
            private_data = instance.get("private")
            if private_data:
                resources_with_private.append(
                    {
                        "type": resource.get("type"),
                        "name": resource.get("name"),
                        "provider": resource.get("provider"),
                        "mode": resource.get("mode"),
                        "private": private_data,
                        "attributes": instance.get("attributes", {}),
                    }
                )

    return resources_with_private


def decrypt_private_state(encrypted_private: str) -> dict[str, Any] | None:
    """Decrypt private state data using framework encryption."""
    try:
        # Decode base64
        encrypted_bytes = base64.b64decode(encrypted_private)

        # Decrypt using pyvider encryption
        decrypted_bytes = decrypt(encrypted_bytes)

        # Unpack msgpack
        private_data = msgpack.unpackb(decrypted_bytes, raw=False)

        return private_data
    except Exception as e:
        logger.debug(f"Failed to decrypt private state: {e}")
        return None


def display_resource_overview(resources: list[dict[str, Any]]) -> None:
    """Display an overview table of resources with private state."""
    if not resources:
        console.print("[yellow]No resources with private state found.[/yellow]")
        return

    table = Table(title="Resources with Private State")
    table.add_column("Type", style="cyan")
    table.add_column("Name", style="magenta")
    table.add_column("Mode", style="blue")
    table.add_column("Provider", style="green")
    table.add_column("Private Data", style="yellow")

    for resource in resources:
        private_status = "✅ Encrypted" if resource["private"] else "❌ None"
        table.add_row(
            resource["type"],
            resource["name"],
            resource["mode"],
            resource["provider"] or "N/A",
            private_status,
        )

    console.print(table)


def display_resource_details(resource: dict[str, Any], show_encrypted: bool = False) -> None:
    """Display detailed information about a resource including private state."""

    # Resource header
    resource_title = f"{resource['type']}.{resource['name']}"
    console.print(f"\n[bold cyan]{resource_title}[/bold cyan]")

    # Public attributes
    if resource["attributes"]:
        attrs_tree = Tree("📋 [bold]Public Attributes[/bold]")
        for key, value in resource["attributes"].items():
            # Format value for display
            if isinstance(value, dict | list):
                json.dumps(value, indent=2)
                attrs_tree.add(f"[green]{key}[/green]: [dim]{type(value).__name__}[/dim]")
            else:
                attrs_tree.add(f"[green]{key}[/green]: [white]{value}[/white]")
        console.print(attrs_tree)

    # Private state
    if resource["private"]:
        console.print("\n[bold yellow]🔐 Private State[/bold yellow]")

        if show_encrypted:
            console.print("[dim]Encrypted (Base64):[/dim]")
            encrypted_panel = Panel(
                resource["private"],
                title="Encrypted Private State",
                border_style="yellow",
            )
            console.print(encrypted_panel)

        # Try to decrypt
        decrypted = decrypt_private_state(resource["private"])
        if decrypted:
            console.print("[dim]Decrypted Content:[/dim]")
            decrypted_json = json.dumps(decrypted, indent=2, default=str)
            syntax = Syntax(decrypted_json, "json", theme="monokai", line_numbers=True)
            console.print(syntax)
        else:
            console.print("[red]❌ Failed to decrypt private state[/red]")
            console.print("[dim]This could be due to:[/dim]")
            console.print("[dim]• Missing PYVIDER_PRIVATE_STATE_SHARED_SECRET environment variable[/dim]")
            console.print("[dim]• Incorrect shared secret[/dim]")
            console.print("[dim]• Corrupted private state data[/dim]")
    else:
        console.print("[dim]No private state data[/dim]")


@click.group("state")
def state_cli() -> None:
    """Commands for inspecting Terraform state with private state support."""
    pass


@state_cli.command("show")
@click.argument(
    "state_file",
    type=click.Path(exists=True, dir_okay=False),
    default=DEFAULT_TFSTATE_FILE,
)
@click.option("--resource", "-r", help="Show details for a specific resource (format: type.name)")
@click.option("--show-encrypted", is_flag=True, help="Also show encrypted private state data")
@click.option("--private-only", is_flag=True, help="Only show resources that have private state")
def show_state(state_file: str, resource: str | None, show_encrypted: bool, private_only: bool) -> None:
    """
    Display Terraform state with decrypted private state data.

    This command reads a Terraform state file and displays both public attributes
    and decrypted private state data for resources. Requires the
    PYVIDER_PRIVATE_STATE_SHARED_SECRET environment variable to be set.

    Examples:
        soup state show                              # Show overview of all resources
        soup state show --private-only              # Show only resources with private state
        soup state show -r pyvider_timed_token.example  # Show details for specific resource
        soup state show --show-encrypted            # Include encrypted private state in output
    """
    state_path = Path(state_file)

    try:
        state = load_terraform_state(state_path)
    except click.ClickException:
        raise

    resources_with_private = find_resources_with_private_state(state)

    if private_only:
        target_resources = resources_with_private
    else:
        # Get all resources
        target_resources = []
        for res in state.get("resources", []):
            for instance in res.get("instances", []):
                target_resources.append(
                    {
                        "type": res.get("type"),
                        "name": res.get("name"),
                        "provider": res.get("provider"),
                        "mode": res.get("mode"),
                        "private": instance.get("private"),
                        "attributes": instance.get("attributes", {}),
                    }
                )

    # Header
    console.print("[bold blue]🗂️  Terraform State Analysis[/bold blue]")
    console.print(f"[dim]State file: {state_path}[/dim]")
    console.print(f"[dim]Terraform version: {state.get('terraform_version', 'unknown')}[/dim]")
    console.print(f"[dim]Serial: {state.get('serial', 'unknown')}[/dim]\n")

    if resource:
        # Show specific resource
        resource_type, resource_name = resource.split(".", 1) if "." in resource else (resource, "")
        found_resource = None

        for res in target_resources:
            if res["type"] == resource_type and (not resource_name or res["name"] == resource_name):
                found_resource = res
                break

        if found_resource:
            display_resource_details(found_resource, show_encrypted)
        else:
            console.print(f"[red]Resource '{resource}' not found in state[/red]")
            return

    else:
        # Show overview
        if private_only:
            console.print(f"[bold]Found {len(resources_with_private)} resources with private state:[/bold]\n")
        else:
            console.print(
                f"[bold]Found {len(target_resources)} total resources ({len(resources_with_private)} with private state):[/bold]\n"
            )

        display_resource_overview(target_resources if not private_only else resources_with_private)

        if resources_with_private:
            console.print(
                "\n[dim]💡 Use [bold]--resource <type.name>[/bold] to see decrypted private state details[/dim]"
            )
            console.print(
                "[dim]💡 Use [bold]--private-only[/bold] to show only resources with private state[/dim]"
            )


@state_cli.command("decrypt")
@click.argument("encrypted_data", type=str)
@click.option(
    "--format",
    "-f",
    type=click.Choice(["json", "raw"]),
    default=DEFAULT_OUTPUT_FORMAT,
    help="Output format",
)
def decrypt_private_data(encrypted_data: str, format: str) -> None:
    """
    Decrypt a base64-encoded private state string.

    This is useful for debugging private state issues or examining private state
    data outside of the full state file context.

    Example:
        soup state decrypt "PaDuMfrlCnnhZsKb..."
    """
    decrypted = decrypt_private_state(encrypted_data)

    if decrypted:
        if format == "json":
            output = json.dumps(decrypted, indent=2, default=str)
            syntax = Syntax(output, "json", theme="monokai", line_numbers=True)
            console.print(syntax)
        else:
            console.print(decrypted)
    else:
        console.print("[red]❌ Failed to decrypt data[/red]")
        console.print("[dim]Ensure PYVIDER_PRIVATE_STATE_SHARED_SECRET is set correctly[/dim]")


@state_cli.command("validate")
@click.argument(
    "state_file",
    type=click.Path(exists=True, dir_okay=False),
    default=DEFAULT_TFSTATE_FILE,
)
def validate_private_state(state_file: str) -> None:
    """
    Validate that all private state in the state file can be decrypted.

    This command checks every resource with private state to ensure the
    private state data can be successfully decrypted with the current
    shared secret.
    """
    state_path = Path(state_file)
    state = load_terraform_state(state_path)
    resources_with_private = find_resources_with_private_state(state)

    if not resources_with_private:
        console.print("[green]✅ No resources with private state found[/green]")
        return

    console.print(f"[bold]Validating private state for {len(resources_with_private)} resources...[/bold]\n")

    valid_count = 0
    invalid_count = 0

    table = Table()
    table.add_column("Resource", style="cyan")
    table.add_column("Status", style="bold")
    table.add_column("Details", style="dim")

    for resource in resources_with_private:
        resource_name = f"{resource['type']}.{resource['name']}"

        decrypted = decrypt_private_state(resource["private"])
        if decrypted:
            valid_count += 1
            table.add_row(
                resource_name,
                "[green]✅ Valid[/green]",
                f"Decrypted {len(decrypted)} fields",
            )
        else:
            invalid_count += 1
            table.add_row(resource_name, "[red]❌ Invalid[/red]", "Failed to decrypt")

    console.print(table)
    console.print(f"\n[bold]Summary:[/bold] {valid_count} valid, {invalid_count} invalid")

    if invalid_count > 0:
        console.print("\n[red]❌ Some private state data could not be decrypted[/red]")
        console.print("[dim]Check that PYVIDER_PRIVATE_STATE_SHARED_SECRET is correct[/dim]")
        raise click.Abort()
    else:
        console.print("\n[green]✅ All private state data is valid[/green]")


if __name__ == "__main__":
    state_cli()


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 96: tofusoup/stir.py | checksum=aea5cf79580c... | modified=2025-09-17T17:32:12 | op=+ | size=160 | tokens=45 | type=x-python ###
<<< BOF <<<
#
# tofusoup/stir.py
#
# Legacy compatibility module - redirects to the new modular structure
#

from tofusoup.stir.cli import stir_cli

__all__ = ["stir_cli"]
>>> EOF >>>

### FILE 97: tofusoup/stir/__init__.py | checksum=40aa57a8c968... | modified=2025-09-17T17:32:12 | op=+ | size=96 | tokens=35 | type=x-python ###
<<< BOF <<<
#
# tofusoup/stir/__init__.py
#

from tofusoup.stir.cli import stir_cli

__all__ = ["stir_cli"]
>>> EOF >>>

### FILE 98: tofusoup/stir/cli.py | checksum=e2ba1d0ae48e... | modified=2025-09-17T17:32:12 | op=+ | size=5240 | tokens=1188 | type=x-python ###
<<< BOF <<<
#
# tofusoup/stir/cli.py
#

import asyncio
from pathlib import Path
import sys
from time import monotonic

import click

from tofusoup.stir.config import MAX_CONCURRENT_TESTS, STIR_PLUGIN_CACHE_DIR
from tofusoup.stir.display import console
from tofusoup.stir.executor import execute_tests, initialize_tests
from tofusoup.stir.models import TestResult
from tofusoup.stir.reporting import print_failure_report, print_summary_panel
from tofusoup.stir.runtime import StirRuntime


def process_results(results: list[TestResult | Exception]) -> tuple[list[TestResult], int, bool]:
    """Process test results and return failure analysis."""
    failed_tests = []
    skipped_count = 0
    all_passed = True

    for res in results:
        if isinstance(res, TestResult):
            if res.skipped:
                skipped_count += 1
            elif not res.success:
                all_passed = False
                failed_tests.append(res)
        elif res and not isinstance(res, asyncio.CancelledError):
            all_passed = False
            console.print(f"[bold red]CRITICAL ERROR in test runner:[/bold red] {res}")

    if failed_tests:
        console.print("\n[bold red]📊 Failure Analysis:[/bold red]")
        for failure in failed_tests:
            print_failure_report(failure)

    return failed_tests, skipped_count, all_passed


async def main(target_path: str, runtime: StirRuntime) -> None:
    """Main execution function for stir tests."""
    start_time = monotonic()
    base_dir = Path(target_path).resolve()

    test_dirs = []

    # Add regular test directories (non-hidden)
    test_dirs.extend([d for d in base_dir.iterdir() if d.is_dir() and not d.name.startswith(".")])

    # Handle .plating-tests specially - add its subdirectories as test directories
    plating_dir = base_dir / ".plating-tests"
    if plating_dir.is_dir():
        plating_test_dirs = [d for d in plating_dir.iterdir() if d.is_dir()]
        test_dirs.extend(plating_test_dirs)

    # Add base directory if it contains .tf files
    if any(base_dir.glob("*.tf")):
        test_dirs.append(base_dir)

    test_dirs = sorted(test_dirs)

    if not test_dirs:
        console.print(f"🤷 No directories found in '{base_dir}'.")
        return

    # Phase 1: Provider preparation (serial)
    await runtime.prepare_providers(test_dirs)

    # Phase 2: Test execution (parallel)
    initialize_tests(test_dirs)

    console.print("[bold]🚀 Tofusoup Stir[/bold]")
    console.print(
        f"Found {len(test_dirs)} test suites in '{base_dir}'. Running up to {MAX_CONCURRENT_TESTS} in parallel..."
    )

    results = await execute_tests(test_dirs, runtime)
    failed_tests, skipped_count, all_passed = process_results(results)

    duration = monotonic() - start_time
    print_summary_panel(len(test_dirs), len(failed_tests), skipped_count, duration)

    if not all_passed:
        sys.exit(1)


@click.command("stir")
@click.argument(
    "path",
    default=".",
    type=click.Path(exists=True, file_okay=False, resolve_path=True),
)
@click.option(
    "--matrix",
    is_flag=True,
    help="Run tests across multiple tool version combinations defined in soup.toml",
)
@click.option(
    "--matrix-output",
    type=click.Path(dir_okay=False),
    help="Save matrix test results to JSON file",
)
@click.option(
    "--json",
    "output_json",
    is_flag=True,
    help="Output results in JSON format",
)
@click.option(
    "--upgrade",
    is_flag=True,
    help="Force upgrade providers to latest versions",
)
@click.option(
    "--no-cache",
    is_flag=True,
    help="Disable plugin caching (downloads providers for each test)",
)
def stir_cli(
    path: str, matrix: bool, matrix_output: str, output_json: bool, upgrade: bool, no_cache: bool
) -> None:
    """
    Run multi-threaded Terraform tests against all subdirectories in a given PATH.

    When --matrix is used, runs tests across multiple Terraform/OpenTofu versions
    as configured in soup.toml's [workenv.matrix] section or wrkenv.toml's [matrix] section.
    """
    try:
        # Initialize runtime with configuration
        plugin_cache_dir = None if no_cache else STIR_PLUGIN_CACHE_DIR
        runtime = StirRuntime(plugin_cache_dir=plugin_cache_dir, force_upgrade=upgrade)

        if matrix:
            # Run matrix testing
            from tofusoup.testing.matrix import run_matrix_stir_tests

            results = asyncio.run(run_matrix_stir_tests(Path(path)))

            if matrix_output:
                import json

                with open(matrix_output, "w") as f:
                    json.dump(results, f, indent=2, default=str)
                console.print(f"✅ Matrix results saved to {matrix_output}")

            if output_json:
                import json

                console.print(json.dumps(results, indent=2, default=str))
        else:
            # Run standard single-version testing with runtime
            asyncio.run(main(path, runtime))

    except KeyboardInterrupt:
        console.print("\n[yellow]⚠️ Interrupted by user[/yellow]")
        sys.exit(130)
    except Exception as e:
        console.print(f"[bold red]💥 Fatal error:[/bold red] {e}")
        console.print_exception()
        sys.exit(1)
>>> EOF >>>

### FILE 99: tofusoup/stir/config.py | checksum=aebc0a4bc234... | modified=2025-09-17T17:32:12 | op=+ | size=1056 | tokens=326 | type=x-python ###
<<< BOF <<<
#
# tofusoup/stir/config.py
#

import os
from pathlib import Path
import shutil

from tofusoup.config.defaults import (
    ENV_PYVIDER_PRIVATE_STATE_SHARED_SECRET,
    ENV_TF_DATA_DIR,
    ENV_TF_LOG,
)

# Configuration constants
TF_COMMAND = shutil.which("tofu") or shutil.which("terraform") or "tofu"
MAX_CONCURRENT_TESTS = os.cpu_count() or 4
LOGS_DIR = Path("output/")

# Runtime configuration
DEFAULT_PLUGIN_CACHE_DIR = Path.home() / ".terraform.d" / "plugin-cache"
STIR_PLUGIN_CACHE_DIR = Path.home() / ".tofusoup" / "plugin-cache"
PROVIDER_PREPARATION_TIMEOUT = 300  # 5 minutes

# Environment variable names
ENV_VARS = {
    "TF_LOG": ENV_TF_LOG,
    "TF_DATA_DIR": ENV_TF_DATA_DIR,
    "PYVIDER_PRIVATE_STATE_SHARED_SECRET": ENV_PYVIDER_PRIVATE_STATE_SHARED_SECRET,
}

# Phase emojis for status display
PHASE_EMOJI = {
    "PENDING": "⏳",
    "CLEANING": "🧹",
    "INIT": "🔄",
    "APPLYING": "🚀",
    "ANALYZING": "🔬",
    "DESTROYING": "💥",
    "PASS": "✅",
    "FAIL": "❌",
    "ERROR": "🔥",
    "SKIPPED": "⏭️",
}
>>> EOF >>>

### FILE 100: tofusoup/stir/display.py | checksum=da3486a17860... | modified=2025-09-17T17:32:12 | op=+ | size=3296 | tokens=783 | type=x-python ###
<<< BOF <<<
#
# tofusoup/stir/display.py
#

import asyncio
from time import monotonic

from rich.console import Console
from rich.live import Live
from rich.table import Table

from tofusoup.stir.config import PHASE_EMOJI

# Shared state for the live display
test_statuses: dict[str, dict] = {}

# Rich Console Initialization
console = Console(record=True)


def generate_status_table() -> Table:
    """Generate a rich table showing current test status."""
    table = Table(box=None, expand=True, show_header=True)
    table.add_column("Status", justify="center", width=3)
    table.add_column("Phase", justify="center", width=3)
    table.add_column("Test Suite", justify="left", style="cyan", no_wrap=True, ratio=2)
    table.add_column("Elapsed", justify="right", style="magenta", width=10)
    table.add_column("Prov", justify="center", style="blue", width=5)
    table.add_column("Res", justify="center", style="blue", width=5)
    table.add_column("Data", justify="center", style="blue", width=5)
    table.add_column("Func", justify="center", style="blue", width=5)

    show_eph_func_col = any(status.get("ephemeral_functions", 0) > 0 for status in test_statuses.values())
    if show_eph_func_col:
        table.add_column("Eph. Func", justify="center", style="blue", width=9)

    table.add_column("Outs", justify="center", style="blue", width=5)
    table.add_column("Last Log", justify="left", style="yellow", ratio=5)

    for directory, status_info in sorted(test_statuses.items()):
        phase_text = status_info["text"]
        last_log = status_info.get("last_log", "")

        start_time = status_info.get("start_time")
        end_time = status_info.get("end_time")

        elapsed_str = ""
        if start_time:
            actual_end_time = end_time or monotonic()
            elapsed = actual_end_time - start_time
            elapsed_str = f"{elapsed:.1f}s"

        phase_emoji = PHASE_EMOJI.get(phase_text.split(" ")[-1], "❓")

        if status_info.get("active"):
            status_emoji = (
                "[yellow]🔄[/yellow]" if not status_info.get("has_warnings") else "[yellow]⚠️[/yellow]"
            )
        elif status_info.get("skipped"):
            status_emoji = "[dim]⏭️[/dim]"
        elif status_info.get("success"):
            status_emoji = "[green]✅[/green]"
        else:
            status_emoji = "[red]❌[/red]"

        row_data = [
            status_emoji,
            phase_emoji,
            f"[bold]{directory}[/bold]",
            elapsed_str,
            str(status_info.get("providers", "")),
            str(status_info.get("resources", "")),
            str(status_info.get("data_sources", "")),
            str(status_info.get("functions", "")),
        ]
        if show_eph_func_col:
            row_data.append(str(status_info.get("ephemeral_functions", "")))
        row_data.extend(
            [
                str(status_info.get("outputs", "")),
                last_log,
            ]
        )
        table.add_row(*row_data)

    return table


async def live_updater(live_display: Live, stop_event: asyncio.Event) -> None:
    """Update the live display with current test statuses."""
    while not stop_event.is_set():
        live_display.update(generate_status_table())
        await asyncio.sleep(0.1)
>>> EOF >>>

### FILE 101: tofusoup/stir/executor.py | checksum=b0c101d1255c... | modified=2025-09-17T17:32:12 | op=+ | size=8938 | tokens=1618 | type=x-python ###
<<< BOF <<<
#
# tofusoup/stir/executor.py
#

import asyncio
import json
from pathlib import Path
import shutil
from time import monotonic

from tofusoup.stir.config import LOGS_DIR, MAX_CONCURRENT_TESTS
from tofusoup.stir.display import console, test_statuses
from tofusoup.stir.models import TestResult
from tofusoup.stir.runtime import StirRuntime
from tofusoup.stir.terraform import run_terraform_command


async def run_test_lifecycle(
    directory: Path, semaphore: asyncio.Semaphore, runtime: StirRuntime
) -> TestResult:
    """Execute the full lifecycle of a Terraform test."""
    dir_name = directory.name
    start_time = monotonic()

    async with semaphore:
        try:
            if not any(directory.glob("*.tf")):
                test_statuses[dir_name].update(
                    text="SKIPPED",
                    style="dim",
                    active=False,
                    success=True,
                    skipped=True,
                    start_time=start_time,
                    end_time=monotonic(),
                )
                return TestResult(
                    directory=dir_name,
                    success=True,
                    skipped=True,
                    start_time=start_time,
                    end_time=monotonic(),
                )

            test_statuses[dir_name].update(
                text="CLEANING",
                style="dim yellow",
                active=True,
                last_log="",
                start_time=start_time,
            )
            for pattern in [".terraform*", "terraform.tfstate*", ".soup"]:
                for path in directory.glob(pattern):
                    if path.is_dir():
                        await asyncio.to_thread(shutil.rmtree, path, ignore_errors=True)
                    else:
                        await asyncio.to_thread(path.unlink, missing_ok=True)

            test_statuses[dir_name].update(text="INIT", style="yellow")

            # Use providers that were pre-downloaded by runtime
            runtime.validate_ready()

            init_rc, _, _, _, _, _ = await run_terraform_command(
                directory, ["init", "-no-color", "-input=false"], runtime=runtime
            )
            if init_rc != 0:
                end_time = monotonic()
                test_statuses[dir_name].update(
                    text="FAIL",
                    style="bold red",
                    active=False,
                    success=False,
                    end_time=end_time,
                )
                return TestResult(
                    directory=dir_name,
                    success=False,
                    skipped=False,
                    start_time=start_time,
                    end_time=end_time,
                )

            test_statuses[dir_name].update(text="APPLYING", style="blue")
            (
                apply_rc,
                _,
                stdout_log,
                stderr_log,
                tf_log,
                parsed_logs,
            ) = await run_terraform_command(
                directory, ["apply", "-input=false", "-auto-approve"], runtime=runtime, tail_log=True
            )

            if apply_rc == 0:
                test_statuses[dir_name].update(text="ANALYZING", style="magenta")
                show_rc, show_stdout, _, _, _, _ = await run_terraform_command(
                    directory, ["show", "-json"], runtime=runtime, capture_stdout=True
                )

                if show_rc == 0:
                    try:
                        state = json.loads(show_stdout)
                        test_statuses[dir_name]["providers"] = len(state.get("provider_configs", {}))
                        root_module = state.get("values", {}).get("root_module", {})
                        resources = [r for r in root_module.get("resources", []) if r.get("mode") == "managed"]
                        data_sources = [r for r in root_module.get("resources", []) if r.get("mode") == "data"]
                        test_statuses[dir_name]["resources"] = len(resources)
                        test_statuses[dir_name]["data_sources"] = len(data_sources)
                        test_statuses[dir_name]["outputs"] = len(state.get("values", {}).get("outputs", {}))
                    except json.JSONDecodeError:
                        pass

                test_statuses[dir_name].update(text="DESTROYING", style="dim green")
                await run_terraform_command(
                    directory,
                    ["destroy", "-auto-approve", "-input=false"],
                    runtime=runtime,
                    tail_log=True,
                )
                end_time = monotonic()
                test_statuses[dir_name].update(
                    text="PASS",
                    style="bold green",
                    active=False,
                    success=True,
                    end_time=end_time,
                )

                status = test_statuses[dir_name]
                return TestResult(
                    directory=dir_name,
                    success=True,
                    skipped=False,
                    start_time=start_time,
                    end_time=end_time,
                    stdout_log_path=stdout_log,
                    stderr_log_path=stderr_log,
                    tf_log_path=tf_log,
                    parsed_logs=parsed_logs,
                    outputs=status.get("outputs", 0),
                    has_warnings=status.get("has_warnings", False),
                    providers=status.get("providers", 0),
                    resources=status.get("resources", 0),
                    data_sources=status.get("data_sources", 0),
                    functions=status.get("functions", 0),
                    ephemeral_functions=status.get("ephemeral_functions", 0),
                )
            else:
                test_statuses[dir_name].update(text="DESTROYING", style="dim red")
                await run_terraform_command(
                    directory,
                    ["destroy", "-auto-approve", "-input=false"],
                    runtime=runtime,
                    tail_log=True,
                )
                end_time = monotonic()
                test_statuses[dir_name].update(
                    text="FAIL",
                    style="bold red",
                    active=False,
                    success=False,
                    end_time=end_time,
                )

                status = test_statuses[dir_name]
                return TestResult(
                    directory=dir_name,
                    success=False,
                    skipped=False,
                    start_time=start_time,
                    end_time=end_time,
                    stdout_log_path=stdout_log,
                    stderr_log_path=stderr_log,
                    tf_log_path=tf_log,
                    parsed_logs=parsed_logs,
                    outputs=status.get("outputs", 0),
                    has_warnings=status.get("has_warnings", False),
                    providers=status.get("providers", 0),
                    resources=status.get("resources", 0),
                    data_sources=status.get("data_sources", 0),
                    functions=status.get("functions", 0),
                    ephemeral_functions=status.get("ephemeral_functions", 0),
                )

        except Exception:
            console.print_exception()
            end_time = monotonic()
            test_statuses[dir_name].update(
                text="ERROR",
                style="bold red",
                active=False,
                success=False,
                end_time=end_time,
            )
            return TestResult(
                directory=dir_name,
                success=False,
                skipped=False,
                start_time=start_time,
                end_time=end_time,
            )


def initialize_tests(test_dirs: list[Path]) -> None:
    """Initialize test directories and status tracking."""
    LOGS_DIR.mkdir(exist_ok=True)
    for d in test_dirs:
        test_statuses[d.name] = {
            "text": "PENDING",
            "style": "dim",
            "active": False,
            "success": False,
            "skipped": False,
            "start_time": None,
            "end_time": None,
            "last_log": "",
            "outputs": 0,
            "has_warnings": False,
            "providers": 0,
            "resources": 0,
            "data_sources": 0,
            "functions": 0,
            "ephemeral_functions": 0,
        }


async def execute_tests(test_dirs: list[Path], runtime: StirRuntime) -> list[TestResult | Exception]:
    """Execute all tests concurrently."""
    semaphore = asyncio.Semaphore(MAX_CONCURRENT_TESTS)
    tasks = [run_test_lifecycle(d, semaphore, runtime) for d in test_dirs]
    return await asyncio.gather(*tasks, return_exceptions=True)
>>> EOF >>>

### FILE 102: tofusoup/stir/models.py | checksum=fd72103e67db... | modified=2025-09-17T17:32:12 | op=+ | size=618 | tokens=176 | type=x-python ###
<<< BOF <<<
#
# tofusoup/stir/models.py
#

from pathlib import Path
from typing import Any, NamedTuple


class TestResult(NamedTuple):
    """Represents the result of running a single test."""

    directory: str
    success: bool
    skipped: bool
    start_time: float
    end_time: float
    stdout_log_path: Path | None = None
    stderr_log_path: Path | None = None
    tf_log_path: Path | None = None
    parsed_logs: list[dict[str, Any]] = []
    outputs: int = 0
    has_warnings: bool = False
    providers: int = 0
    resources: int = 0
    data_sources: int = 0
    functions: int = 0
    ephemeral_functions: int = 0
>>> EOF >>>

### FILE 103: tofusoup/stir/reporting.py | checksum=10f495c82bae... | modified=2025-09-17T17:32:12 | op=+ | size=2552 | tokens=604 | type=x-python ###
<<< BOF <<<
#
# tofusoup/stir/reporting.py
#

import json

from rich.panel import Panel
from rich.syntax import Syntax
from rich.table import Table
from rich.text import Text

from tofusoup.stir.display import console
from tofusoup.stir.models import TestResult


def print_failure_report(result: TestResult) -> None:
    """Print a detailed failure report for a failed test."""
    title = f"🚨 Failure Report for {result.directory} "
    console.print(f"[bold red]{title.center(80, '─')}[/bold red]")

    error_logs = [log for log in result.parsed_logs if log.get("@level") in ("error", "critical")]

    if not error_logs:
        console.print(
            "[yellow]No specific error messages found in log. The failure may have been a crash.[/yellow]"
        )
    else:
        console.print(Text.from_markup(f"\n[bold]Error Log Events ({len(error_logs)} found):[/bold]"))
        for error_log in error_logs:
            console.print(
                Syntax(
                    json.dumps(error_log, indent=2),
                    "json",
                    theme="monokai",
                    line_numbers=False,
                    word_wrap=True,
                )
            )
            console.print("-" * 20)

    if result.tf_log_path:
        console.print(
            Text.from_markup(f"\n[bold]Full Terraform Log:[/bold] [yellow]{result.tf_log_path}[/yellow]")
        )

    console.print("\n" + "─" * 80 + "\n")


def print_summary_panel(total_tests: int, failed_tests: int, skipped_tests: int, duration: float) -> None:
    """Print a summary panel with test results."""
    passed_tests = total_tests - failed_tests - skipped_tests
    success = failed_tests == 0

    title = (
        "✅ [bold green]All Tests Passed[/bold green]"
        if success
        else "🔥 [bold red]Some Tests Failed[/bold red]"
    )
    border_style = "green" if success else "red"

    summary_table = Table.grid(padding=(0, 2))
    summary_table.add_column()
    summary_table.add_column(justify="right")
    summary_table.add_row("Total tests:", f"[bold]{total_tests}[/bold]")
    summary_table.add_row("Passed:", f"[green]{passed_tests}[/green]")
    summary_table.add_row("Failed:", f"[red]{failed_tests}[/red]")
    summary_table.add_row("Skipped:", f"[dim]{skipped_tests}[/dim]")
    summary_table.add_row("Duration:", f"{duration:.2f}s")

    console.print(
        Panel(
            summary_table,
            title=title,
            border_style=border_style,
            expand=False,
            padding=(1, 2),
        )
    )
>>> EOF >>>

### FILE 104: tofusoup/stir/runtime.py | checksum=7eb1435ba860... | modified=2025-10-10T12:05:05 | op=+ | size=11224 | tokens=2258 | type=x-python ###
<<< BOF <<<
#
# tofusoup/stir/runtime.py
#

from pathlib import Path
import re
import tempfile

from tofusoup.stir.display import console


class StirRuntime:
    """
    Runtime manager for Stir test execution.

    Handles provider management, environment setup, and ensures efficient
    parallel test execution by pre-warming providers before parallel execution.
    """

    def __init__(self, plugin_cache_dir: Path | None = None, force_upgrade: bool = False):
        """
        Initialize the Stir runtime.

        Args:
            plugin_cache_dir: Directory to use for plugin cache. If None, uses default.
            force_upgrade: Whether to force provider upgrades
        """
        self.force_upgrade = force_upgrade
        self.plugin_cache_dir = plugin_cache_dir or self._default_plugin_cache_dir()
        self.environment_vars: dict[str, str] = {}
        self._provider_cache_ready = False

    def _default_plugin_cache_dir(self) -> Path:
        """Get the default plugin cache directory."""
        return Path.home() / ".terraform.d" / "plugin-cache"

    async def prepare_providers(self, test_dirs: list[Path]) -> None:
        """
        Pre-download all required providers to avoid race conditions during parallel execution.

        Args:
            test_dirs: List of test directories to scan for provider requirements
        """
        console.print("[bold blue]🔧 Preparing providers...[/bold blue]")

        # Ensure plugin cache directory exists
        self.plugin_cache_dir.mkdir(parents=True, exist_ok=True)

        # Find all unique providers needed across all test directories
        required_providers = await self._scan_provider_requirements(test_dirs)

        if not required_providers:
            console.print("[yellow]⚠️  No provider requirements found in test directories[/yellow]")
            self._provider_cache_ready = True
            return

        # Deduplicate providers by source, preferring higher versions
        deduplicated_providers = self._deduplicate_providers(required_providers)

        # Create a temporary manifest to download all providers
        await self._download_providers(deduplicated_providers)

        self._provider_cache_ready = True
        console.print(
            f"[bold green]✅ Providers prepared[/bold green] ({len(required_providers)} unique providers)"
        )

    async def _scan_provider_requirements(self, test_dirs: list[Path]) -> set[tuple[str, str]]:
        """
        Scan all test directories to identify required providers.

        Returns:
            Set of (source, version_constraint) tuples
        """
        providers = set()

        for test_dir in test_dirs:
            tf_files = list(test_dir.glob("*.tf"))
            for tf_file in tf_files:
                try:
                    content = tf_file.read_text(encoding="utf-8")
                    dir_providers = self._extract_providers_from_content(content)
                    providers.update(dir_providers)
                except Exception as e:
                    console.log(f"[{test_dir.name}] Warning: Could not read {tf_file.name}: {e}")

        return providers

    def _extract_providers_from_content(self, content: str) -> set[tuple[str, str]]:
        """
        Extract provider requirements from Terraform configuration content.

        Args:
            content: Terraform configuration file content

        Returns:
            Set of (source, version_constraint) tuples
        """
        providers = set()

        # Match required_providers block content
        terraform_block_pattern = r"required_providers\s*\{([^}]*(?:\{[^}]*\}[^}]*)*)\}"
        terraform_matches = re.findall(terraform_block_pattern, content, re.DOTALL | re.MULTILINE)

        for match in terraform_matches:
            # Find provider name and extract everything between braces
            # Handle compact format like: pyvider = { source = "...", version = "..." }
            provider_pattern = r"(\w+)\s*=\s*\{\s*(.+?)\s*(?:\}|$)"
            provider_match = re.search(provider_pattern, match.strip(), re.DOTALL)

            if provider_match:
                provider_name = provider_match.group(1)
                provider_content = provider_match.group(2)

                # Extract source
                source_match = re.search(r'source\s*=\s*"([^"]+)"', provider_content)
                if source_match:
                    source = source_match.group(1)

                    # Skip local providers - they can't be downloaded from registries
                    if source.startswith("local/"):
                        continue

                    # Extract version (optional)
                    version_match = re.search(r'version\s*=\s*"([^"]+)"', provider_content)
                    version = version_match.group(1) if version_match else ">= 0.0.0"

                    providers.add((source, version))

        # Only look for legacy provider syntax if we didn't find any in required_providers
        # AND if we're scanning files that don't have terraform blocks with required_providers
        if not providers and "required_providers" not in content:
            legacy_pattern = r'provider\s+"([^"]+)"\s*\{'
            legacy_matches = re.findall(legacy_pattern, content)
            for provider_name in legacy_matches:
                # For legacy syntax, assume hashicorp namespace if no explicit source
                if "/" not in provider_name:
                    source = f"hashicorp/{provider_name}"
                else:
                    source = provider_name
                providers.add((source, ">= 0.0.0"))

        return providers

    def _deduplicate_providers(self, providers: set[tuple[str, str]]) -> set[tuple[str, str]]:
        """
        Deduplicate providers by source, keeping the one with the highest version.

        Args:
            providers: Set of (source, version_constraint) tuples

        Returns:
            Deduplicated set of providers
        """
        # Group by source
        by_source: dict[str, list[str]] = {}
        for source, version in providers:
            if source not in by_source:
                by_source[source] = []
            by_source[source].append(version)

        # For each source, pick the best version constraint
        result = set()
        for source, versions in by_source.items():
            # If we have ">= 0.0.0", prefer specific versions
            specific_versions = [v for v in versions if not v.startswith(">=")]
            if specific_versions:
                # Use the first specific version found (they should all be the same for real projects)
                version = specific_versions[0]
            else:
                # Use the first constraint found
                version = versions[0]
            result.add((source, version))

        return result

    async def _download_providers(self, providers: set[tuple[str, str]]) -> None:
        """
        Download all required providers using a temporary terraform configuration.

        Args:
            providers: Set of (source, version_constraint) tuples to download

        Note:
            Uses tempfile.TemporaryDirectory which automatically cleans up after use.
            This is safe for parallel execution as each invocation gets a unique directory.
        """
        if not providers:
            return

        # Create temporary directory for provider manifest (auto-cleaned on context exit)
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            manifest_file = temp_path / "providers.tf"

            # Generate a minimal terraform configuration that requires all providers
            terraform_config = self._generate_provider_manifest(providers)
            manifest_file.write_text(terraform_config)

            # Run terraform init to download providers
            from tofusoup.stir.terraform import run_terraform_command

            console.print(f"[blue]📥 Downloading {len(providers)} providers to cache...[/blue]")

            init_args = ["init", "-no-color", "-input=false"]
            if self.force_upgrade:
                init_args.append("-upgrade")

            init_rc, _, stdout_log, stderr_log, _, _ = await run_terraform_command(
                temp_path,
                init_args,
                runtime=None,  # Don't use runtime for provider preparation
                override_cache_dir=self.plugin_cache_dir,
            )

            if init_rc != 0:
                # Read logs to see what went wrong
                stdout_content = stdout_log.read_text() if stdout_log.exists() else "No stdout"
                stderr_content = stderr_log.read_text() if stderr_log.exists() else "No stderr"
                console.print(f"[red]Terraform init failed with code {init_rc}[/red]")
                console.print(f"[red]STDOUT:[/red] {stdout_content}")
                console.print(f"[red]STDERR:[/red] {stderr_content}")
                raise RuntimeError("Failed to download providers to cache")

    def _generate_provider_manifest(self, providers: set[tuple[str, str]]) -> str:
        """
        Generate a Terraform configuration that requires all specified providers.

        Args:
            providers: Set of (source, version_constraint) tuples

        Returns:
            Terraform configuration string
        """
        lines = ["terraform {", "  required_providers {"]

        for i, (source, version) in enumerate(sorted(providers)):
            # Extract provider name from source (e.g., "hashicorp/aws" -> "aws")
            provider_name = source.split("/")[-1]
            # Ensure unique names in case of conflicts - use dashes instead of underscores
            provider_key = f"{provider_name}-{i}" if i > 0 else provider_name

            lines.append(f"    {provider_key} = {{")
            lines.append(f'      source  = "{source}"')
            lines.append(f'      version = "{version}"')
            lines.append("    }")

        lines.extend(["  }", "}"])

        return "\n".join(lines)

    def get_terraform_env(self, base_env: dict[str, str]) -> dict[str, str]:
        """
        Get the normalized Terraform environment for test execution.

        Args:
            base_env: Base environment to extend

        Returns:
            Environment variables dict for terraform execution
        """
        env = base_env.copy()

        # Always set plugin cache if directory exists
        if self.plugin_cache_dir.exists():
            env["TF_PLUGIN_CACHE_DIR"] = str(self.plugin_cache_dir)
            # Enable potentially faster caching at the expense of lock file completeness
            env["TF_PLUGIN_CACHE_MAY_BREAK_DEPENDENCY_LOCK_FILE"] = "1"

        return env

    @property
    def providers_ready(self) -> bool:
        """Check if providers have been prepared."""
        return self._provider_cache_ready

    def validate_ready(self) -> None:
        """Validate that the runtime is ready for test execution."""
        if not self._provider_cache_ready:
            raise RuntimeError("Runtime not ready: call prepare_providers() first")


__all__ = ["StirRuntime"]
>>> EOF >>>

### FILE 105: tofusoup/stir/terraform.py | checksum=96caf5292a5e... | modified=2025-09-17T17:32:12 | op=+ | size=5430 | tokens=1277 | type=x-python ###
<<< BOF <<<
#
# tofusoup/stir/terraform.py
#

import asyncio
import contextlib
from datetime import UTC, datetime
import json
import os
from pathlib import Path
import re
from typing import Any

from tofusoup.stir.config import ENV_VARS, LOGS_DIR, TF_COMMAND
from tofusoup.stir.display import console, test_statuses
from tofusoup.stir.runtime import StirRuntime


async def _tail_tf_log(log_path: Path, process: asyncio.subprocess.Process, dir_name: str) -> None:
    """Asynchronously tails the Terraform JSON log file to update the UI in real-time."""
    try:
        await _wait_for_log_file(log_path, process)
        await _process_log_file(log_path, process, dir_name)
    except Exception as e:
        console.log(f"[{dir_name}] Error tailing log: {e}")


async def _wait_for_log_file(log_path: Path, process: asyncio.subprocess.Process) -> None:
    """Wait for log file to be created."""
    while not await asyncio.to_thread(log_path.exists):
        if process.returncode is not None:
            return
        await asyncio.sleep(0.1)


async def _process_log_file(log_path: Path, process: asyncio.subprocess.Process, dir_name: str) -> None:
    """Process log file entries and update test status."""
    with open(log_path, encoding="utf-8") as f:
        while process.returncode is None:
            line = f.readline()
            if line:
                _process_log_line(line, dir_name)
            else:
                await asyncio.sleep(0.1)


def _process_log_line(line: str, dir_name: str) -> None:
    """Process a single log line and update status."""
    try:
        log_entry = json.loads(line)
        level = log_entry.get("@level", "info")
        message = log_entry.get("@message", "")

        if level in ("info", "warn", "error") and message:
            test_statuses[dir_name]["last_log"] = message

        if level == "warn":
            test_statuses[dir_name]["has_warnings"] = True

        _update_function_counts(message, dir_name)
    except json.JSONDecodeError:
        pass


def _update_function_counts(message: str, dir_name: str) -> None:
    """Update function call counts from log message."""
    if "CallFunction" in message and "GRPCProvider" in message:
        if "ephemeral" in message:
            test_statuses[dir_name]["ephemeral_functions"] += 1
        else:
            test_statuses[dir_name]["functions"] += 1


async def run_terraform_command(
    directory: Path,
    args: list[str],
    runtime: StirRuntime | None = None,
    tail_log: bool = False,
    capture_stdout: bool = False,
    override_cache_dir: Path | None = None,
) -> tuple[int, str, Path, Path, Path, list[dict[str, Any]]]:
    """
    A dedicated runner for Terraform commands that sets up the correct environment,
    captures logs, and can tail the JSON log for live UI updates.
    """
    dir_name = directory.name
    timestamp = datetime.now(UTC).strftime("%Y%m%d-%H%M%S")

    soup_dir = directory / ".soup"
    tf_data_dir = soup_dir / "tfdata"
    logs_dir = soup_dir / "logs"
    logs_dir.mkdir(parents=True, exist_ok=True)
    tf_data_dir.mkdir(parents=True, exist_ok=True)

    tf_log_path = logs_dir / "terraform.log"

    sanitized_dir_name = re.sub(r"[\\/.:]", "_", dir_name)
    cmd_basename = Path(TF_COMMAND).name
    stdout_log_path = LOGS_DIR / f"{sanitized_dir_name}.{cmd_basename}.{args[0]}.stdout.{timestamp}.log"
    stderr_log_path = LOGS_DIR / f"{sanitized_dir_name}.{cmd_basename}.{args[0]}.stderr.{timestamp}.log"

    env = os.environ.copy()
    env[ENV_VARS["TF_DATA_DIR"]] = str(tf_data_dir)
    env[ENV_VARS["TF_LOG"]] = "JSON"
    env["TF_LOG_PATH"] = str(tf_log_path)
    env[ENV_VARS["PYVIDER_PRIVATE_STATE_SHARED_SECRET"]] = "stir-test-secret"

    # Handle provider preparation phase (runtime=None with override_cache_dir)
    if runtime is None and override_cache_dir:
        # Special case: provider preparation phase
        if override_cache_dir.exists():
            env["TF_PLUGIN_CACHE_DIR"] = str(override_cache_dir)
            env["TF_PLUGIN_CACHE_MAY_BREAK_DEPENDENCY_LOCK_FILE"] = "1"
    elif runtime:
        # Normal execution: use runtime-managed environment
        env = runtime.get_terraform_env(env)
    else:
        # Neither runtime nor override provided
        raise RuntimeError(
            "Either StirRuntime or override_cache_dir must be provided for terraform command execution"
        )

    command = [TF_COMMAND, *args]

    process = await asyncio.create_subprocess_exec(
        *command,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE,
        cwd=directory,
        env=env,
    )

    tail_task = None
    if tail_log:
        tail_task = asyncio.create_task(_tail_tf_log(tf_log_path, process, dir_name))

    stdout_data, stderr_data = await process.communicate()

    if tail_task:
        await tail_task

    stdout_log_path.write_bytes(stdout_data)
    stderr_log_path.write_bytes(stderr_data)

    parsed_logs = []
    if tf_log_path.exists():
        with open(tf_log_path) as f:
            for line in f:
                with contextlib.suppress(json.JSONDecodeError):
                    parsed_logs.append(json.loads(line))

    final_stdout = stdout_data.decode("utf-8", errors="ignore") if capture_stdout else ""
    return (
        process.returncode,
        final_stdout,
        stdout_log_path,
        stderr_log_path,
        tf_log_path,
        parsed_logs,
    )
>>> EOF >>>

### FILE 106: tofusoup/testing/__init__.py | checksum=2b63828ca3e9... | modified=2025-09-17T17:32:12 | op=+ | size=55 | tokens=27 | type=x-python ###
<<< BOF <<<
#
# tofusoup/testing/__init__.py
#

# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 107: tofusoup/testing/cli.py | checksum=0c3071335276... | modified=2025-09-17T17:32:12 | op=+ | size=2652 | tokens=632 | type=x-python ###
<<< BOF <<<
#!/usr/bin/env python3
#
# tofusoup/testing/cli.py
#
import asyncio
import sys

import click
from provide.foundation import logger

from tofusoup.common.exceptions import TofuSoupError

from .logic import (
    TEST_SUITE_CONFIG,
    run_all_test_suites,
    run_test_suite,
)


def _print_results_report(results: list) -> None:
    """Prints a summary table and detailed failure report."""
    pass


@click.group("test")
@click.pass_context
def test_cli(ctx) -> None:
    """A unified command to execute various conformance test suites."""
    if not ctx.obj:
        ctx.obj = {}


@test_cli.command("all")
@click.pass_context
def test_all_command(ctx) -> None:
    """Runs all available conformance test suites (CTY, RPC, Wire, etc.)."""
    verbose = ctx.obj.get("VERBOSE", False)
    project_root = ctx.obj.get("PROJECT_ROOT")
    if not project_root:
        logger.error("Could not determine project root from context.")
        sys.exit(1)

    try:
        loaded_config = ctx.obj.get("TOFUSOUP_CONFIG", {})
        asyncio.run(run_all_test_suites(project_root, loaded_config, verbose))

    except TofuSoupError as e:
        logger.error(f"Error running all test suites: {e}", exc_info=verbose)
        sys.exit(1)
    except Exception as e:
        logger.error(f"Unexpected error running all test suites: {e}", exc_info=verbose)
        sys.exit(1)


# Dynamically create subcommands for each test suite
for suite_name_key in TEST_SUITE_CONFIG:
    suite_config_data = TEST_SUITE_CONFIG[suite_name_key]

    @test_cli.command(
        name=suite_name_key,
        help=f"Runs the {suite_config_data['description']}. Pass additional options after -- for pytest.",
        context_settings=dict(ignore_unknown_options=True),
    )
    @click.argument("pytest_options", nargs=-1, type=click.UNPROCESSED)
    @click.pass_context
    def _suite_command(ctx, pytest_options: tuple[str, ...], snk=suite_name_key) -> None:
        verbose = ctx.obj.get("VERBOSE", False)
        project_root = ctx.obj.get("PROJECT_ROOT")
        if not project_root:
            logger.error("Could not determine project root from context.")
            sys.exit(1)

        try:
            loaded_config = ctx.obj.get("TOFUSOUP_CONFIG", {})
            asyncio.run(run_test_suite(snk, project_root, loaded_config, verbose, list(pytest_options)))
        except TofuSoupError as e:
            logger.error(f"Error running test suite '{snk}': {e}", exc_info=verbose)
            sys.exit(1)
        except Exception as e:
            logger.error(f"Unexpected error in test suite '{snk}': {e}", exc_info=verbose)
            sys.exit(1)


# 🍲🥄🖥️🪄
>>> EOF >>>

### FILE 108: tofusoup/testing/logic.py | checksum=dceccf3b6d96... | modified=2025-10-10T12:04:44 | op=+ | size=5760 | tokens=1349 | type=x-python ###
<<< BOF <<<
#
# tofusoup/testing/logic.py
#
import asyncio
import json
import os
import pathlib
import sys
from typing import Any

import attrs
from provide.foundation import logger
from provide.foundation.errors import ResourceError, ValidationError, error_boundary

from tofusoup.common.exceptions import TofuSoupError
from tofusoup.harness.logic import ensure_go_harness_build


@attrs.define(frozen=True)
class TestSuiteResult:
    suite_name: str
    success: bool
    duration: float
    passed: int
    failed: int
    skipped: int
    errors: int
    failures: list[dict[str, Any]] = attrs.field(factory=list)


TEST_SUITE_CONFIG = {
    "cty": {
        "path": "conformance/cty",
        "description": "CTY compatibility tests",
        "required_harnesses": ["soup-go"],
    },
    "wire": {
        "path": "conformance/wire",
        "description": "Terraform Wire Protocol tests",
        "required_harnesses": ["soup-go"],
    },
    "rpc": {
        "path": "conformance/rpc",
        "description": "RPC compatibility tests",
        "required_harnesses": ["soup-go"],
    },
    "hcl": {
        "path": "conformance/hcl",
        "description": "HCL compatibility tests",
        "required_harnesses": ["soup-go"],
    },
}


async def _run_pytest_suite(
    suite_name: str,
    project_root: pathlib.Path,
    suite_path_relative: str,
    pytest_args: list[str],
    env_vars: dict,
) -> TestSuiteResult:
    pytest_target_path = project_root / suite_path_relative
    if not pytest_target_path.exists():
        raise TofuSoupError(f"Test suite path not found: {pytest_target_path}")

    # Use project-specific temp directory for test reports
    reports_dir = project_root / "soup" / "output" / "test-reports"
    reports_dir.mkdir(parents=True, exist_ok=True)

    # Create unique report file name to support parallel test execution
    report_path = reports_dir / f"{suite_name}-report-{os.getpid()}.json"

    # Corrected invocation: Use `-o` to override configuration for this specific run.
    # This is the correct way to tell this pytest session to only find `souptest_` files.
    command = [
        sys.executable,
        "-m",
        "pytest",
        f"--json-report-file={report_path}",
        "-o",
        "python_files=souptest_*.py",
        *pytest_args,
        str(pytest_target_path),
    ]

    current_env = os.environ.copy()
    current_env.update({k: str(v) for k, v in env_vars.items()})

    logger.debug(f"Running pytest with command: {' '.join(command)}", env=current_env)

    process = await asyncio.create_subprocess_exec(
        *command, cwd=str(project_root), stdout=None, stderr=None, env=current_env
    )
    await process.wait()

    @error_boundary(
        fallback_result=lambda: TestSuiteResult(
            suite_name=suite_name,
            success=False,
            duration=0,
            passed=0,
            failed=1,
            skipped=0,
            errors=1,
            failures=[{"nodeid": "runner_error", "longrepr": "Test report processing failed"}],
        )
    )
    def _process_test_report() -> TestSuiteResult:
        try:
            with open(report_path) as f:
                report_content = f.read()
                if not report_content:
                    raise ValidationError("Empty test report file")
                report = json.loads(report_content)
        except FileNotFoundError as e:
            raise ResourceError(f"Test report file not found: {report_path}") from e
        except json.JSONDecodeError as e:
            raise ValidationError(f"Invalid JSON in test report: {e}") from e

        summary = report.get("summary", {})
        failures = [test for test in report.get("tests", []) if test.get("outcome") in ("failed", "error")]
        return TestSuiteResult(
            suite_name=suite_name,
            success=(report.get("exitcode", 1) == 0),
            duration=report.get("duration", 0.0),
            passed=summary.get("passed", 0),
            failed=summary.get("failed", 0),
            skipped=summary.get("skipped", 0),
            errors=len(report.get("errors", [])),
            failures=failures,
        )

    try:
        return _process_test_report()
    finally:
        # Keep report files for debugging - they're in a well-organized location
        # and will be cleaned up by project cleanup scripts if needed
        logger.debug(f"Test report saved to {report_path}")


async def run_test_suite(
    suite_name: str,
    project_root: pathlib.Path,
    loaded_config: dict,
    verbose: bool,
    pytest_options: list[str] | None = None,
) -> TestSuiteResult:
    if suite_name not in TEST_SUITE_CONFIG:
        raise TofuSoupError(f"Test suite '{suite_name}' is not defined.")

    suite_cfg = TEST_SUITE_CONFIG[suite_name]
    for harness_key in suite_cfg.get("required_harnesses", []):
        if harness_key.startswith("go-") or harness_key == "soup-go":
            ensure_go_harness_build(harness_key, project_root, loaded_config)

    suite_defaults = loaded_config.get("test_suite_defaults", {})
    suite_specific = loaded_config.get("test_suite", {}).get(suite_name, {})

    env_vars = {
        **suite_defaults.get("env_vars", {}),
        **suite_specific.get("env_vars", {}),
    }

    pytest_args = ["-v"] if verbose else []
    if pytest_options:
        pytest_args.extend(pytest_options)

    return await _run_pytest_suite(suite_name, project_root, suite_cfg["path"], pytest_args, env_vars)


async def run_all_test_suites(
    project_root: pathlib.Path, loaded_config: dict, verbose: bool
) -> list[TestSuiteResult]:
    tasks = [run_test_suite(name, project_root, loaded_config, verbose, None) for name in TEST_SUITE_CONFIG]
    return await asyncio.gather(*tasks)


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 109: tofusoup/testing/matrix.py | checksum=d606823801b2... | modified=2025-09-17T17:32:12 | op=+ | size=13111 | tokens=2595 | type=x-python ###
<<< BOF <<<
#
# tofusoup/testing/matrix.py
#
"""
Matrix testing functionality for TofuSoup.

Provides version matrix testing for the 'soup stir' command to validate
providers against multiple versions of Terraform/OpenTofu.
"""

import asyncio
from collections.abc import Callable
from dataclasses import dataclass, field
import itertools
import json
import os
import pathlib
from typing import Any

from rich.console import Console
from rich.progress import BarColumn, Progress, SpinnerColumn, TextColumn, TimeElapsedColumn
from rich.table import Table
from wrkenv import WorkenvConfig, get_tool_manager

from tofusoup.config.defaults import MATRIX_PARALLEL_JOBS, MATRIX_TIMEOUT_MINUTES

from ..workenv_integration import create_workenv_config_with_soup

console = Console()


@dataclass
class MatrixCombination:
    """Represents a specific combination of tool versions."""

    tools: dict[str, str] = field(default_factory=dict)

    def __str__(self) -> str:
        """String representation for display."""
        tool_strs = [f"{tool}:{version}" for tool, version in self.tools.items()]
        return f"[{', '.join(tool_strs)}]"

    def to_dict(self) -> dict:
        """Convert to dictionary for serialization."""
        return {"tools": self.tools}

    @classmethod
    def from_dict(cls, data: dict) -> "MatrixCombination":
        """Create from dictionary."""
        return cls(tools=data.get("tools", {}))


@dataclass
class MatrixResult:
    """Result from testing a matrix combination."""

    combination: MatrixCombination
    success: bool
    duration_seconds: float = 0.0
    error_message: str | None = None
    test_results: dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> dict:
        """Convert to dictionary for serialization."""
        return {
            "combination": self.combination.to_dict(),
            "success": self.success,
            "duration_seconds": self.duration_seconds,
            "error_message": self.error_message,
            "test_results": self.test_results,
        }


class VersionMatrix:
    """Manages version matrix testing for TofuSoup."""

    def __init__(self, base_tools: dict[str, str], config: WorkenvConfig | None = None) -> None:
        """
        Initialize the version matrix.

        Args:
            base_tools: Base tool versions (e.g., {"terraform": "1.5.7", "tofu": "1.6.2"})
            config: Optional WorkenvConfig. If not provided, creates one with soup compatibility.
        """
        self.config = config or create_workenv_config_with_soup()
        self.base_tools = base_tools

        # Get matrix configuration (from soup.toml or wrkenv.toml)
        self.matrix_config = self.config.get_setting("matrix", {})
        self.parallel_jobs = self.matrix_config.get("parallel_jobs", MATRIX_PARALLEL_JOBS)
        self.timeout_minutes = self.matrix_config.get("timeout_minutes", MATRIX_TIMEOUT_MINUTES)

    def generate_combinations(self) -> list[MatrixCombination]:
        """
        Generate all combinations for matrix testing.

        Returns:
            List of MatrixCombination objects to test
        """
        # Get version lists from matrix config
        matrix_versions = self.matrix_config.get("versions", {})

        # Build tool version lists
        tool_versions = {}
        for tool_name, base_version in self.base_tools.items():
            # Get additional versions to test for this tool
            extra_versions = matrix_versions.get(tool_name, [])

            # Combine base version with matrix versions
            all_versions = [base_version]
            if extra_versions:
                # Add matrix versions, avoiding duplicates
                for v in extra_versions:
                    if v not in all_versions:
                        all_versions.append(v)

            tool_versions[tool_name] = all_versions

        # Generate all combinations
        combinations = []

        if not tool_versions:
            return combinations

        tool_names = list(tool_versions.keys())
        version_lists = [tool_versions[tool] for tool in tool_names]

        for version_combo in itertools.product(*version_lists):
            combo_dict = dict(zip(tool_names, version_combo, strict=False))
            combinations.append(MatrixCombination(tools=combo_dict))

        return combinations

    async def run_stir_tests(
        self, stir_directory: pathlib.Path, test_filter: Callable[[MatrixCombination], bool] | None = None
    ) -> dict[str, Any]:
        """
        Run 'soup stir' tests across all matrix combinations.

        Args:
            stir_directory: Directory containing stir test cases
            test_filter: Optional function to filter which combinations to test

        Returns:
            Dictionary containing test results and statistics
        """
        combinations = self.generate_combinations()

        if test_filter:
            combinations = [c for c in combinations if test_filter(c)]

        if not combinations:
            return {
                "success_count": 0,
                "failure_count": 0,
                "results": [],
                "message": "No combinations to test",
            }

        console.print(f"\n[bold cyan]Running {len(combinations)} matrix combinations...[/bold cyan]")

        results = []
        semaphore = asyncio.Semaphore(self.parallel_jobs)

        async def test_combination(combo: MatrixCombination) -> MatrixResult:
            async with semaphore:
                return await self._test_single_combination(combo, stir_directory)

        # Run all combinations with progress tracking
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TimeElapsedColumn(),
            console=console,
        ) as progress:
            task = progress.add_task("Testing combinations...", total=len(combinations))

            tasks = [test_combination(combo) for combo in combinations]

            for coro in asyncio.as_completed(tasks):
                result = await coro
                results.append(result)
                progress.advance(task)

                # Update progress description with latest result
                status = "✅" if result.success else "❌"
                progress.update(
                    task,
                    description=f"Testing combinations... {status} {result.combination}",
                )

        # Show results summary
        self._display_results_table(results)

        # Aggregate results
        success_count = sum(1 for r in results if r.success)
        failure_count = len(results) - success_count

        return {
            "success_count": success_count,
            "failure_count": failure_count,
            "results": [r.to_dict() for r in results],
            "total_combinations": len(combinations),
            "parallel_jobs": self.parallel_jobs,
        }

    async def _test_single_combination(
        self, combination: MatrixCombination, stir_directory: pathlib.Path
    ) -> MatrixResult:
        """Test a single tool version combination."""
        import time

        start_time = time.time()

        try:
            # Install all tools in this combination
            await self._install_combination_tools(combination)

            # Run soup stir with this combination
            result = await self._run_stir_test(combination, stir_directory)

            duration = time.time() - start_time

            return MatrixResult(
                combination=combination,
                success=result["success"],
                duration_seconds=duration,
                test_results=result,
            )

        except Exception as e:
            duration = time.time() - start_time

            return MatrixResult(
                combination=combination,
                success=False,
                duration_seconds=duration,
                error_message=str(e),
            )

    async def _install_combination_tools(self, combination: MatrixCombination) -> None:
        """Install all tools for a specific combination."""
        for tool_name, version in combination.tools.items():
            manager = get_tool_manager(tool_name, self.config)
            if not manager:
                raise Exception(f"No manager available for tool: {tool_name}")

            # Check if already installed
            current_version = manager.get_installed_version()
            if current_version == version:
                binary_path = manager.get_current_binary_path()
                if binary_path and binary_path.exists():
                    continue  # Already installed

            # Install the specific version
            console.print(f"Installing {tool_name} {version} for matrix testing...")
            await asyncio.get_event_loop().run_in_executor(
                None,
                manager.install_version,
                version,
                False,  # not dry_run
            )

    async def _run_stir_test(
        self, combination: MatrixCombination, stir_directory: pathlib.Path
    ) -> dict[str, Any]:
        """Run soup stir test for a specific combination."""
        import json

        # Build the soup stir command
        cmd = [
            "soup",
            "stir",
            str(stir_directory),
            "--json",  # Get JSON output for parsing
        ]

        # Set up environment with the tool versions
        env = dict(os.environ)
        for tool_name, version in combination.tools.items():
            # Ensure the right version is active
            manager = get_tool_manager(tool_name, self.config)
            if manager:
                binary_path = manager.get_binary_path(version)
                if binary_path.exists():
                    # Add to PATH
                    env["PATH"] = f"{binary_path.parent}:{env.get('PATH', '')}"

        # Run the stir command
        process = await asyncio.create_subprocess_exec(
            *cmd,
            env=env,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )

        stdout, stderr = await asyncio.wait_for(process.communicate(), timeout=self.timeout_minutes * 60)

        if process.returncode == 0:
            # Parse JSON output if available
            try:
                result = json.loads(stdout.decode())
                result["success"] = True
            except:
                result = {
                    "success": True,
                    "stdout": stdout.decode(),
                    "stderr": stderr.decode(),
                }
        else:
            result = {
                "success": False,
                "stdout": stdout.decode(),
                "stderr": stderr.decode(),
                "returncode": process.returncode,
            }

        return result

    def _display_results_table(self, results: list[MatrixResult]) -> None:
        """Display results in a nice table."""
        table = Table(title="Matrix Test Results")

        # Add columns
        table.add_column("Combination", style="cyan")
        table.add_column("Status", style="bold")
        table.add_column("Duration", style="yellow")
        table.add_column("Error", style="red")

        # Add rows
        for result in results:
            status = "✅ Pass" if result.success else "❌ Fail"
            duration = f"{result.duration_seconds:.1f}s"
            error = result.error_message or ""

            table.add_row(
                str(result.combination),
                status,
                duration,
                error,
            )

        console.print(table)

    def save_results(self, results: dict[str, Any], output_path: pathlib.Path) -> None:
        """Save matrix test results to a file."""
        with open(output_path, "w") as f:
            json.dump(results, f, indent=2)

        console.print(f"[green]Matrix test results saved to: {output_path}[/green]")


# Convenience function for soup stir integration
async def run_matrix_stir_tests(
    stir_directory: pathlib.Path, tools: dict[str, str] | None = None, config: WorkenvConfig | None = None
) -> dict[str, Any]:
    """
    Run matrix testing for soup stir.

    This is the main entry point for the soup stir matrix testing feature.

    Args:
        stir_directory: Directory containing stir test cases
        tools: Optional base tools. If not provided, uses current config.
        config: Optional WorkenvConfig

    Returns:
        Test results dictionary
    """
    if config is None:
        config = create_workenv_config_with_soup()

    if tools is None:
        # Get tools from current configuration
        tools = config.get_all_tools()
        # Filter to just terraform/tofu
        tools = {k: v for k, v in tools.items() if k in ["terraform", "tofu"]}

    matrix = VersionMatrix(tools, config)
    return await matrix.run_stir_tests(stir_directory)


# 🍲🧪🔢🪄
>>> EOF >>>

### FILE 110: tofusoup/testing/matrix_profiles.py | checksum=3284ffd746ab... | modified=2025-09-17T17:32:12 | op=+ | size=11804 | tokens=2320 | type=x-python ###
<<< BOF <<<
"""
Profile-based matrix testing for TofuSoup.

Instead of generating combinations, uses pre-defined profiles from soup.toml
to test against specific tool configurations.
"""

import asyncio
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any

from rich.console import Console
from rich.progress import BarColumn, Progress, SpinnerColumn, TextColumn, TimeElapsedColumn
from rich.table import Table
from wrkenv import WorkenvConfig, get_tool_manager

from tofusoup.config.defaults import MATRIX_PARALLEL_JOBS, MATRIX_TIMEOUT_MINUTES

from ..workenv_integration import create_workenv_config_with_soup

console = Console()


@dataclass
class ProfileTestResult:
    """Result from testing a specific profile."""

    profile_name: str
    success: bool
    duration_seconds: float = 0.0
    error_message: str | None = None
    test_results: dict[str, Any] = field(default_factory=dict)
    tools: dict[str, str] = field(default_factory=dict)

    def to_dict(self) -> dict:
        """Convert to dictionary for serialization."""
        return {
            "profile": self.profile_name,
            "success": self.success,
            "duration_seconds": self.duration_seconds,
            "error_message": self.error_message,
            "test_results": self.test_results,
            "tools": self.tools,
        }


class ProfileMatrix:
    """Manages profile-based matrix testing for TofuSoup."""

    def __init__(self, config: WorkenvConfig | None = None) -> None:
        """
        Initialize the profile matrix.

        Args:
            config: Optional WorkenvConfig. If not provided, creates one with soup compatibility.
        """
        self.config = config or create_workenv_config_with_soup()

        # Get matrix configuration
        self.matrix_config = self.config.get_setting("matrix", {})
        self.matrix_profiles = self.matrix_config.get("profiles", [])
        self.parallel_jobs = self.matrix_config.get("parallel_jobs", MATRIX_PARALLEL_JOBS)
        self.timeout_minutes = self.matrix_config.get("timeout_minutes", MATRIX_TIMEOUT_MINUTES)

    def get_test_profiles(self) -> list[str]:
        """
        Get list of profiles to test.

        Returns:
            List of profile names from matrix config
        """
        if self.matrix_profiles:
            return self.matrix_profiles

        # If no explicit matrix profiles, test all available profiles
        all_profiles = self.config.get_all_profiles()
        return list(all_profiles.keys())

    async def run_profile_tests(
        self, stir_directory: Path, profiles: list[str] | None = None
    ) -> dict[str, Any]:
        """
        Run 'soup stir' tests for each profile.

        Args:
            stir_directory: Directory containing stir test cases
            profiles: Optional list of specific profiles to test

        Returns:
            Dictionary containing test results and statistics
        """
        test_profiles = profiles or self.get_test_profiles()

        if not test_profiles:
            return {
                "success_count": 0,
                "failure_count": 0,
                "results": [],
                "message": "No profiles to test",
            }

        console.print(f"\n[bold cyan]Running tests for {len(test_profiles)} profiles...[/bold cyan]")

        results = []
        semaphore = asyncio.Semaphore(self.parallel_jobs)

        async def test_profile(profile_name: str) -> ProfileTestResult:
            async with semaphore:
                return await self._test_single_profile(profile_name, stir_directory)

        # Run all profiles with progress tracking
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TimeElapsedColumn(),
            console=console,
        ) as progress:
            task = progress.add_task("Testing profiles...", total=len(test_profiles))

            tasks = [test_profile(profile) for profile in test_profiles]

            for coro in asyncio.as_completed(tasks):
                result = await coro
                results.append(result)
                progress.advance(task)

                # Update progress description with latest result
                status = "✅" if result.success else "❌"
                progress.update(
                    task,
                    description=f"Testing profiles... {status} {result.profile_name}",
                )

        # Show results summary
        self._display_results_table(results)

        # Aggregate results
        success_count = sum(1 for r in results if r.success)
        failure_count = len(results) - success_count

        return {
            "success_count": success_count,
            "failure_count": failure_count,
            "results": [r.to_dict() for r in results],
            "total_profiles": len(test_profiles),
            "parallel_jobs": self.parallel_jobs,
        }

    async def _test_single_profile(self, profile_name: str, stir_directory: Path) -> ProfileTestResult:
        """Test a single profile configuration."""
        import os
        import time

        start_time = time.time()

        try:
            # Get profile configuration
            profile = self.config.get_profile(profile_name)
            if not profile:
                raise Exception(f"Profile '{profile_name}' not found")

            # Extract tools from profile
            tools = {}
            terraform_flavor = profile.get(
                "terraform_flavor", self.config.get_setting("terraform_flavor", "terraform")
            )

            # Get the appropriate tool based on flavor
            if terraform_flavor == "opentofu" and "tofu" in profile:
                tools["tofu"] = profile["tofu"]
            elif "terraform" in profile:
                tools["terraform"] = profile["terraform"]

            # Install tools for this profile
            await self._install_profile_tools(profile_name, profile)

            # Set up environment for this profile
            env = dict(os.environ)
            env["WORKENV_PROFILE"] = profile_name

            # Run soup stir with this profile
            result = await self._run_stir_test(profile_name, stir_directory, env)

            duration = time.time() - start_time

            return ProfileTestResult(
                profile_name=profile_name,
                success=result["success"],
                duration_seconds=duration,
                test_results=result,
                tools=tools,
            )

        except Exception as e:
            duration = time.time() - start_time

            return ProfileTestResult(
                profile_name=profile_name,
                success=False,
                duration_seconds=duration,
                error_message=str(e),
            )

    async def _install_profile_tools(self, profile_name: str, profile: dict[str, Any]) -> None:
        """Install all tools for a specific profile."""
        # Determine which tools to install based on terraform_flavor
        terraform_flavor = profile.get(
            "terraform_flavor", self.config.get_setting("terraform_flavor", "terraform")
        )

        tools_to_install = {}
        if terraform_flavor == "opentofu" and "tofu" in profile:
            tools_to_install["tofu"] = profile["tofu"]
        elif "terraform" in profile:
            tools_to_install["terraform"] = profile["terraform"]

        # Install each tool
        for tool_name, version in tools_to_install.items():
            manager = get_tool_manager(tool_name, self.config)
            if not manager:
                raise Exception(f"No manager available for tool: {tool_name}")

            # Check if already installed
            current_version = manager.get_installed_version()
            if current_version == version:
                binary_path = manager.get_current_binary_path()
                if binary_path and binary_path.exists():
                    continue  # Already installed

            # Install the specific version
            console.print(f"Installing {tool_name} {version} for profile '{profile_name}'...")
            await asyncio.get_event_loop().run_in_executor(
                None,
                manager.install_version,
                version,
                False,  # not dry_run
            )

    async def _run_stir_test(
        self, profile_name: str, stir_directory: Path, env: dict[str, str]
    ) -> dict[str, Any]:
        """Run soup stir test for a specific profile."""
        import json

        # Build the soup stir command
        cmd = [
            "soup",
            "stir",
            str(stir_directory),
            "--json",  # Get JSON output for parsing
        ]

        # Run the stir command
        process = await asyncio.create_subprocess_exec(
            *cmd,
            env=env,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )

        stdout, stderr = await asyncio.wait_for(process.communicate(), timeout=self.timeout_minutes * 60)

        if process.returncode == 0:
            # Parse JSON output if available
            try:
                result = json.loads(stdout.decode())
                result["success"] = True
            except:
                result = {
                    "success": True,
                    "stdout": stdout.decode(),
                    "stderr": stderr.decode(),
                }
        else:
            result = {
                "success": False,
                "stdout": stdout.decode(),
                "stderr": stderr.decode(),
                "returncode": process.returncode,
            }

        return result

    def _display_results_table(self, results: list[ProfileTestResult]) -> None:
        """Display results in a nice table."""
        table = Table(title="Profile Test Results")

        # Add columns
        table.add_column("Profile", style="cyan")
        table.add_column("Tools", style="yellow")
        table.add_column("Status", style="bold")
        table.add_column("Duration", style="yellow")
        table.add_column("Error", style="red")

        # Add rows
        for result in results:
            status = "✅ Pass" if result.success else "❌ Fail"
            duration = f"{result.duration_seconds:.1f}s"
            error = result.error_message or ""

            # Format tools display
            tools_str = ", ".join(f"{k}:{v}" for k, v in result.tools.items()) if result.tools else "N/A"

            table.add_row(
                result.profile_name,
                tools_str,
                status,
                duration,
                error,
            )

        console.print(table)

    def save_results(self, results: dict[str, Any], output_path: Path) -> None:
        """Save profile test results to a file."""
        import json

        with open(output_path, "w") as f:
            json.dump(results, f, indent=2)

        console.print(f"[green]Profile test results saved to: {output_path}[/green]")


# Convenience function for soup stir integration
async def run_profile_matrix_tests(
    stir_directory: Path, profiles: list[str] | None = None, config: WorkenvConfig | None = None
) -> dict[str, Any]:
    """
    Run profile-based matrix testing for soup stir.

    Args:
        stir_directory: Directory containing stir test cases
        profiles: Optional list of specific profiles to test
        config: Optional WorkenvConfig

    Returns:
        Test results dictionary
    """
    matrix = ProfileMatrix(config)
    return await matrix.run_profile_tests(stir_directory, profiles)
>>> EOF >>>

### FILE 111: tofusoup/wire/__init__.py | checksum=36d6a41d77d9... | modified=2025-09-17T17:32:12 | op=+ | size=52 | tokens=28 | type=x-python ###
<<< BOF <<<
#
# tofusoup/wire/__init__.py
#

# 🍲🥄🚀🪄
>>> EOF >>>

### FILE 112: tofusoup/wire/cli.py | checksum=1f7b0b509ea5... | modified=2025-09-17T17:32:12 | op=+ | size=2453 | tokens=594 | type=x-python ###
<<< BOF <<<
#!/usr/bin/env python3
#
# tofusoup/wire/cli.py
#
import json
from pathlib import Path

import click
import msgpack
from rich import print_json

from .logic import convert_json_to_msgpack, convert_msgpack_to_json


@click.group()
def wire() -> None:
    """Commands for working with the Terraform wire protocol."""
    pass


@wire.command("to-msgpack")
@click.argument(
    "input_path",
    type=click.Path(exists=True, dir_okay=False, resolve_path=True, path_type=Path),
)
@click.option(
    "-o",
    "--output",
    "output_path",
    type=click.Path(dir_okay=False, resolve_path=True, path_type=Path),
    help="Output file path. Defaults to the input file with a .msgpack extension.",
)
def to_msgpack(input_path: Path, output_path: Path | None) -> None:
    """Converts a JSON file to the MessagePack wire format."""
    try:
        result_path = convert_json_to_msgpack(input_path, output_path)
        click.echo(f"✅ Successfully converted '{input_path.name}' to '{result_path.name}'")
    except (json.JSONDecodeError, msgpack.exceptions.PackException) as e:
        raise click.ClickException(f"Error during conversion: {e}")
    except Exception as e:
        raise click.ClickException(f"An unexpected error occurred: {e}")


@wire.command("to-json")
@click.argument(
    "input_path",
    type=click.Path(exists=True, dir_okay=False, resolve_path=True, path_type=Path),
)
@click.option(
    "-o",
    "--output",
    "output_path",
    type=click.Path(dir_okay=False, resolve_path=True, path_type=Path),
    help="Output file path. Defaults to the input file with a .json extension.",
)
@click.option(
    "--pretty/--no-pretty",
    default=True,
    help="Pretty-print the JSON output to the console.",
)
def to_json(input_path: Path, output_path: Path | None, pretty: bool) -> None:
    """Converts a MessagePack wire format file to JSON."""
    try:
        result_path = convert_msgpack_to_json(input_path, output_path)
        click.echo(f"✅ Successfully converted '{input_path.name}' to '{result_path.name}'")
        if pretty:
            # Read back the result for pretty printing
            json_data = result_path.read_text("utf-8")
            print_json(json_data)
    except msgpack.exceptions.UnpackException as e:
        raise click.ClickException(f"Error unpacking MessagePack file: {e}")
    except Exception as e:
        raise click.ClickException(f"An unexpected error occurred: {e}")


# 🍲🥄🖥️🪄
>>> EOF >>>

### FILE 113: tofusoup/wire/logging.py | checksum=561e38546cfe... | modified=2025-09-17T17:32:12 | op=+ | size=846 | tokens=191 | type=x-python ###
<<< BOF <<<
#
# tofusoup/wire/logging.py
#
"""Centralized logging configuration using Pyvider Telemetry."""

from provide.foundation import LoggingConfig, TelemetryConfig, get_hub

from tofusoup.config.defaults import DEFAULT_LOG_LEVEL


def configure_logging() -> None:
    """
    Configures Pyvider Telemetry for the library.

    This setup ensures that all log output is structured as JSON and directed
    to STDERR, preventing interference with the wire protocol's STDOUT/STDIN.
    """
    config = TelemetryConfig(
        logging=LoggingConfig(
            console_formatter="json",
            default_level=DEFAULT_LOG_LEVEL,
            das_emoji_prefix_enabled=True,
            logger_name_emoji_prefix_enabled=False,
        )
    )
    hub = get_hub()
    hub.initialize_foundation(config=config)


# <3 🍲 🍜 🍥>


# 🍲🥄📄🪄
>>> EOF >>>

### FILE 114: tofusoup/wire/logic.py | checksum=e20e87b7bafe... | modified=2025-09-17T17:32:12 | op=+ | size=1682 | tokens=389 | type=x-python ###
<<< BOF <<<
#
# tofusoup/wire/logic.py
#
import json
from pathlib import Path

import msgpack


def convert_json_to_msgpack(input_path: Path, output_path: Path | None) -> Path:
    """
    Reads a JSON file and writes its content as a MessagePack file.

    Args:
        input_path: The path to the source JSON file.
        output_path: The path to the destination MessagePack file. If None,
                     it defaults to the input path with a .msgpack extension.

    Returns:
        The path to the created MessagePack file.
    """
    if not input_path.exists():
        raise FileNotFoundError(f"Input file not found: {input_path}")

    if output_path is None:
        output_path = input_path.with_suffix(".msgpack")

    data = json.loads(input_path.read_text("utf-8"))
    packed_data = msgpack.packb(data)
    output_path.write_bytes(packed_data)
    return output_path


def convert_msgpack_to_json(input_path: Path, output_path: Path | None) -> Path:
    """
    Reads a MessagePack file and writes its content as a JSON file.

    Args:
        input_path: The path to the source MessagePack file.
        output_path: The path to the destination JSON file. If None,
                     it defaults to the input path with a .json extension.

    Returns:
        The path to the created JSON file.
    """
    if not input_path.exists():
        raise FileNotFoundError(f"Input file not found: {input_path}")

    if output_path is None:
        output_path = input_path.with_suffix(".json")

    unpacked_data = msgpack.unpackb(input_path.read_bytes())
    output_path.write_text(json.dumps(unpacked_data, indent=2), "utf-8")
    return output_path


# 🍲🥄📄🪄
>>> EOF >>>


### BUNDLE SUMMARY ###
- Included Files: 114
- Total Size (Included): 401126 bytes
- Duplicate Files Skipped: 0
- Items Excluded by Config/Defaults: 158 (Files: 153, Dirs: 5)
- Empty Files Found: 0
- System Errors Encountered: 0
- Encoding Errors (Fallback Attempted): 0
- Estimated Bundle Token Range: 100580 - 108559
- Processing Time: 0.21 seconds
### END BUNDLE SUMMARY ###

--- END OF BFILE bfiles-20251010-131213.txt ---
